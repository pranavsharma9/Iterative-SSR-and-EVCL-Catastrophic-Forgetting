{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 11.2,
  "eval_steps": 500,
  "global_step": 700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16,
      "grad_norm": 15.099788665771484,
      "learning_rate": 1.9826302729528538e-05,
      "loss": 6.5558,
      "step": 10
    },
    {
      "epoch": 0.32,
      "grad_norm": 16.472700119018555,
      "learning_rate": 1.957816377171216e-05,
      "loss": 5.9814,
      "step": 20
    },
    {
      "epoch": 0.48,
      "grad_norm": 22.525754928588867,
      "learning_rate": 1.9330024813895784e-05,
      "loss": 4.6592,
      "step": 30
    },
    {
      "epoch": 0.64,
      "grad_norm": 14.136307716369629,
      "learning_rate": 1.9081885856079405e-05,
      "loss": 3.5191,
      "step": 40
    },
    {
      "epoch": 0.8,
      "grad_norm": 10.699347496032715,
      "learning_rate": 1.883374689826303e-05,
      "loss": 2.5953,
      "step": 50
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.146968364715576,
      "learning_rate": 1.8585607940446654e-05,
      "loss": 1.9405,
      "step": 60
    },
    {
      "epoch": 0.992,
      "eval_loss": 1.7234774827957153,
      "eval_runtime": 54.947,
      "eval_samples_per_second": 9.1,
      "eval_steps_per_second": 1.147,
      "step": 62
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.0222315788269043,
      "learning_rate": 1.8337468982630275e-05,
      "loss": 1.7434,
      "step": 70
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.272719144821167,
      "learning_rate": 1.8089330024813896e-05,
      "loss": 1.4683,
      "step": 80
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.3677941858768463,
      "learning_rate": 1.784119106699752e-05,
      "loss": 1.3896,
      "step": 90
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.455379456281662,
      "learning_rate": 1.7593052109181142e-05,
      "loss": 1.3765,
      "step": 100
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1937273144721985,
      "learning_rate": 1.7344913151364767e-05,
      "loss": 1.3755,
      "step": 110
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.2018095701932907,
      "learning_rate": 1.7096774193548388e-05,
      "loss": 1.3785,
      "step": 120
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3917486667633057,
      "eval_runtime": 55.0136,
      "eval_samples_per_second": 9.089,
      "eval_steps_per_second": 1.145,
      "step": 125
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.19091908633708954,
      "learning_rate": 1.6848635235732013e-05,
      "loss": 1.4323,
      "step": 130
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.18941844999790192,
      "learning_rate": 1.6600496277915634e-05,
      "loss": 1.3548,
      "step": 140
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.17142409086227417,
      "learning_rate": 1.635235732009926e-05,
      "loss": 1.3224,
      "step": 150
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.1792631894350052,
      "learning_rate": 1.610421836228288e-05,
      "loss": 1.3799,
      "step": 160
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.16962186992168427,
      "learning_rate": 1.58560794044665e-05,
      "loss": 1.379,
      "step": 170
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.189938023686409,
      "learning_rate": 1.5607940446650125e-05,
      "loss": 1.3249,
      "step": 180
    },
    {
      "epoch": 2.992,
      "eval_loss": 1.3622301816940308,
      "eval_runtime": 54.8852,
      "eval_samples_per_second": 9.11,
      "eval_steps_per_second": 1.148,
      "step": 187
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.1760844737291336,
      "learning_rate": 1.5359801488833747e-05,
      "loss": 1.4013,
      "step": 190
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.19391362369060516,
      "learning_rate": 1.5111662531017371e-05,
      "loss": 1.3193,
      "step": 200
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.21116405725479126,
      "learning_rate": 1.4863523573200992e-05,
      "loss": 1.3246,
      "step": 210
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.21782957017421722,
      "learning_rate": 1.4615384615384615e-05,
      "loss": 1.3292,
      "step": 220
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.24771635234355927,
      "learning_rate": 1.4367245657568238e-05,
      "loss": 1.4182,
      "step": 230
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.23453247547149658,
      "learning_rate": 1.4119106699751861e-05,
      "loss": 1.2707,
      "step": 240
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3830399513244629,
      "learning_rate": 1.3870967741935486e-05,
      "loss": 1.2668,
      "step": 250
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3133708238601685,
      "eval_runtime": 54.5231,
      "eval_samples_per_second": 9.17,
      "eval_steps_per_second": 1.155,
      "step": 250
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.3261362314224243,
      "learning_rate": 1.3622828784119109e-05,
      "loss": 1.256,
      "step": 260
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.3102218806743622,
      "learning_rate": 1.3374689826302731e-05,
      "loss": 1.2644,
      "step": 270
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.2956174910068512,
      "learning_rate": 1.3126550868486354e-05,
      "loss": 1.293,
      "step": 280
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.24006807804107666,
      "learning_rate": 1.2878411910669977e-05,
      "loss": 1.2196,
      "step": 290
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.22023960947990417,
      "learning_rate": 1.26302729528536e-05,
      "loss": 1.2553,
      "step": 300
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.25227120518684387,
      "learning_rate": 1.2382133995037221e-05,
      "loss": 1.2189,
      "step": 310
    },
    {
      "epoch": 4.992,
      "eval_loss": 1.2475138902664185,
      "eval_runtime": 83.138,
      "eval_samples_per_second": 6.014,
      "eval_steps_per_second": 0.758,
      "step": 312
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.20268139243125916,
      "learning_rate": 1.2133995037220844e-05,
      "loss": 1.2617,
      "step": 320
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.16818532347679138,
      "learning_rate": 1.1885856079404467e-05,
      "loss": 1.2361,
      "step": 330
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.16285939514636993,
      "learning_rate": 1.163771712158809e-05,
      "loss": 1.207,
      "step": 340
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.14720547199249268,
      "learning_rate": 1.1389578163771713e-05,
      "loss": 1.1982,
      "step": 350
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.14531975984573364,
      "learning_rate": 1.1141439205955336e-05,
      "loss": 1.1696,
      "step": 360
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.15341149270534515,
      "learning_rate": 1.0893300248138959e-05,
      "loss": 1.2477,
      "step": 370
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.2304328680038452,
      "eval_runtime": 83.0678,
      "eval_samples_per_second": 6.019,
      "eval_steps_per_second": 0.758,
      "step": 375
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.14693348109722137,
      "learning_rate": 1.0645161290322582e-05,
      "loss": 1.287,
      "step": 380
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.13868801295757294,
      "learning_rate": 1.0397022332506203e-05,
      "loss": 1.2071,
      "step": 390
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.14917415380477905,
      "learning_rate": 1.0148883374689826e-05,
      "loss": 1.2295,
      "step": 400
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.13422618806362152,
      "learning_rate": 9.90074441687345e-06,
      "loss": 1.1751,
      "step": 410
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.14891865849494934,
      "learning_rate": 9.652605459057073e-06,
      "loss": 1.2448,
      "step": 420
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.13404838740825653,
      "learning_rate": 9.404466501240696e-06,
      "loss": 1.1487,
      "step": 430
    },
    {
      "epoch": 6.992,
      "eval_loss": 1.2244668006896973,
      "eval_runtime": 83.1257,
      "eval_samples_per_second": 6.015,
      "eval_steps_per_second": 0.758,
      "step": 437
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.1455325335264206,
      "learning_rate": 9.156327543424319e-06,
      "loss": 1.1997,
      "step": 440
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.1440066546201706,
      "learning_rate": 8.90818858560794e-06,
      "loss": 1.2,
      "step": 450
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.14011989533901215,
      "learning_rate": 8.660049627791563e-06,
      "loss": 1.2497,
      "step": 460
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.1337536871433258,
      "learning_rate": 8.411910669975186e-06,
      "loss": 1.1714,
      "step": 470
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.1406736522912979,
      "learning_rate": 8.16377171215881e-06,
      "loss": 1.1703,
      "step": 480
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.15348248183727264,
      "learning_rate": 7.915632754342433e-06,
      "loss": 1.2281,
      "step": 490
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.21499581634998322,
      "learning_rate": 7.667493796526055e-06,
      "loss": 1.2159,
      "step": 500
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.2203501462936401,
      "eval_runtime": 53.8344,
      "eval_samples_per_second": 9.288,
      "eval_steps_per_second": 1.17,
      "step": 500
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.14032427966594696,
      "learning_rate": 7.4193548387096784e-06,
      "loss": 1.2147,
      "step": 510
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.13608480989933014,
      "learning_rate": 7.1712158808933005e-06,
      "loss": 1.1967,
      "step": 520
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.12671981751918793,
      "learning_rate": 6.923076923076923e-06,
      "loss": 1.19,
      "step": 530
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.14090842008590698,
      "learning_rate": 6.674937965260546e-06,
      "loss": 1.1699,
      "step": 540
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.13933126628398895,
      "learning_rate": 6.426799007444169e-06,
      "loss": 1.2324,
      "step": 550
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.13513998687267303,
      "learning_rate": 6.178660049627791e-06,
      "loss": 1.1454,
      "step": 560
    },
    {
      "epoch": 8.992,
      "eval_loss": 1.2175209522247314,
      "eval_runtime": 53.8868,
      "eval_samples_per_second": 9.279,
      "eval_steps_per_second": 1.169,
      "step": 562
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.1275225430727005,
      "learning_rate": 5.930521091811415e-06,
      "loss": 1.1781,
      "step": 570
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.13740228116512299,
      "learning_rate": 5.682382133995038e-06,
      "loss": 1.1699,
      "step": 580
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.13333922624588013,
      "learning_rate": 5.434243176178661e-06,
      "loss": 1.2071,
      "step": 590
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.13756243884563446,
      "learning_rate": 5.186104218362284e-06,
      "loss": 1.2869,
      "step": 600
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.13620734214782715,
      "learning_rate": 4.937965260545906e-06,
      "loss": 1.1386,
      "step": 610
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.13357141613960266,
      "learning_rate": 4.689826302729529e-06,
      "loss": 1.1774,
      "step": 620
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.215499758720398,
      "eval_runtime": 54.8556,
      "eval_samples_per_second": 9.115,
      "eval_steps_per_second": 1.148,
      "step": 625
    },
    {
      "epoch": 10.08,
      "grad_norm": 0.12372567504644394,
      "learning_rate": 4.4416873449131515e-06,
      "loss": 1.2374,
      "step": 630
    },
    {
      "epoch": 10.24,
      "grad_norm": 0.13717760145664215,
      "learning_rate": 4.193548387096774e-06,
      "loss": 1.2416,
      "step": 640
    },
    {
      "epoch": 10.4,
      "grad_norm": 0.13430973887443542,
      "learning_rate": 3.945409429280397e-06,
      "loss": 1.196,
      "step": 650
    },
    {
      "epoch": 10.56,
      "grad_norm": 0.1432785838842392,
      "learning_rate": 3.69727047146402e-06,
      "loss": 1.1749,
      "step": 660
    },
    {
      "epoch": 10.72,
      "grad_norm": 0.1292610913515091,
      "learning_rate": 3.4491315136476427e-06,
      "loss": 1.1945,
      "step": 670
    },
    {
      "epoch": 10.88,
      "grad_norm": 0.1392902135848999,
      "learning_rate": 3.200992555831266e-06,
      "loss": 1.148,
      "step": 680
    },
    {
      "epoch": 10.992,
      "eval_loss": 1.2140165567398071,
      "eval_runtime": 54.8993,
      "eval_samples_per_second": 9.108,
      "eval_steps_per_second": 1.148,
      "step": 687
    },
    {
      "epoch": 11.04,
      "grad_norm": 0.1450749635696411,
      "learning_rate": 2.952853598014889e-06,
      "loss": 1.2749,
      "step": 690
    },
    {
      "epoch": 11.2,
      "grad_norm": 0.13379469513893127,
      "learning_rate": 2.7047146401985114e-06,
      "loss": 1.2097,
      "step": 700
    }
  ],
  "logging_steps": 10,
  "max_steps": 806,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 13,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.880896411205632e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
