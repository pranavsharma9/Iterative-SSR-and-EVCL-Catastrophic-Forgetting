{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3df9f10-1efb-4437-b04e-e6c2020be1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import tyxe\n",
    "\n",
    "import random\n",
    "import functools\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyro.infer import SVI, TraceMeanField_ELBO, Trace_ELBO\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, TensorDataset\n",
    "\n",
    "from datasets import load_dataset  # Added to load SuperNI dataset\n",
    "\n",
    "from typing import Optional, List\n",
    "from model.mle_prior import MLEPrior\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaff032f-ae3f-4be6-a016-d5ee7237f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Current Device Index: 0\n",
      "Current Device Name: NVIDIA A100-SXM4-80GB\n",
      "Number of GPUs: 1\n",
      "Device 0: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "print(\"Current Device Index:\", current_device)\n",
    "\n",
    "device_name = torch.cuda.get_device_name(current_device)\n",
    "print(\"Current Device Name:\", device_name)\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs:\", num_gpus)\n",
    "\n",
    "for device_id in range(num_gpus):\n",
    "    print(f\"Device {device_id}: {torch.cuda.get_device_name(device_id)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3192f-96f4-44da-9eb4-aea2856aab4f",
   "metadata": {},
   "source": [
    "### Task1 -QA LoRA+EVCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d43227-5365-4537-a585-1f370b504d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_info(\n",
    "    model, \n",
    "    data_loader, \n",
    "    prev_fisher_info=None, \n",
    "    ewc_gamma=1.0, \n",
    "    num_epochs=1, \n",
    "    head_modules=None, \n",
    "    n_samples=None\n",
    "):\n",
    "\n",
    "    fisher = {}\n",
    "    \n",
    "    # Initialize Fisher matrix for LoRA parameters, excluding head modules if provided\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lora' in name and (head_modules is None or not any(name.startswith(head) for head in head_modules)):\n",
    "            fisher[name] = torch.zeros_like(param).to(DEVICE)\n",
    "    \n",
    "    # Save the model's current training state and set to eval\n",
    "    old_training_state = model.training\n",
    "    model.eval()\n",
    "    \n",
    "    scaler = GradScaler(device='cuda')\n",
    "\n",
    "    batch_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            if n_samples is not None and batch_count >= n_samples:\n",
    "                break\n",
    "\n",
    "            print(f\"Processing batch {batch_count + 1}\")\n",
    "            model.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            try:\n",
    "                # with autocast(device_type='cuda'):\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "            # scaler.scale(loss).backward()\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in batch {batch_count + 1}: {e}\")\n",
    "                break\n",
    "\n",
    "            # Accumulate Fisher information for LoRA parameters\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'lora' in name and param.grad is not None and (head_modules is None or not any(name.startswith(head) for head in head_modules)):\n",
    "                    fisher[name] += param.grad.data ** 2\n",
    "\n",
    "            print(f\"Completed batch {batch_count + 1}\")\n",
    "            batch_count += 1\n",
    "\n",
    "    # Normalize Fisher information by the number of processed batches or samples\n",
    "    normalization_factor = batch_count if n_samples is None else min(batch_count, n_samples)\n",
    "    for name in fisher:\n",
    "        fisher[name] = fisher[name] / normalization_factor\n",
    "\n",
    "    # Integrate previous Fisher information with EWC scaling\n",
    "    if prev_fisher_info is not None:\n",
    "        for name in fisher:\n",
    "            if name in prev_fisher_info:\n",
    "                fisher[name] += ewc_gamma * prev_fisher_info[name]\n",
    "\n",
    "    # Restore the model's original training state\n",
    "    model.train(old_training_state)\n",
    "    \n",
    "    return fisher\n",
    "\n",
    "# Function to get variational posterior means\n",
    "def get_variational_posterior_means(model):\n",
    "    posterior_means = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if hasattr(module, 'lora_A'):\n",
    "            # print('yes')\n",
    "            for key in module.lora_A:\n",
    "                param_name = f\"{name}.lora_A.{key}\"\n",
    "                loc_name = f\"{param_name}_loc\"\n",
    "                if loc_name in pyro.get_param_store():\n",
    "                    lora_A_loc = pyro.param(loc_name).detach().clone()\n",
    "                    # Add '.weight' to the parameter name\n",
    "                    posterior_means[f\"{param_name}.weight\"] = lora_A_loc\n",
    "        if hasattr(module, 'lora_B'):\n",
    "            # print('yes')\n",
    "            for key in module.lora_B:\n",
    "                param_name = f\"{name}.lora_B.{key}\"\n",
    "                loc_name = f\"{param_name}_loc\"\n",
    "                if loc_name in pyro.get_param_store():\n",
    "                    lora_B_loc = pyro.param(loc_name).detach().clone()\n",
    "                    # Add '.weight' to the parameter name\n",
    "                    posterior_means[f\"{param_name}.weight\"] = lora_B_loc\n",
    "    return posterior_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4265f3da-cf93-4c14-b872-82c7f2817cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft.tuners.lora import LoraLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc12ed2-8b42-4e1e-87f5-ed00d1eb2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling,BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import PeftConfig, PeftModel\n",
    "from accelerate import init_empty_weights\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "from peft.tuners.lora import LoraLayer\n",
    "from pyro.nn.module import to_pyro_module_\n",
    "import bitsandbytes\n",
    "\n",
    "def deterministic_lora_task():\n",
    "    login(\"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\")\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "    base_model_repo_id = \"meta-llama/Meta-Llama-3-8B\"  \n",
    "    adapter_model_dir = r\"/home/pranav24/cs-546-project/SSR/Latest_Weights/QA_Weights/finetuned-weights/QA_Final\"\n",
    "\n",
    "    os.chdir(r'/home/pranav24/cs-546-project')\n",
    "    \n",
    "   \n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,  \n",
    "        device_map=\"auto\",  \n",
    "        offload_folder=\"offload\",  \n",
    "        offload_state_dict=True,  \n",
    "    )\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_repo_id)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_repo_id,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16, \n",
    "    )\n",
    "    model.config.reduction = \"mean\" \n",
    "    \n",
    "\n",
    "    peft_config = PeftConfig.from_pretrained(adapter_model_dir)\n",
    "    model = PeftModel.from_pretrained(model, adapter_model_dir, config=peft_config)\n",
    "        \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lora' in name:\n",
    "            print(name)\n",
    "    return model,tokenizer\n",
    "\n",
    "\n",
    "# def initialize_lora():\n",
    "#     login(\"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\")\n",
    "#     # Set environment variable to manage memory fragmentation\n",
    "#     os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    \n",
    "     \n",
    "#     # Specify directories and the path to the zip file\n",
    "#     offload_dir = os.path.expanduser(\"llama_offload_evcl/\")\n",
    "     \n",
    "#     os.makedirs(offload_dir, exist_ok=True)\n",
    "     \n",
    "#     # Extract only the specified JSON file from the zip archive\n",
    "#     os.chdir('/home/pranav24/cs-546-project/SSR/Latest_Weights/QA_Weights')\n",
    "#     target_file = \"task024_cosmosqa_answer_generation.json\"\n",
    "     \n",
    "#     # Load tokenizer from Hugging Face\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "#     # Load the model with accelerate's offloading and device map auto-setup\n",
    "#     with init_empty_weights():\n",
    "#         model = AutoModelForCausalLM.from_pretrained(\n",
    "#             \"meta-llama/Meta-Llama-3-8B\",\n",
    "#             device_map=\"auto\",\n",
    "#             # max_memory=max_memory,\n",
    "#             offload_folder=offload_dir,\n",
    "#             load_in_8bit=True,\n",
    "#             llm_int8_enable_fp32_cpu_offload=True\n",
    "#         )\n",
    "     \n",
    "#     # Configure LoRA with reduced rank\n",
    "#     lora_config = LoraConfig(\n",
    "#         r=8,\n",
    "#         lora_alpha=16,\n",
    "#         lora_dropout=0.1,\n",
    "#         bias=\"none\",\n",
    "#         task_type=\"CAUSAL_LM\",\n",
    "#     )\n",
    "#     model = get_peft_model(model, lora_config)\n",
    "\n",
    "#     #printing the trainable parameters\n",
    "#     model.print_trainable_parameters()\n",
    "\n",
    "#     # for name, param in model.named_parameters():\n",
    "#     #     if 'lora' in name:\n",
    "#     #         print(name)\n",
    "\n",
    "#     return model, tokenizer\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62ff472-4fa4-47c2-b2bf-f39fd4fbfbea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['device_map', 'offload_folder', 'offload_state_dict']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857b759074c04f248c01e1befc421cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a61c7e892744916ae95dc6e8bb5c042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3d85040ff048bf8e379f5fc3503c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6ffcab16a14246961da440e35aa607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea642d6a9ff463e8d83192b66a3409b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc5a9f73658422c8659c71b6622e0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bc084d720d4787941aadb9736d5c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3f8755ae4a407fb2211d7bcc8b15ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b4add457064ccaafff01033f62887b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00d12026da14a8499f066b9f677c9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662d6619f93c4afe87c5b136bb41dbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c945d8fdde1b45408f6ef84f116d50ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading base model...\")\n",
    "model,tokenizer=deterministic_lora_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57385901-11a1-491b-abb3-1b924f4d6cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c993e341f557425db817a53fa30959af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from accelerate import init_empty_weights\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "from peft.tuners.lora import LoraLayer\n",
    "from pyro.nn.module import to_pyro_module_\n",
    "os.chdir('/home/pranav24/cs-546-project/SSR/Latest_Weights/QA_Weights')\n",
    "target_file = \"task024_cosmosqa_answer_generation.json\"\n",
    "\n",
    "with open(target_file, 'r', encoding='utf-8-sig') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "instances = json_data['Instances'][0:2500]\n",
    "input_texts = [str(instance['input']) for instance in instances]\n",
    "output_texts = [str(instance['output'][0]) if instance['output'] else \"\" for instance in instances]\n",
    "\n",
    "# Create Hugging Face Dataset\n",
    "ds = Dataset.from_dict({'input': input_texts, 'output': output_texts})\n",
    "\n",
    "# Tokenize the dataset\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"input\"], examples[\"output\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"output\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )[\"input_ids\"]\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# Apply tokenization and set format\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Split dataset into train and eval\n",
    "train_size = int(0.8 * len(tokenized_datasets))\n",
    "train_dataset = tokenized_datasets.select(range(train_size))\n",
    "eval_dataset = tokenized_datasets.select(range(train_size, len(tokenized_datasets)))\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 4  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6015f59-7b73-46b6-940a-9f1ec22c3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(model, tokenizer, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"Model and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cecb98-c125-4a32-a87f-05e4addea699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    sampled_weights_log = []  # To store sampled weights for verification\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            labels = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # Log sampled weights for LoRA layers during the forward pass\n",
    "                for name, module in model.named_modules():\n",
    "                    if hasattr(module, \"lora_A\"):\n",
    "                        for key in module.lora_A:\n",
    "                            loc = pyro.param(f\"{name}.lora_A.{key}_loc\")\n",
    "                            scale = pyro.param(f\"{name}.lora_A.{key}_scale\")\n",
    "                            sampled_weight = pyro.sample(\n",
    "                                f\"{name}.lora_A.{key}\",\n",
    "                                dist.Normal(loc, scale).to_event(loc.dim())\n",
    "                            )\n",
    "                            # Log sampled weight for debugging\n",
    "                            sampled_weights_log.append(\n",
    "                                (name, key, sampled_weight.clone().cpu().numpy())\n",
    "                            )\n",
    "                            # Ensure the sampled weight is used in the model\n",
    "                            module.lora_A[key].weight.data.copy_(sampled_weight)\n",
    "\n",
    "                    if hasattr(module, \"lora_B\"):\n",
    "                        for key in module.lora_B:\n",
    "                            loc = pyro.param(f\"{name}.lora_B.{key}_loc\")\n",
    "                            scale = pyro.param(f\"{name}.lora_B.{key}_scale\")\n",
    "                            sampled_weight = pyro.sample(\n",
    "                                f\"{name}.lora_B.{key}\",\n",
    "                                dist.Normal(loc, scale).to_event(loc.dim())\n",
    "                            )\n",
    "                            # Log sampled weight for debugging\n",
    "                            sampled_weights_log.append(\n",
    "                                (name, key, sampled_weight.clone().cpu().numpy())\n",
    "                            )\n",
    "                            # Ensure the sampled weight is used in the model\n",
    "                            module.lora_B[key].weight.data.copy_(sampled_weight)\n",
    "\n",
    "                # Perform forward pass\n",
    "                outputs = model(input_ids, labels=labels, attention_mask=attention_mask)\n",
    "                loss = outputs.loss\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    # Log the sampled weights (optional, for debugging)\n",
    "    # print(\"Sampled Weights Log:\")\n",
    "    # for layer_name, key, weight in sampled_weights_log[:5]:  # Show only the first 5 entries\n",
    "    #     print(f\"Layer: {layer_name}, Key: {key}, Sampled Weight (snippet): {weight.flatten()[:5]}\")\n",
    "\n",
    "    print(f\"Evaluation Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479be571-c608-4e8b-9f9b-2c09915106a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(model,eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae06200-7093-45ff-bec3-abc1e93834af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from torch.optim import AdamW\n",
    "import torch.cuda.amp as amp\n",
    "from transformers import get_scheduler\n",
    "from pyro.optim import ExponentialLR\n",
    "evaluation_loss=[]\n",
    "\n",
    "\n",
    "def run_lora_evcl_1(\n",
    "    train_loader,\n",
    "    eval_loader,\n",
    "    num_epochs: int = 100,\n",
    "    model: str = \"meta-llama/Meta-Llama-3-8B\",\n",
    "    batch_size: int = 2,\n",
    "    learning_rate: float = 1e-5,\n",
    "    logging_steps: int = 100,\n",
    "    eval_steps: int = 200,\n",
    "    save_steps: int = 500,\n",
    "    output_dir: str = \"finetuned-weights-LoRA-EVCL\",\n",
    "    load_pyro: bool = False,\n",
    "    best_output_dir=\"finetuned-weights-LoRA-EVCL-Final-Task1_VCL_best\"\n",
    "):\n",
    "\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lora' in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False  # Freeze non-LoRA parameters\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    def bayesian_guide(input_ids, attention_mask, labels, epoch, warmup_epochs=10, min_scale_factor=0.1):\n",
    "\n",
    "        annealing_factor = max(1.0 - (epoch / warmup_epochs), min_scale_factor)\n",
    "        \n",
    "        # Define variational distributions over the LoRA parameters\n",
    "        for name, module in model.named_modules():\n",
    "            if hasattr(module, 'lora_A'):\n",
    "                for key in module.lora_A:\n",
    "                    param_name = f\"{name}.lora_A.{key}\"\n",
    "                    lora_A_param = module.lora_A[key].weight\n",
    "                    device = lora_A_param.device\n",
    "\n",
    "                    # Ensure initial values are leaf tensors with requires_grad=True\n",
    "                    loc_init = lora_A_param.detach().clone().to(device).requires_grad_()\n",
    "                    scale_init = (0.01 * torch.ones_like(lora_A_param)).to(device).requires_grad_()\n",
    "\n",
    "                    loc = pyro.param(\n",
    "                        f\"{param_name}_loc\",\n",
    "                        loc_init\n",
    "                    )\n",
    "                    scale = pyro.param(\n",
    "                        f\"{param_name}_scale\",\n",
    "                        scale_init,\n",
    "                        constraint=dist.constraints.positive\n",
    "                    )\n",
    "                    \n",
    "                    adjusted_scale = scale * annealing_factor\n",
    "                    \n",
    "                    pyro.sample(\n",
    "                        param_name,\n",
    "                        dist.Normal(loc, adjusted_scale).to_event(lora_A_param.dim())\n",
    "                    )\n",
    "            if hasattr(module, 'lora_B'):\n",
    "                for key in module.lora_B:\n",
    "                    param_name = f\"{name}.lora_B.{key}\"\n",
    "                    lora_B_param = module.lora_B[key].weight\n",
    "                    device = lora_B_param.device\n",
    "\n",
    "                    # Ensure initial values are leaf tensors with requires_grad=True\n",
    "                    loc_init = lora_B_param.detach().clone().to(device).requires_grad_()\n",
    "                    scale_init = (0.01 * torch.ones_like(lora_B_param)).to(device).requires_grad_()\n",
    "\n",
    "                    loc = pyro.param(\n",
    "                        f\"{param_name}_loc\",\n",
    "                        loc_init\n",
    "                    )\n",
    "                    scale = pyro.param(\n",
    "                        f\"{param_name}_scale\",\n",
    "                        scale_init,\n",
    "                        constraint=dist.constraints.positive\n",
    "                    )\n",
    "                    \n",
    "                    adjusted_scale = scale * annealing_factor\n",
    "                    \n",
    "                    pyro.sample(\n",
    "                        param_name,\n",
    "                        dist.Normal(loc, adjusted_scale).to_event(lora_B_param.dim())\n",
    "                    )\n",
    "                    \n",
    "    def bayesian_model(input_ids, attention_mask, labels):\n",
    "        # Define a function to sample and substitute LoRA parameters\n",
    "        def model_with_sampled_lora():\n",
    "            # Sample LoRA parameters and set them in the model\n",
    "            for name, module in model.named_modules():\n",
    "                if hasattr(module, 'lora_A'):\n",
    "                    for key in module.lora_A:\n",
    "                        param_name = f\"{name}.lora_A.{key}\"\n",
    "                        lora_A_module = module.lora_A[key]\n",
    "                        device = lora_A_module.weight.device\n",
    "    \n",
    "                        # Sample from the prior\n",
    "                        sampled_weight = pyro.sample(\n",
    "                            param_name,\n",
    "                            dist.Normal(\n",
    "                                lora_A_module.weight.detach().to(device),\n",
    "                                (0.1 * torch.ones_like(lora_A_module.weight)).to(device)\n",
    "                            ).to_event(lora_A_module.weight.dim())\n",
    "                        )\n",
    "    \n",
    "                        # Assign the sampled weight to the module\n",
    "                        with torch.no_grad():\n",
    "                            lora_A_module.weight.copy_(sampled_weight)\n",
    "    \n",
    "                if hasattr(module, 'lora_B'):\n",
    "                    for key in module.lora_B:\n",
    "                        param_name = f\"{name}.lora_B.{key}\"\n",
    "                        lora_B_module = module.lora_B[key]\n",
    "                        device = lora_B_module.weight.device\n",
    "    \n",
    "                        # Sample from the prior\n",
    "                        sampled_weight = pyro.sample(\n",
    "                            param_name,\n",
    "                            dist.Normal(\n",
    "                                lora_B_module.weight.detach().to(device),\n",
    "                                (0.1 * torch.ones_like(lora_B_module.weight)).to(device)\n",
    "                            ).to_event(lora_B_module.weight.dim())\n",
    "                        )\n",
    "    \n",
    "                        # Assign the sampled weight to the module\n",
    "                        with torch.no_grad():\n",
    "                            lora_B_module.weight.copy_(sampled_weight)\n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            return loss\n",
    "    \n",
    "        # Use the modified model with sampled LoRA parameters\n",
    "        return model_with_sampled_lora()\n",
    "\n",
    "\n",
    "    # Set up SVI\n",
    "    if load_pyro:\n",
    "        print('using previous pyro params')\n",
    "        pyro.get_param_store().load('pyro_param_store_task1.pt')\n",
    "    else:\n",
    "        print('not using previous pyro params')\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "    optim = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "    optim = pyro.optim.PyroOptim(AdamW, {\"lr\": learning_rate, \"weight_decay\": 1e-5})\n",
    "  \n",
    "    scheduler = ExponentialLR({'optimizer': AdamW, 'optim_args': {'lr': learning_rate}, 'gamma': 0.1})\n",
    "    elbo = TraceMeanField_ELBO()\n",
    "    # svi = SVI(bayesian_model, bayesian_guide, scheduler, loss=elbo)\n",
    "    # svi = SVI(bayesian_model, lambda *args, **kwargs: bayesian_guide(*args, **kwargs, epoch=epoch), scheduler, loss=elbo)\n",
    "\n",
    "    print(f\"Training on Task 1...\")\n",
    "    max_wait=20\n",
    "    best_eval_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        svi = SVI(bayesian_model, lambda *args, **kwargs: bayesian_guide(*args, **kwargs, epoch=epoch), scheduler, loss=elbo)\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for num_batches, batch in enumerate(train_loader, 1):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            # if epoch==0 and num_batches==1:\n",
    "            #     generated_ids = model.generate(\n",
    "            #     input_ids=input_ids,\n",
    "            #     attention_mask=attention_mask,\n",
    "            #     max_new_tokens=512,  # Adjust as needed\n",
    "            #     num_return_sequences=1,\n",
    "            # )\n",
    "                \n",
    "            #     batch_predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            #     print(batch_predictions)\n",
    "    \n",
    "            #     data = {\n",
    "            #                 \"batch_predictions\": batch_predictions,\n",
    "            #             }\n",
    "\n",
    "\n",
    "            #     with open(f\"/home/pranav24/cs-546-project/Testing/predictions_EVCL_1_epoch_{epoch}_{num_batches}.json\", \"w\") as json_file:\n",
    "            #         json.dump(data, json_file, indent=4)\n",
    "\n",
    "            # generated_ids = model.generate(\n",
    "            #     input_ids=input_ids,\n",
    "            #     attention_mask=attention_mask,\n",
    "            #     max_new_tokens=512,  # Adjust as needed\n",
    "            #     num_return_sequences=1,\n",
    "            # )\n",
    "\n",
    "            # batch_predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            # print(batch_predictions)\n",
    "\n",
    "            # data = {\n",
    "            #             \"batch_predictions\": batch_predictions,\n",
    "            #         }\n",
    "\n",
    "\n",
    "            # with open(f\"/home/pranav24/cs-546-project/Testing/predictions_EVCL_1_{num_batches}.json\", \"w\") as json_file:\n",
    "            #     json.dump(data, json_file, indent=4)\n",
    "            \n",
    "            loss = svi.step(input_ids, attention_mask, labels)\n",
    "            total_loss += loss\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "            # Logging\n",
    "            if num_batches % logging_steps == 0:\n",
    "                avg_loss = total_loss / num_batches\n",
    "                print(f\"Epoch {epoch}, Step {num_batches}, Loss: {avg_loss}\")\n",
    "\n",
    "            # Evaluation\n",
    "            if num_batches % eval_steps == 0:\n",
    "                eval_loss=evaluate_model(model, eval_loader)\n",
    "                evaluation_loss.append(eval_loss)\n",
    "                \n",
    "\n",
    "\n",
    "        avg_epoch_loss = total_loss / num_batches\n",
    "        print(f\"Task 1 Epoch {epoch} completed. Average Loss: {avg_epoch_loss}\")\n",
    "\n",
    "        if epoch%25==0:\n",
    "            save_trained_model(model, tokenizer, output_dir)\n",
    "            pyro.get_param_store().save('pyro_param_store_task1_vcl.pt')\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=512,  # Adjust as needed\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "            batch_predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            # print(batch_predictions)\n",
    "\n",
    "            data = {\n",
    "                        \"batch_predictions\": batch_predictions,\n",
    "                    }\n",
    "\n",
    "\n",
    "            with open(f\"/home/pranav24/cs-546-project/Testing/predictions_EVCL_1_epoch_{epoch}_{num_batches}.json\", \"w\") as json_file:\n",
    "                json.dump(data, json_file, indent=4)\n",
    "            \n",
    "                \n",
    "        if eval_loss<best_eval_loss:\n",
    "            best_eval_loss=eval_loss\n",
    "            no_improvement=0\n",
    "            save_trained_model(model, tokenizer, best_output_dir)\n",
    "            pyro.get_param_store().save('pyro_param_store_task1_evcl_best.pt')\n",
    "        else:\n",
    "            no_improvement+=1\n",
    "\n",
    "        if no_improvement>=max_wait and epoch>=99:\n",
    "            print(f'early stopping at epoch: {epoch}')\n",
    "            break\n",
    "            \n",
    "    \n",
    "    save_trained_model(model, tokenizer, output_dir)\n",
    "    pyro.get_param_store().save('pyro_param_store_task1_evcl.pt') \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88408ab-cd21-43bf-a8bb-6c9f4e8e3b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pranav24/cs-546-project\n",
      "/home/pranav24/cs-546-project\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('/home/pranav24/cs-546-project/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed87466-51c2-43f4-bccc-e0710e0b8fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,033,669,120 || trainable%: 0.0424\n",
      "not using previous pyro params\n",
      "Training on Task 1...\n",
      "Epoch 0, Step 100, Loss: 6176292.57\n",
      "Epoch 0, Step 200, Loss: 6176287.4625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161/2792350256.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 11.4057\n",
      "Epoch 0, Step 300, Loss: 6176286.691666666\n",
      "Epoch 0, Step 400, Loss: 6176285.65875\n",
      "Evaluation Loss: 11.2700\n",
      "Epoch 0, Step 500, Loss: 6176284.49\n",
      "Task 1 Epoch 0 completed. Average Loss: 6176284.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\n",
      "Epoch 1, Step 100, Loss: 6528860.455\n",
      "Epoch 1, Step 200, Loss: 6528858.83\n",
      "Evaluation Loss: 11.5142\n",
      "Epoch 1, Step 300, Loss: 6528859.108333333\n",
      "Epoch 1, Step 400, Loss: 6528859.57625\n",
      "Evaluation Loss: 11.3345\n",
      "Epoch 1, Step 500, Loss: 6528859.643\n",
      "Task 1 Epoch 1 completed. Average Loss: 6528859.643\n",
      "Epoch 2, Step 100, Loss: 6924451.315\n",
      "Epoch 2, Step 200, Loss: 6924452.1825\n",
      "Evaluation Loss: 11.2308\n",
      "Epoch 2, Step 300, Loss: 6924452.593333334\n",
      "Epoch 2, Step 400, Loss: 6924452.785\n",
      "Evaluation Loss: 11.4595\n",
      "Epoch 2, Step 500, Loss: 6924452.857\n",
      "Task 1 Epoch 2 completed. Average Loss: 6924452.857\n",
      "Epoch 3, Step 100, Loss: 7374395.85\n",
      "Epoch 3, Step 200, Loss: 7374396.195\n",
      "Evaluation Loss: 11.2773\n",
      "Epoch 3, Step 300, Loss: 7374396.215\n",
      "Epoch 3, Step 400, Loss: 7374396.3025\n",
      "Evaluation Loss: 11.4745\n",
      "Epoch 3, Step 500, Loss: 7374396.3\n",
      "Task 1 Epoch 3 completed. Average Loss: 7374396.3\n",
      "Epoch 4, Step 100, Loss: 7895289.98\n",
      "Epoch 4, Step 200, Loss: 7895290.325\n",
      "Evaluation Loss: 11.3143\n",
      "Epoch 4, Step 300, Loss: 7895290.268333334\n",
      "Epoch 4, Step 400, Loss: 7895290.42625\n",
      "Evaluation Loss: 11.1858\n",
      "Epoch 4, Step 500, Loss: 7895290.318\n",
      "Task 1 Epoch 4 completed. Average Loss: 7895290.318\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\n",
      "Epoch 5, Step 100, Loss: 8512868.29\n",
      "Epoch 5, Step 200, Loss: 8512868.36\n",
      "Evaluation Loss: 11.3627\n",
      "Epoch 5, Step 300, Loss: 8512868.306666667\n",
      "Epoch 5, Step 400, Loss: 8512868.255\n",
      "Evaluation Loss: 11.1710\n",
      "Epoch 5, Step 500, Loss: 8512868.356\n",
      "Task 1 Epoch 5 completed. Average Loss: 8512868.356\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\n",
      "Epoch 6, Step 100, Loss: 9270244.37\n",
      "Epoch 6, Step 200, Loss: 9270244.205\n",
      "Evaluation Loss: 11.4621\n",
      "Epoch 6, Step 300, Loss: 9270244.313333333\n",
      "Epoch 6, Step 400, Loss: 9270244.395\n",
      "Evaluation Loss: 11.5221\n",
      "Epoch 6, Step 500, Loss: 9270244.42\n",
      "Task 1 Epoch 6 completed. Average Loss: 9270244.42\n",
      "Epoch 7, Step 100, Loss: 10248243.98\n",
      "Epoch 7, Step 200, Loss: 10248243.89\n",
      "Evaluation Loss: 11.1949\n",
      "Epoch 7, Step 300, Loss: 10248243.913333334\n",
      "Epoch 7, Step 400, Loss: 10248243.9125\n",
      "Evaluation Loss: 11.4447\n",
      "Epoch 7, Step 500, Loss: 10248243.85\n",
      "Task 1 Epoch 7 completed. Average Loss: 10248243.85\n",
      "Epoch 8, Step 100, Loss: 11628315.83\n",
      "Epoch 8, Step 200, Loss: 11628315.915\n",
      "Evaluation Loss: 11.3236\n",
      "Epoch 8, Step 300, Loss: 11628315.88\n",
      "Epoch 8, Step 400, Loss: 11628315.8475\n",
      "Evaluation Loss: 11.2677\n",
      "Epoch 8, Step 500, Loss: 11628315.876\n",
      "Task 1 Epoch 8 completed. Average Loss: 11628315.876\n",
      "Epoch 9, Step 100, Loss: 13989446.92\n",
      "Epoch 9, Step 200, Loss: 13989446.915\n",
      "Evaluation Loss: 11.3653\n",
      "Epoch 9, Step 300, Loss: 13989446.926666666\n",
      "Epoch 9, Step 400, Loss: 13989446.9275\n",
      "Evaluation Loss: 11.5380\n",
      "Epoch 9, Step 500, Loss: 13989446.924\n",
      "Task 1 Epoch 9 completed. Average Loss: 13989446.924\n",
      "Epoch 10, Step 100, Loss: 13989446.92\n",
      "Epoch 10, Step 200, Loss: 13989446.935\n",
      "Evaluation Loss: 11.4061\n",
      "Epoch 10, Step 300, Loss: 13989446.936666667\n",
      "Epoch 10, Step 400, Loss: 13989446.94\n",
      "Evaluation Loss: 11.3358\n",
      "Epoch 10, Step 500, Loss: 13989446.938\n",
      "Task 1 Epoch 10 completed. Average Loss: 13989446.938\n",
      "Epoch 11, Step 100, Loss: 13989446.95\n",
      "Epoch 11, Step 200, Loss: 13989446.94\n",
      "Evaluation Loss: 11.2593\n",
      "Epoch 11, Step 300, Loss: 13989446.916666666\n",
      "Epoch 11, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.2510\n",
      "Epoch 11, Step 500, Loss: 13989446.928\n",
      "Task 1 Epoch 11 completed. Average Loss: 13989446.928\n",
      "Epoch 12, Step 100, Loss: 13989446.89\n",
      "Epoch 12, Step 200, Loss: 13989446.91\n",
      "Evaluation Loss: 11.5906\n",
      "Epoch 12, Step 300, Loss: 13989446.916666666\n",
      "Epoch 12, Step 400, Loss: 13989446.92\n",
      "Evaluation Loss: 11.2991\n",
      "Epoch 12, Step 500, Loss: 13989446.93\n",
      "Task 1 Epoch 12 completed. Average Loss: 13989446.93\n",
      "Epoch 13, Step 100, Loss: 13989446.89\n",
      "Epoch 13, Step 200, Loss: 13989446.895\n",
      "Evaluation Loss: 11.3956\n",
      "Epoch 13, Step 300, Loss: 13989446.913333334\n",
      "Epoch 13, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.2709\n",
      "Epoch 13, Step 500, Loss: 13989446.922\n",
      "Task 1 Epoch 13 completed. Average Loss: 13989446.922\n",
      "Epoch 14, Step 100, Loss: 13989446.92\n",
      "Epoch 14, Step 200, Loss: 13989446.94\n",
      "Evaluation Loss: 11.2665\n",
      "Epoch 14, Step 300, Loss: 13989446.936666667\n",
      "Epoch 14, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.3133\n",
      "Epoch 14, Step 500, Loss: 13989446.93\n",
      "Task 1 Epoch 14 completed. Average Loss: 13989446.93\n",
      "Epoch 15, Step 100, Loss: 13989446.91\n",
      "Epoch 15, Step 200, Loss: 13989446.915\n",
      "Evaluation Loss: 11.2882\n",
      "Epoch 15, Step 300, Loss: 13989446.916666666\n",
      "Epoch 15, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.1874\n",
      "Epoch 15, Step 500, Loss: 13989446.928\n",
      "Task 1 Epoch 15 completed. Average Loss: 13989446.928\n",
      "Epoch 16, Step 100, Loss: 13989446.96\n",
      "Epoch 16, Step 200, Loss: 13989446.935\n",
      "Evaluation Loss: 11.2347\n",
      "Epoch 16, Step 300, Loss: 13989446.94\n",
      "Epoch 16, Step 400, Loss: 13989446.9375\n",
      "Evaluation Loss: 11.1400\n",
      "Epoch 16, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 16 completed. Average Loss: 13989446.94\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\n",
      "Epoch 17, Step 100, Loss: 13989446.95\n",
      "Epoch 17, Step 200, Loss: 13989446.945\n",
      "Evaluation Loss: 11.2553\n",
      "Epoch 17, Step 300, Loss: 13989446.946666667\n",
      "Epoch 17, Step 400, Loss: 13989446.935\n",
      "Evaluation Loss: 11.3700\n",
      "Epoch 17, Step 500, Loss: 13989446.932\n",
      "Task 1 Epoch 17 completed. Average Loss: 13989446.932\n",
      "Epoch 18, Step 100, Loss: 13989446.9\n",
      "Epoch 18, Step 200, Loss: 13989446.91\n",
      "Evaluation Loss: 11.1388\n",
      "Epoch 18, Step 300, Loss: 13989446.92\n",
      "Epoch 18, Step 400, Loss: 13989446.9275\n",
      "Evaluation Loss: 11.2310\n",
      "Epoch 18, Step 500, Loss: 13989446.928\n",
      "Task 1 Epoch 18 completed. Average Loss: 13989446.928\n",
      "Epoch 19, Step 100, Loss: 13989446.93\n",
      "Epoch 19, Step 200, Loss: 13989446.915\n",
      "Evaluation Loss: 11.0926\n",
      "Epoch 19, Step 300, Loss: 13989446.906666666\n",
      "Epoch 19, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.6110\n",
      "Epoch 19, Step 500, Loss: 13989446.928\n",
      "Task 1 Epoch 19 completed. Average Loss: 13989446.928\n",
      "Epoch 20, Step 100, Loss: 13989446.91\n",
      "Epoch 20, Step 200, Loss: 13989446.925\n",
      "Evaluation Loss: 11.1849\n",
      "Epoch 20, Step 300, Loss: 13989446.936666667\n",
      "Epoch 20, Step 400, Loss: 13989446.9375\n",
      "Evaluation Loss: 11.4604\n",
      "Epoch 20, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 20 completed. Average Loss: 13989446.94\n",
      "Epoch 21, Step 100, Loss: 13989446.94\n",
      "Epoch 21, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.1076\n",
      "Epoch 21, Step 300, Loss: 13989446.93\n",
      "Epoch 21, Step 400, Loss: 13989446.9325\n",
      "Evaluation Loss: 11.5025\n",
      "Epoch 21, Step 500, Loss: 13989446.93\n",
      "Task 1 Epoch 21 completed. Average Loss: 13989446.93\n",
      "Epoch 22, Step 100, Loss: 13989446.97\n",
      "Epoch 22, Step 200, Loss: 13989446.97\n",
      "Evaluation Loss: 11.5086\n",
      "Epoch 22, Step 300, Loss: 13989446.96\n",
      "Epoch 22, Step 400, Loss: 13989446.96\n",
      "Evaluation Loss: 11.1316\n",
      "Epoch 22, Step 500, Loss: 13989446.95\n",
      "Task 1 Epoch 22 completed. Average Loss: 13989446.95\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\n",
      "Epoch 23, Step 100, Loss: 13989446.93\n",
      "Epoch 23, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.2843\n",
      "Epoch 23, Step 300, Loss: 13989446.943333333\n",
      "Epoch 23, Step 400, Loss: 13989446.95\n",
      "Evaluation Loss: 11.4023\n",
      "Epoch 23, Step 500, Loss: 13989446.946\n",
      "Task 1 Epoch 23 completed. Average Loss: 13989446.946\n",
      "Epoch 24, Step 100, Loss: 13989446.92\n",
      "Epoch 24, Step 200, Loss: 13989446.945\n",
      "Evaluation Loss: 11.4384\n",
      "Epoch 24, Step 300, Loss: 13989446.923333334\n",
      "Epoch 24, Step 400, Loss: 13989446.9125\n",
      "Evaluation Loss: 11.1489\n",
      "Epoch 24, Step 500, Loss: 13989446.916\n",
      "Task 1 Epoch 24 completed. Average Loss: 13989446.916\n",
      "Epoch 25, Step 100, Loss: 13989446.92\n",
      "Epoch 25, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.1712\n",
      "Epoch 25, Step 300, Loss: 13989446.936666667\n",
      "Epoch 25, Step 400, Loss: 13989446.9325\n",
      "Evaluation Loss: 11.3711\n",
      "Epoch 25, Step 500, Loss: 13989446.944\n",
      "Task 1 Epoch 25 completed. Average Loss: 13989446.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL\n",
      "Epoch 26, Step 100, Loss: 13989446.96\n",
      "Epoch 26, Step 200, Loss: 13989446.965\n",
      "Evaluation Loss: 11.5050\n",
      "Epoch 26, Step 300, Loss: 13989446.963333333\n",
      "Epoch 26, Step 400, Loss: 13989446.9675\n",
      "Evaluation Loss: 11.1722\n",
      "Epoch 26, Step 500, Loss: 13989446.966\n",
      "Task 1 Epoch 26 completed. Average Loss: 13989446.966\n",
      "Epoch 27, Step 100, Loss: 13989446.96\n",
      "Epoch 27, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.2235\n",
      "Epoch 27, Step 300, Loss: 13989446.933333334\n",
      "Epoch 27, Step 400, Loss: 13989446.94\n",
      "Evaluation Loss: 11.4512\n",
      "Epoch 27, Step 500, Loss: 13989446.942\n",
      "Task 1 Epoch 27 completed. Average Loss: 13989446.942\n",
      "Epoch 28, Step 100, Loss: 13989446.9\n",
      "Epoch 28, Step 200, Loss: 13989446.89\n",
      "Evaluation Loss: 11.3776\n",
      "Epoch 28, Step 300, Loss: 13989446.916666666\n",
      "Epoch 28, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.1595\n",
      "Epoch 28, Step 500, Loss: 13989446.928\n",
      "Task 1 Epoch 28 completed. Average Loss: 13989446.928\n",
      "Epoch 29, Step 100, Loss: 13989446.96\n",
      "Epoch 29, Step 200, Loss: 13989446.945\n",
      "Evaluation Loss: 11.4822\n",
      "Epoch 29, Step 300, Loss: 13989446.93\n",
      "Epoch 29, Step 400, Loss: 13989446.9375\n",
      "Evaluation Loss: 11.3619\n",
      "Epoch 29, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 29 completed. Average Loss: 13989446.94\n",
      "Epoch 30, Step 100, Loss: 13989446.92\n",
      "Epoch 30, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.5003\n",
      "Epoch 30, Step 300, Loss: 13989446.936666667\n",
      "Epoch 30, Step 400, Loss: 13989446.9475\n",
      "Evaluation Loss: 11.3782\n",
      "Epoch 30, Step 500, Loss: 13989446.938\n",
      "Task 1 Epoch 30 completed. Average Loss: 13989446.938\n",
      "Epoch 31, Step 100, Loss: 13989446.95\n",
      "Epoch 31, Step 200, Loss: 13989446.925\n",
      "Evaluation Loss: 11.3331\n",
      "Epoch 31, Step 300, Loss: 13989446.933333334\n",
      "Epoch 31, Step 400, Loss: 13989446.9425\n",
      "Evaluation Loss: 11.3155\n",
      "Epoch 31, Step 500, Loss: 13989446.946\n",
      "Task 1 Epoch 31 completed. Average Loss: 13989446.946\n",
      "Epoch 32, Step 100, Loss: 13989446.93\n",
      "Epoch 32, Step 200, Loss: 13989446.925\n",
      "Evaluation Loss: 11.0965\n",
      "Epoch 32, Step 300, Loss: 13989446.933333334\n",
      "Epoch 32, Step 400, Loss: 13989446.9425\n",
      "Evaluation Loss: 11.2619\n",
      "Epoch 32, Step 500, Loss: 13989446.932\n",
      "Task 1 Epoch 32 completed. Average Loss: 13989446.932\n",
      "Epoch 33, Step 100, Loss: 13989446.93\n",
      "Epoch 33, Step 200, Loss: 13989446.925\n",
      "Evaluation Loss: 11.5517\n",
      "Epoch 33, Step 300, Loss: 13989446.936666667\n",
      "Epoch 33, Step 400, Loss: 13989446.935\n",
      "Evaluation Loss: 11.4507\n",
      "Epoch 33, Step 500, Loss: 13989446.932\n",
      "Task 1 Epoch 33 completed. Average Loss: 13989446.932\n",
      "Epoch 34, Step 100, Loss: 13989446.96\n",
      "Epoch 34, Step 200, Loss: 13989446.95\n",
      "Evaluation Loss: 11.4347\n",
      "Epoch 34, Step 300, Loss: 13989446.94\n",
      "Epoch 34, Step 400, Loss: 13989446.94\n",
      "Evaluation Loss: 11.3293\n",
      "Epoch 34, Step 500, Loss: 13989446.944\n",
      "Task 1 Epoch 34 completed. Average Loss: 13989446.944\n",
      "Epoch 35, Step 100, Loss: 13989446.96\n",
      "Epoch 35, Step 200, Loss: 13989446.965\n",
      "Evaluation Loss: 11.3447\n",
      "Epoch 35, Step 300, Loss: 13989446.966666667\n",
      "Epoch 35, Step 400, Loss: 13989446.9675\n",
      "Evaluation Loss: 11.2801\n",
      "Epoch 35, Step 500, Loss: 13989446.96\n",
      "Task 1 Epoch 35 completed. Average Loss: 13989446.96\n",
      "Epoch 36, Step 100, Loss: 13989446.91\n",
      "Epoch 36, Step 200, Loss: 13989446.915\n",
      "Evaluation Loss: 11.4333\n",
      "Epoch 36, Step 300, Loss: 13989446.92\n",
      "Epoch 36, Step 400, Loss: 13989446.9275\n",
      "Evaluation Loss: 11.3069\n",
      "Epoch 36, Step 500, Loss: 13989446.932\n",
      "Task 1 Epoch 36 completed. Average Loss: 13989446.932\n",
      "Epoch 37, Step 100, Loss: 13989446.94\n",
      "Epoch 37, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.1145\n",
      "Epoch 37, Step 300, Loss: 13989446.933333334\n",
      "Epoch 37, Step 400, Loss: 13989446.9325\n",
      "Evaluation Loss: 11.4258\n",
      "Epoch 37, Step 500, Loss: 13989446.922\n",
      "Task 1 Epoch 37 completed. Average Loss: 13989446.922\n",
      "Epoch 38, Step 100, Loss: 13989446.91\n",
      "Epoch 38, Step 200, Loss: 13989446.915\n",
      "Evaluation Loss: 11.2229\n",
      "Epoch 38, Step 300, Loss: 13989446.93\n",
      "Epoch 38, Step 400, Loss: 13989446.93\n",
      "Evaluation Loss: 11.3592\n",
      "Epoch 38, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 38 completed. Average Loss: 13989446.94\n",
      "Epoch 39, Step 100, Loss: 13989446.93\n",
      "Epoch 39, Step 200, Loss: 13989446.91\n",
      "Evaluation Loss: 11.1073\n",
      "Epoch 39, Step 300, Loss: 13989446.92\n",
      "Epoch 39, Step 400, Loss: 13989446.9175\n",
      "Evaluation Loss: 11.5609\n",
      "Epoch 39, Step 500, Loss: 13989446.922\n",
      "Task 1 Epoch 39 completed. Average Loss: 13989446.922\n",
      "Epoch 40, Step 100, Loss: 13989446.96\n",
      "Epoch 40, Step 200, Loss: 13989446.955\n",
      "Evaluation Loss: 11.2727\n",
      "Epoch 40, Step 300, Loss: 13989446.963333333\n",
      "Epoch 40, Step 400, Loss: 13989446.9625\n",
      "Evaluation Loss: 11.4706\n",
      "Epoch 40, Step 500, Loss: 13989446.952\n",
      "Task 1 Epoch 40 completed. Average Loss: 13989446.952\n",
      "Epoch 41, Step 100, Loss: 13989446.92\n",
      "Epoch 41, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.3423\n",
      "Epoch 41, Step 300, Loss: 13989446.913333334\n",
      "Epoch 41, Step 400, Loss: 13989446.91\n",
      "Evaluation Loss: 11.1472\n",
      "Epoch 41, Step 500, Loss: 13989446.914\n",
      "Task 1 Epoch 41 completed. Average Loss: 13989446.914\n",
      "Epoch 42, Step 100, Loss: 13989446.92\n",
      "Epoch 42, Step 200, Loss: 13989446.91\n",
      "Evaluation Loss: 11.3976\n",
      "Epoch 42, Step 300, Loss: 13989446.926666666\n",
      "Epoch 42, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.2051\n",
      "Epoch 42, Step 500, Loss: 13989446.934\n",
      "Task 1 Epoch 42 completed. Average Loss: 13989446.934\n",
      "Epoch 43, Step 100, Loss: 13989446.92\n",
      "Epoch 43, Step 200, Loss: 13989446.91\n",
      "Evaluation Loss: 11.0903\n",
      "Epoch 43, Step 300, Loss: 13989446.923333334\n",
      "Epoch 43, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.1958\n",
      "Epoch 43, Step 500, Loss: 13989446.916\n",
      "Task 1 Epoch 43 completed. Average Loss: 13989446.916\n",
      "Epoch 44, Step 100, Loss: 13989446.88\n",
      "Epoch 44, Step 200, Loss: 13989446.91\n",
      "Evaluation Loss: 11.4399\n",
      "Epoch 44, Step 300, Loss: 13989446.93\n",
      "Epoch 44, Step 400, Loss: 13989446.9125\n",
      "Evaluation Loss: 11.1445\n",
      "Epoch 44, Step 500, Loss: 13989446.908\n",
      "Task 1 Epoch 44 completed. Average Loss: 13989446.908\n",
      "Epoch 45, Step 100, Loss: 13989446.92\n",
      "Epoch 45, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.4442\n",
      "Epoch 45, Step 300, Loss: 13989446.923333334\n",
      "Epoch 45, Step 400, Loss: 13989446.9325\n",
      "Evaluation Loss: 11.4248\n",
      "Epoch 45, Step 500, Loss: 13989446.924\n",
      "Task 1 Epoch 45 completed. Average Loss: 13989446.924\n",
      "Epoch 46, Step 100, Loss: 13989446.92\n",
      "Epoch 46, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.3683\n",
      "Epoch 46, Step 300, Loss: 13989446.916666666\n",
      "Epoch 46, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.3112\n",
      "Epoch 46, Step 500, Loss: 13989446.922\n",
      "Task 1 Epoch 46 completed. Average Loss: 13989446.922\n",
      "Epoch 47, Step 100, Loss: 13989446.88\n",
      "Epoch 47, Step 200, Loss: 13989446.915\n",
      "Evaluation Loss: 11.3350\n",
      "Epoch 47, Step 300, Loss: 13989446.926666666\n",
      "Epoch 47, Step 400, Loss: 13989446.935\n",
      "Evaluation Loss: 11.4893\n",
      "Epoch 47, Step 500, Loss: 13989446.938\n",
      "Task 1 Epoch 47 completed. Average Loss: 13989446.938\n",
      "Epoch 48, Step 100, Loss: 13989446.95\n",
      "Epoch 48, Step 200, Loss: 13989446.925\n",
      "Evaluation Loss: 11.3252\n",
      "Epoch 48, Step 300, Loss: 13989446.94\n",
      "Epoch 48, Step 400, Loss: 13989446.9375\n",
      "Evaluation Loss: 11.4370\n",
      "Epoch 48, Step 500, Loss: 13989446.936\n",
      "Task 1 Epoch 48 completed. Average Loss: 13989446.936\n",
      "Epoch 49, Step 100, Loss: 13989446.92\n",
      "Epoch 49, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.3640\n",
      "Epoch 49, Step 300, Loss: 13989446.926666666\n",
      "Epoch 49, Step 400, Loss: 13989446.9425\n",
      "Evaluation Loss: 11.3518\n",
      "Epoch 49, Step 500, Loss: 13989446.948\n",
      "Task 1 Epoch 49 completed. Average Loss: 13989446.948\n",
      "Epoch 50, Step 100, Loss: 13989446.94\n",
      "Epoch 50, Step 200, Loss: 13989446.935\n",
      "Evaluation Loss: 11.3221\n",
      "Epoch 50, Step 300, Loss: 13989446.936666667\n",
      "Epoch 50, Step 400, Loss: 13989446.9425\n",
      "Evaluation Loss: 11.4960\n",
      "Epoch 50, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 50 completed. Average Loss: 13989446.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL\n",
      "Epoch 51, Step 100, Loss: 13989446.91\n",
      "Epoch 51, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.2274\n",
      "Epoch 51, Step 300, Loss: 13989446.923333334\n",
      "Epoch 51, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.5068\n",
      "Epoch 51, Step 500, Loss: 13989446.926\n",
      "Task 1 Epoch 51 completed. Average Loss: 13989446.926\n",
      "Epoch 52, Step 100, Loss: 13989446.91\n",
      "Epoch 52, Step 200, Loss: 13989446.9\n",
      "Evaluation Loss: 11.4275\n",
      "Epoch 52, Step 300, Loss: 13989446.93\n",
      "Epoch 52, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.3350\n",
      "Epoch 52, Step 500, Loss: 13989446.93\n",
      "Task 1 Epoch 52 completed. Average Loss: 13989446.93\n",
      "Epoch 53, Step 100, Loss: 13989446.96\n",
      "Epoch 53, Step 200, Loss: 13989446.965\n",
      "Evaluation Loss: 11.3674\n",
      "Epoch 53, Step 300, Loss: 13989446.96\n",
      "Epoch 53, Step 400, Loss: 13989446.96\n",
      "Evaluation Loss: 11.3195\n",
      "Epoch 53, Step 500, Loss: 13989446.96\n",
      "Task 1 Epoch 53 completed. Average Loss: 13989446.96\n",
      "Epoch 54, Step 100, Loss: 13989446.91\n",
      "Epoch 54, Step 200, Loss: 13989446.935\n",
      "Evaluation Loss: 11.3934\n",
      "Epoch 54, Step 300, Loss: 13989446.94\n",
      "Epoch 54, Step 400, Loss: 13989446.94\n",
      "Evaluation Loss: 11.3555\n",
      "Epoch 54, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 54 completed. Average Loss: 13989446.94\n",
      "Epoch 55, Step 100, Loss: 13989446.91\n",
      "Epoch 55, Step 200, Loss: 13989446.89\n",
      "Evaluation Loss: 11.3308\n",
      "Epoch 55, Step 300, Loss: 13989446.92\n",
      "Epoch 55, Step 400, Loss: 13989446.9325\n",
      "Evaluation Loss: 11.4666\n",
      "Epoch 55, Step 500, Loss: 13989446.934\n",
      "Task 1 Epoch 55 completed. Average Loss: 13989446.934\n",
      "Epoch 56, Step 100, Loss: 13989446.96\n",
      "Epoch 56, Step 200, Loss: 13989446.95\n",
      "Evaluation Loss: 11.5210\n",
      "Epoch 56, Step 300, Loss: 13989446.95\n",
      "Epoch 56, Step 400, Loss: 13989446.9425\n",
      "Evaluation Loss: 11.4832\n",
      "Epoch 56, Step 500, Loss: 13989446.938\n",
      "Task 1 Epoch 56 completed. Average Loss: 13989446.938\n",
      "Epoch 57, Step 100, Loss: 13989446.92\n",
      "Epoch 57, Step 200, Loss: 13989446.925\n",
      "Evaluation Loss: 11.4737\n",
      "Epoch 57, Step 300, Loss: 13989446.926666666\n",
      "Epoch 57, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.5109\n",
      "Epoch 57, Step 500, Loss: 13989446.912\n",
      "Task 1 Epoch 57 completed. Average Loss: 13989446.912\n",
      "Epoch 58, Step 100, Loss: 13989446.99\n",
      "Epoch 58, Step 200, Loss: 13989446.94\n",
      "Evaluation Loss: 11.2828\n",
      "Epoch 58, Step 300, Loss: 13989446.936666667\n",
      "Epoch 58, Step 400, Loss: 13989446.9475\n",
      "Evaluation Loss: 11.3892\n",
      "Epoch 58, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 58 completed. Average Loss: 13989446.94\n",
      "Epoch 59, Step 100, Loss: 13989446.94\n",
      "Epoch 59, Step 200, Loss: 13989446.945\n",
      "Evaluation Loss: 11.4373\n",
      "Epoch 59, Step 300, Loss: 13989446.936666667\n",
      "Epoch 59, Step 400, Loss: 13989446.935\n",
      "Evaluation Loss: 11.3288\n",
      "Epoch 59, Step 500, Loss: 13989446.934\n",
      "Task 1 Epoch 59 completed. Average Loss: 13989446.934\n",
      "Epoch 60, Step 100, Loss: 13989446.92\n",
      "Epoch 60, Step 200, Loss: 13989446.94\n",
      "Evaluation Loss: 11.4345\n",
      "Epoch 60, Step 300, Loss: 13989446.93\n",
      "Epoch 60, Step 400, Loss: 13989446.935\n",
      "Evaluation Loss: 11.2563\n",
      "Epoch 60, Step 500, Loss: 13989446.936\n",
      "Task 1 Epoch 60 completed. Average Loss: 13989446.936\n",
      "Epoch 61, Step 100, Loss: 13989446.99\n",
      "Epoch 61, Step 200, Loss: 13989446.965\n",
      "Evaluation Loss: 11.1529\n",
      "Epoch 61, Step 300, Loss: 13989446.953333333\n",
      "Epoch 61, Step 400, Loss: 13989446.95\n",
      "Evaluation Loss: 11.4520\n",
      "Epoch 61, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 61 completed. Average Loss: 13989446.94\n",
      "Epoch 62, Step 100, Loss: 13989446.95\n",
      "Epoch 62, Step 200, Loss: 13989446.94\n",
      "Evaluation Loss: 11.3483\n",
      "Epoch 62, Step 300, Loss: 13989446.936666667\n",
      "Epoch 62, Step 400, Loss: 13989446.9375\n",
      "Evaluation Loss: 11.3605\n",
      "Epoch 62, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 62 completed. Average Loss: 13989446.94\n",
      "Epoch 63, Step 100, Loss: 13989446.99\n",
      "Epoch 63, Step 200, Loss: 13989446.985\n",
      "Evaluation Loss: 11.0908\n",
      "Epoch 63, Step 300, Loss: 13989446.976666667\n",
      "Epoch 63, Step 400, Loss: 13989446.9725\n",
      "Evaluation Loss: 11.2203\n",
      "Epoch 63, Step 500, Loss: 13989446.964\n",
      "Task 1 Epoch 63 completed. Average Loss: 13989446.964\n",
      "Epoch 64, Step 100, Loss: 13989446.96\n",
      "Epoch 64, Step 200, Loss: 13989446.96\n",
      "Evaluation Loss: 11.4751\n",
      "Epoch 64, Step 300, Loss: 13989446.94\n",
      "Epoch 64, Step 400, Loss: 13989446.9425\n",
      "Evaluation Loss: 11.4334\n",
      "Epoch 64, Step 500, Loss: 13989446.932\n",
      "Task 1 Epoch 64 completed. Average Loss: 13989446.932\n",
      "Epoch 65, Step 100, Loss: 13989446.9\n",
      "Epoch 65, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.5686\n",
      "Epoch 65, Step 300, Loss: 13989446.933333334\n",
      "Epoch 65, Step 400, Loss: 13989446.9325\n",
      "Evaluation Loss: 11.4263\n",
      "Epoch 65, Step 500, Loss: 13989446.934\n",
      "Task 1 Epoch 65 completed. Average Loss: 13989446.934\n",
      "Epoch 66, Step 100, Loss: 13989446.88\n",
      "Epoch 66, Step 200, Loss: 13989446.905\n",
      "Evaluation Loss: 11.2312\n",
      "Epoch 66, Step 300, Loss: 13989446.913333334\n",
      "Epoch 66, Step 400, Loss: 13989446.9275\n",
      "Evaluation Loss: 11.4437\n",
      "Epoch 66, Step 500, Loss: 13989446.936\n",
      "Task 1 Epoch 66 completed. Average Loss: 13989446.936\n",
      "Epoch 67, Step 100, Loss: 13989446.91\n",
      "Epoch 67, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.4020\n",
      "Epoch 67, Step 300, Loss: 13989446.923333334\n",
      "Epoch 67, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.2212\n",
      "Epoch 67, Step 500, Loss: 13989446.932\n",
      "Task 1 Epoch 67 completed. Average Loss: 13989446.932\n",
      "Epoch 68, Step 100, Loss: 13989446.93\n",
      "Epoch 68, Step 200, Loss: 13989446.945\n",
      "Evaluation Loss: 11.5662\n",
      "Epoch 68, Step 300, Loss: 13989446.95\n",
      "Epoch 68, Step 400, Loss: 13989446.945\n",
      "Evaluation Loss: 11.1901\n",
      "Epoch 68, Step 500, Loss: 13989446.944\n",
      "Task 1 Epoch 68 completed. Average Loss: 13989446.944\n",
      "Epoch 69, Step 100, Loss: 13989446.94\n",
      "Epoch 69, Step 200, Loss: 13989446.955\n",
      "Evaluation Loss: 11.3442\n",
      "Epoch 69, Step 300, Loss: 13989446.95\n",
      "Epoch 69, Step 400, Loss: 13989446.9425\n",
      "Evaluation Loss: 11.2229\n",
      "Epoch 69, Step 500, Loss: 13989446.942\n",
      "Task 1 Epoch 69 completed. Average Loss: 13989446.942\n",
      "Epoch 70, Step 100, Loss: 13989446.91\n",
      "Epoch 70, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.2776\n",
      "Epoch 70, Step 300, Loss: 13989446.92\n",
      "Epoch 70, Step 400, Loss: 13989446.935\n",
      "Evaluation Loss: 11.2342\n",
      "Epoch 70, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 70 completed. Average Loss: 13989446.94\n",
      "Epoch 71, Step 100, Loss: 13989446.94\n",
      "Epoch 71, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.4290\n",
      "Epoch 71, Step 300, Loss: 13989446.923333334\n",
      "Epoch 71, Step 400, Loss: 13989446.9325\n",
      "Evaluation Loss: 11.4160\n",
      "Epoch 71, Step 500, Loss: 13989446.924\n",
      "Task 1 Epoch 71 completed. Average Loss: 13989446.924\n",
      "Epoch 72, Step 100, Loss: 13989446.94\n",
      "Epoch 72, Step 200, Loss: 13989446.915\n",
      "Evaluation Loss: 11.4343\n",
      "Epoch 72, Step 300, Loss: 13989446.93\n",
      "Epoch 72, Step 400, Loss: 13989446.94\n",
      "Evaluation Loss: 11.4826\n",
      "Epoch 72, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 72 completed. Average Loss: 13989446.94\n",
      "Epoch 73, Step 100, Loss: 13989446.98\n",
      "Epoch 73, Step 200, Loss: 13989446.96\n",
      "Evaluation Loss: 11.1728\n",
      "Epoch 73, Step 300, Loss: 13989446.96\n",
      "Epoch 73, Step 400, Loss: 13989446.96\n",
      "Evaluation Loss: 11.3682\n",
      "Epoch 73, Step 500, Loss: 13989446.956\n",
      "Task 1 Epoch 73 completed. Average Loss: 13989446.956\n",
      "Epoch 74, Step 100, Loss: 13989446.93\n",
      "Epoch 74, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.4678\n",
      "Epoch 74, Step 300, Loss: 13989446.913333334\n",
      "Epoch 74, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.0995\n",
      "Epoch 74, Step 500, Loss: 13989446.93\n",
      "Task 1 Epoch 74 completed. Average Loss: 13989446.93\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\n",
      "Epoch 75, Step 100, Loss: 13989446.91\n",
      "Epoch 75, Step 200, Loss: 13989446.905\n",
      "Evaluation Loss: 11.3188\n",
      "Epoch 75, Step 300, Loss: 13989446.926666666\n",
      "Epoch 75, Step 400, Loss: 13989446.935\n",
      "Evaluation Loss: 11.3913\n",
      "Epoch 75, Step 500, Loss: 13989446.944\n",
      "Task 1 Epoch 75 completed. Average Loss: 13989446.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL\n",
      "Epoch 76, Step 100, Loss: 13989446.93\n",
      "Epoch 76, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.0640\n",
      "Epoch 76, Step 300, Loss: 13989446.923333334\n",
      "Epoch 76, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.3355\n",
      "Epoch 76, Step 500, Loss: 13989446.928\n",
      "Task 1 Epoch 76 completed. Average Loss: 13989446.928\n",
      "Epoch 77, Step 100, Loss: 13989446.89\n",
      "Epoch 77, Step 200, Loss: 13989446.925\n",
      "Evaluation Loss: 11.4372\n",
      "Epoch 77, Step 300, Loss: 13989446.923333334\n",
      "Epoch 77, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.3471\n",
      "Epoch 77, Step 500, Loss: 13989446.924\n",
      "Task 1 Epoch 77 completed. Average Loss: 13989446.924\n",
      "Epoch 78, Step 100, Loss: 13989446.92\n",
      "Epoch 78, Step 200, Loss: 13989446.945\n",
      "Evaluation Loss: 11.6016\n",
      "Epoch 78, Step 300, Loss: 13989446.94\n",
      "Epoch 78, Step 400, Loss: 13989446.9475\n",
      "Evaluation Loss: 11.3750\n",
      "Epoch 78, Step 500, Loss: 13989446.942\n",
      "Task 1 Epoch 78 completed. Average Loss: 13989446.942\n",
      "Epoch 79, Step 100, Loss: 13989446.96\n",
      "Epoch 79, Step 200, Loss: 13989446.935\n",
      "Evaluation Loss: 11.4294\n",
      "Epoch 79, Step 300, Loss: 13989446.93\n",
      "Epoch 79, Step 400, Loss: 13989446.9275\n",
      "Evaluation Loss: 11.3985\n",
      "Epoch 79, Step 500, Loss: 13989446.93\n",
      "Task 1 Epoch 79 completed. Average Loss: 13989446.93\n",
      "Epoch 80, Step 100, Loss: 13989446.96\n",
      "Epoch 80, Step 200, Loss: 13989446.945\n",
      "Evaluation Loss: 11.3920\n",
      "Epoch 80, Step 300, Loss: 13989446.946666667\n",
      "Epoch 80, Step 400, Loss: 13989446.945\n",
      "Evaluation Loss: 11.3580\n",
      "Epoch 80, Step 500, Loss: 13989446.946\n",
      "Task 1 Epoch 80 completed. Average Loss: 13989446.946\n",
      "Epoch 81, Step 100, Loss: 13989446.91\n",
      "Epoch 81, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.2212\n",
      "Epoch 81, Step 300, Loss: 13989446.94\n",
      "Epoch 81, Step 400, Loss: 13989446.935\n",
      "Evaluation Loss: 11.4153\n",
      "Epoch 81, Step 500, Loss: 13989446.938\n",
      "Task 1 Epoch 81 completed. Average Loss: 13989446.938\n",
      "Epoch 82, Step 100, Loss: 13989446.93\n",
      "Epoch 82, Step 200, Loss: 13989446.955\n",
      "Evaluation Loss: 11.3546\n",
      "Epoch 82, Step 300, Loss: 13989446.95\n",
      "Epoch 82, Step 400, Loss: 13989446.955\n",
      "Evaluation Loss: 11.3982\n",
      "Epoch 82, Step 500, Loss: 13989446.952\n",
      "Task 1 Epoch 82 completed. Average Loss: 13989446.952\n",
      "Epoch 83, Step 100, Loss: 13989446.93\n",
      "Epoch 83, Step 200, Loss: 13989446.935\n",
      "Evaluation Loss: 11.2962\n",
      "Epoch 83, Step 300, Loss: 13989446.933333334\n",
      "Epoch 83, Step 400, Loss: 13989446.93\n",
      "Evaluation Loss: 11.3964\n",
      "Epoch 83, Step 500, Loss: 13989446.924\n",
      "Task 1 Epoch 83 completed. Average Loss: 13989446.924\n",
      "Epoch 84, Step 100, Loss: 13989446.98\n",
      "Epoch 84, Step 200, Loss: 13989446.96\n",
      "Evaluation Loss: 11.3099\n",
      "Epoch 84, Step 300, Loss: 13989446.96\n",
      "Epoch 84, Step 400, Loss: 13989446.9625\n",
      "Evaluation Loss: 11.1754\n",
      "Epoch 84, Step 500, Loss: 13989446.95\n",
      "Task 1 Epoch 84 completed. Average Loss: 13989446.95\n",
      "Epoch 85, Step 100, Loss: 13989446.93\n",
      "Epoch 85, Step 200, Loss: 13989446.96\n",
      "Evaluation Loss: 11.4027\n",
      "Epoch 85, Step 300, Loss: 13989446.95\n",
      "Epoch 85, Step 400, Loss: 13989446.9525\n",
      "Evaluation Loss: 11.2947\n",
      "Epoch 85, Step 500, Loss: 13989446.95\n",
      "Task 1 Epoch 85 completed. Average Loss: 13989446.95\n",
      "Epoch 86, Step 100, Loss: 13989446.93\n",
      "Epoch 86, Step 200, Loss: 13989446.945\n",
      "Evaluation Loss: 11.4853\n",
      "Epoch 86, Step 300, Loss: 13989446.926666666\n",
      "Epoch 86, Step 400, Loss: 13989446.9175\n",
      "Evaluation Loss: 11.2337\n",
      "Epoch 86, Step 500, Loss: 13989446.924\n",
      "Task 1 Epoch 86 completed. Average Loss: 13989446.924\n",
      "Epoch 87, Step 100, Loss: 13989446.96\n",
      "Epoch 87, Step 200, Loss: 13989446.94\n",
      "Evaluation Loss: 11.1301\n",
      "Epoch 87, Step 300, Loss: 13989446.94\n",
      "Epoch 87, Step 400, Loss: 13989446.9275\n",
      "Evaluation Loss: 11.3255\n",
      "Epoch 87, Step 500, Loss: 13989446.934\n",
      "Task 1 Epoch 87 completed. Average Loss: 13989446.934\n",
      "Epoch 88, Step 100, Loss: 13989446.96\n",
      "Epoch 88, Step 200, Loss: 13989446.96\n",
      "Evaluation Loss: 11.2955\n",
      "Epoch 88, Step 300, Loss: 13989446.96\n",
      "Epoch 88, Step 400, Loss: 13989446.96\n",
      "Evaluation Loss: 11.4968\n",
      "Epoch 88, Step 500, Loss: 13989446.952\n",
      "Task 1 Epoch 88 completed. Average Loss: 13989446.952\n",
      "Epoch 89, Step 100, Loss: 13989446.9\n",
      "Epoch 89, Step 200, Loss: 13989446.915\n",
      "Evaluation Loss: 11.2942\n",
      "Epoch 89, Step 300, Loss: 13989446.91\n",
      "Epoch 89, Step 400, Loss: 13989446.9175\n",
      "Evaluation Loss: 11.5630\n",
      "Epoch 89, Step 500, Loss: 13989446.926\n",
      "Task 1 Epoch 89 completed. Average Loss: 13989446.926\n",
      "Epoch 90, Step 100, Loss: 13989446.97\n",
      "Epoch 90, Step 200, Loss: 13989446.95\n",
      "Evaluation Loss: 11.2858\n",
      "Epoch 90, Step 300, Loss: 13989446.95\n",
      "Epoch 90, Step 400, Loss: 13989446.945\n",
      "Evaluation Loss: 11.4715\n",
      "Epoch 90, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 90 completed. Average Loss: 13989446.94\n",
      "Epoch 91, Step 100, Loss: 13989446.93\n",
      "Epoch 91, Step 200, Loss: 13989446.955\n",
      "Evaluation Loss: 11.3091\n",
      "Epoch 91, Step 300, Loss: 13989446.943333333\n",
      "Epoch 91, Step 400, Loss: 13989446.9425\n",
      "Evaluation Loss: 11.0973\n",
      "Epoch 91, Step 500, Loss: 13989446.946\n",
      "Task 1 Epoch 91 completed. Average Loss: 13989446.946\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\n",
      "Epoch 92, Step 100, Loss: 13989446.94\n",
      "Epoch 92, Step 200, Loss: 13989446.925\n",
      "Evaluation Loss: 11.2317\n",
      "Epoch 92, Step 300, Loss: 13989446.93\n",
      "Epoch 92, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.4170\n",
      "Epoch 92, Step 500, Loss: 13989446.936\n",
      "Task 1 Epoch 92 completed. Average Loss: 13989446.936\n",
      "Epoch 93, Step 100, Loss: 13989446.91\n",
      "Epoch 93, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.0879\n",
      "Epoch 93, Step 300, Loss: 13989446.923333334\n",
      "Epoch 93, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.2189\n",
      "Epoch 93, Step 500, Loss: 13989446.932\n",
      "Task 1 Epoch 93 completed. Average Loss: 13989446.932\n",
      "Epoch 94, Step 100, Loss: 13989446.93\n",
      "Epoch 94, Step 200, Loss: 13989446.905\n",
      "Evaluation Loss: 11.4675\n",
      "Epoch 94, Step 300, Loss: 13989446.913333334\n",
      "Epoch 94, Step 400, Loss: 13989446.9225\n",
      "Evaluation Loss: 11.2875\n",
      "Epoch 94, Step 500, Loss: 13989446.918\n",
      "Task 1 Epoch 94 completed. Average Loss: 13989446.918\n",
      "Epoch 95, Step 100, Loss: 13989446.87\n",
      "Epoch 95, Step 200, Loss: 13989446.92\n",
      "Evaluation Loss: 11.3938\n",
      "Epoch 95, Step 300, Loss: 13989446.913333334\n",
      "Epoch 95, Step 400, Loss: 13989446.91\n",
      "Evaluation Loss: 11.3769\n",
      "Epoch 95, Step 500, Loss: 13989446.92\n",
      "Task 1 Epoch 95 completed. Average Loss: 13989446.92\n",
      "Epoch 96, Step 100, Loss: 13989446.92\n",
      "Epoch 96, Step 200, Loss: 13989446.93\n",
      "Evaluation Loss: 11.3511\n",
      "Epoch 96, Step 300, Loss: 13989446.926666666\n",
      "Epoch 96, Step 400, Loss: 13989446.9275\n",
      "Evaluation Loss: 11.3217\n",
      "Epoch 96, Step 500, Loss: 13989446.93\n",
      "Task 1 Epoch 96 completed. Average Loss: 13989446.93\n",
      "Epoch 97, Step 100, Loss: 13989446.97\n",
      "Epoch 97, Step 200, Loss: 13989446.94\n",
      "Evaluation Loss: 11.3988\n",
      "Epoch 97, Step 300, Loss: 13989446.936666667\n",
      "Epoch 97, Step 400, Loss: 13989446.9325\n",
      "Evaluation Loss: 11.5093\n",
      "Epoch 97, Step 500, Loss: 13989446.944\n",
      "Task 1 Epoch 97 completed. Average Loss: 13989446.944\n",
      "Epoch 98, Step 100, Loss: 13989446.93\n",
      "Epoch 98, Step 200, Loss: 13989446.935\n",
      "Evaluation Loss: 10.9878\n",
      "Epoch 98, Step 300, Loss: 13989446.936666667\n",
      "Epoch 98, Step 400, Loss: 13989446.94\n",
      "Evaluation Loss: 11.1982\n",
      "Epoch 98, Step 500, Loss: 13989446.94\n",
      "Task 1 Epoch 98 completed. Average Loss: 13989446.94\n",
      "Epoch 99, Step 100, Loss: 13989446.9\n",
      "Epoch 99, Step 200, Loss: 13989446.895\n",
      "Evaluation Loss: 11.2556\n",
      "Epoch 99, Step 300, Loss: 13989446.906666666\n",
      "Epoch 99, Step 400, Loss: 13989446.9125\n",
      "Evaluation Loss: 11.4953\n",
      "Epoch 99, Step 500, Loss: 13989446.922\n",
      "Task 1 Epoch 99 completed. Average Loss: 13989446.922\n",
      "Epoch 100, Step 100, Loss: 13989446.93\n",
      "Epoch 100, Step 200, Loss: 13989446.935\n",
      "Evaluation Loss: 11.2981\n",
      "Epoch 100, Step 300, Loss: 13989446.94\n",
      "Epoch 100, Step 400, Loss: 13989446.925\n",
      "Evaluation Loss: 11.3812\n",
      "Epoch 100, Step 500, Loss: 13989446.934\n",
      "Task 1 Epoch 100 completed. Average Loss: 13989446.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-Correct-Task1_VCL\n",
      "Epoch 101, Step 100, Loss: 13989446.99\n",
      "Epoch 101, Step 200, Loss: 13989446.97\n",
      "Evaluation Loss: 11.4774\n",
      "Epoch 101, Step 300, Loss: 13989446.97\n",
      "Epoch 101, Step 400, Loss: 13989446.9675\n",
      "Evaluation Loss: 11.2302\n",
      "Epoch 101, Step 500, Loss: 13989446.964\n",
      "Task 1 Epoch 101 completed. Average Loss: 13989446.964\n",
      "Epoch 102, Step 100, Loss: 13989446.96\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTORCH_CUDA_ALLOC_CONF\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpandable_segments:True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mrun_lora_evcl_1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# learning_rate=1e-5,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinetuned-weights-LoRA-EVCL-Correct-Task1_VCL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_pyro\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 212\u001b[0m, in \u001b[0;36mrun_lora_evcl_1\u001b[0;34m(train_loader, eval_loader, num_epochs, model, batch_size, learning_rate, logging_steps, eval_steps, save_steps, output_dir, load_pyro, best_output_dir)\u001b[0m\n\u001b[1;32m    173\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# if epoch==0 and num_batches==1:\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#     generated_ids = model.generate(\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m#     input_ids=input_ids,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# with open(f\"/home/pranav24/cs-546-project/Testing/predictions_EVCL_1_{num_batches}.json\", \"w\") as json_file:\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m#     json.dump(data, json_file, indent=4)\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m    215\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m)\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide_trace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_particle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurrogate_loss_particle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_differentiable_loss_particle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide_trace\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_particle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_particles\u001b[49m\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/pyro/infer/elbo.py:237\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles):\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/pyro/infer/trace_mean_field_elbo.py:82\u001b[0m, in \u001b[0;36mTraceMeanField_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[0;32m---> 82\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     84\u001b[0m         _check_mean_field_requirement(model_trace, guide_trace)\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mget_importance_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/pyro/infer/enum.py:75\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     72\u001b[0m guide_trace \u001b[38;5;241m=\u001b[39m prune_subsample_sites(guide_trace)\n\u001b[1;32m     73\u001b[0m model_trace \u001b[38;5;241m=\u001b[39m prune_subsample_sites(model_trace)\n\u001b[0;32m---> 75\u001b[0m \u001b[43mmodel_trace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m guide_trace\u001b[38;5;241m.\u001b[39mcompute_score_parts()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/pyro/poutine/trace_struct.py:264\u001b[0m, in \u001b[0;36mTrace.compute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m site:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         log_p \u001b[38;5;241m=\u001b[39m \u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    268\u001b[0m         _, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/torch/distributions/independent.py:110\u001b[0m, in \u001b[0;36mIndependent.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m--> 110\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _sum_rightmost(log_prob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreinterpreted_batch_ndims)\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/torch/distributions/normal.py:84\u001b[0m, in \u001b[0;36mNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# compute the variance\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     85\u001b[0m log_scale \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     86\u001b[0m     math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, Real) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\u001b[38;5;241m.\u001b[39mlog()\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;241m-\u001b[39m((value \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m var)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;241m-\u001b[39m log_scale\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;241m-\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi))\n\u001b[1;32m     92\u001b[0m )\n",
      "File \u001b[0;32m~/cs-546-project/venv/lib/python3.11/site-packages/torch/_tensor.py:33\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(f):\n\u001b[1;32m     31\u001b[0m     assigned \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model=run_lora_evcl_1(\n",
    "        train_loader=train_loader,\n",
    "        eval_loader=eval_loader,\n",
    "        num_epochs=200,\n",
    "        model=model,\n",
    "        batch_size=4,\n",
    "        # learning_rate=1e-5,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=100,\n",
    "        eval_steps=200,\n",
    "        save_steps=500,\n",
    "        output_dir=\"finetuned-weights-LoRA-EVCL-Correct-Task1_VCL\",\n",
    "        load_pyro=False,\n",
    "        best_output_dir=\"finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b71b305b-97d7-4077-9ee0-9ee0d3476805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "eval_loss_per_epoch=[]\n",
    "for i in range(0,len(evaluation_loss),2):\n",
    "    eval_loss_per_epoch.append(max(evaluation_loss[i],evaluation_loss[i+1]))\n",
    "\n",
    "print(len(eval_loss_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b052af5-75af-4cb8-b5f6-bb6bf5d6bb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 2))  \n",
    "plt.plot(eval_loss_per_epoch, marker='o', linestyle='-', color='b', label='Evaluation Loss')\n",
    "\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Loss Log Likelihood')\n",
    "plt.title('Validation Loss over training')\n",
    "\n",
    "plt.xlim(-1, len(eval_loss_per_epoch))\n",
    "plt.ylim(10, 12)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64aee245-7e13-4698-8b75-7d72f09421c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav24/cs-546-project/venv/lib/python3.11/site-packages/pyro/params/param_store.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(input_file, map_location)\n",
      "Unused kwargs: ['device_map', 'offload_folder', 'offload_state_dict']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b996d8bfa44800ad9714b421688d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling,BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import PeftConfig, PeftModel\n",
    "from accelerate import init_empty_weights\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "from peft.tuners.lora import LoraLayer\n",
    "from pyro.nn.module import to_pyro_module_\n",
    "import bitsandbytes\n",
    "\n",
    "os.chdir(r'/home/pranav24/cs-546-project')\n",
    "pyro.get_param_store().load('pyro_param_store_task1_evcl_best.pt')\n",
    "login(\"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\")\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "base_model_repo_id = \"meta-llama/Meta-Llama-3-8B\"  \n",
    "adapter_model_dir = r\"/home/pranav24/cs-546-project/finetuned-weights-LoRA-EVCL-Correct-Task1_VCL_best\"\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  \n",
    "    device_map=\"auto\",  \n",
    "    offload_folder=\"offload\",  \n",
    "    offload_state_dict=True,  \n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_repo_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_repo_id,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16, \n",
    ")\n",
    "# model.config.reduction = \"mean\" \n",
    "\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(adapter_model_dir)\n",
    "model = PeftModel.from_pretrained(model, adapter_model_dir, config=peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602a70a2-af6d-4078-98bf-473da225ec18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4891f08-2d31-43d5-9231-a0c14332831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,033,669,120 || trainable%: 0.0424\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f3a69c3-3a02-4521-a882-a55b1fcca627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/1\n",
      "Processing batch 1\n",
      "Completed batch 1\n",
      "Processing batch 2\n",
      "Completed batch 2\n",
      "Processing batch 3\n",
      "Completed batch 3\n",
      "Processing batch 4\n",
      "Completed batch 4\n",
      "Processing batch 5\n",
      "Completed batch 5\n",
      "Processing batch 6\n",
      "Completed batch 6\n",
      "Processing batch 7\n",
      "Completed batch 7\n",
      "Processing batch 8\n",
      "Completed batch 8\n",
      "Processing batch 9\n",
      "Completed batch 9\n",
      "Processing batch 10\n",
      "Completed batch 10\n",
      "Processing batch 11\n",
      "Completed batch 11\n",
      "Processing batch 12\n",
      "Completed batch 12\n",
      "Processing batch 13\n",
      "Completed batch 13\n",
      "Processing batch 14\n",
      "Completed batch 14\n",
      "Processing batch 15\n",
      "Completed batch 15\n",
      "Processing batch 16\n",
      "Completed batch 16\n",
      "Processing batch 17\n",
      "Completed batch 17\n",
      "Processing batch 18\n",
      "Completed batch 18\n",
      "Processing batch 19\n",
      "Completed batch 19\n",
      "Processing batch 20\n",
      "Completed batch 20\n",
      "Processing batch 21\n",
      "Completed batch 21\n",
      "Processing batch 22\n",
      "Completed batch 22\n",
      "Processing batch 23\n",
      "Completed batch 23\n",
      "Processing batch 24\n",
      "Completed batch 24\n",
      "Processing batch 25\n",
      "Completed batch 25\n",
      "Processing batch 26\n",
      "Completed batch 26\n",
      "Processing batch 27\n",
      "Completed batch 27\n",
      "Processing batch 28\n",
      "Completed batch 28\n",
      "Processing batch 29\n",
      "Completed batch 29\n",
      "Processing batch 30\n",
      "Completed batch 30\n",
      "Processing batch 31\n",
      "Completed batch 31\n",
      "Processing batch 32\n",
      "Completed batch 32\n",
      "Processing batch 33\n",
      "Completed batch 33\n",
      "Processing batch 34\n",
      "Completed batch 34\n",
      "Processing batch 35\n",
      "Completed batch 35\n",
      "Processing batch 36\n",
      "Completed batch 36\n",
      "Processing batch 37\n",
      "Completed batch 37\n",
      "Processing batch 38\n",
      "Completed batch 38\n",
      "Processing batch 39\n",
      "Completed batch 39\n",
      "Processing batch 40\n",
      "Completed batch 40\n",
      "Processing batch 41\n",
      "Completed batch 41\n",
      "Processing batch 42\n",
      "Completed batch 42\n",
      "Processing batch 43\n",
      "Completed batch 43\n",
      "Processing batch 44\n",
      "Completed batch 44\n",
      "Processing batch 45\n",
      "Completed batch 45\n",
      "Processing batch 46\n",
      "Completed batch 46\n",
      "Processing batch 47\n",
      "Completed batch 47\n",
      "Processing batch 48\n",
      "Completed batch 48\n",
      "Processing batch 49\n",
      "Completed batch 49\n",
      "Processing batch 50\n",
      "Completed batch 50\n",
      "Processing batch 51\n",
      "Completed batch 51\n",
      "Processing batch 52\n",
      "Completed batch 52\n",
      "Processing batch 53\n",
      "Completed batch 53\n",
      "Processing batch 54\n",
      "Completed batch 54\n",
      "Processing batch 55\n",
      "Completed batch 55\n",
      "Processing batch 56\n",
      "Completed batch 56\n",
      "Processing batch 57\n",
      "Completed batch 57\n",
      "Processing batch 58\n",
      "Completed batch 58\n",
      "Processing batch 59\n",
      "Completed batch 59\n",
      "Processing batch 60\n",
      "Completed batch 60\n",
      "Processing batch 61\n",
      "Completed batch 61\n",
      "Processing batch 62\n",
      "Completed batch 62\n",
      "Processing batch 63\n",
      "Completed batch 63\n",
      "Processing batch 64\n",
      "Completed batch 64\n",
      "Processing batch 65\n",
      "Completed batch 65\n",
      "Processing batch 66\n",
      "Completed batch 66\n",
      "Processing batch 67\n",
      "Completed batch 67\n",
      "Processing batch 68\n",
      "Completed batch 68\n",
      "Processing batch 69\n",
      "Completed batch 69\n",
      "Processing batch 70\n",
      "Completed batch 70\n",
      "Processing batch 71\n",
      "Completed batch 71\n",
      "Processing batch 72\n",
      "Completed batch 72\n",
      "Processing batch 73\n",
      "Completed batch 73\n",
      "Processing batch 74\n",
      "Completed batch 74\n",
      "Processing batch 75\n",
      "Completed batch 75\n",
      "Processing batch 76\n",
      "Completed batch 76\n",
      "Processing batch 77\n",
      "Completed batch 77\n",
      "Processing batch 78\n",
      "Completed batch 78\n",
      "Processing batch 79\n",
      "Completed batch 79\n",
      "Processing batch 80\n",
      "Completed batch 80\n",
      "Processing batch 81\n",
      "Completed batch 81\n",
      "Processing batch 82\n",
      "Completed batch 82\n",
      "Processing batch 83\n",
      "Completed batch 83\n",
      "Processing batch 84\n",
      "Completed batch 84\n",
      "Processing batch 85\n",
      "Completed batch 85\n",
      "Processing batch 86\n",
      "Completed batch 86\n",
      "Processing batch 87\n",
      "Completed batch 87\n",
      "Processing batch 88\n",
      "Completed batch 88\n",
      "Processing batch 89\n",
      "Completed batch 89\n",
      "Processing batch 90\n",
      "Completed batch 90\n",
      "Processing batch 91\n",
      "Completed batch 91\n",
      "Processing batch 92\n",
      "Completed batch 92\n",
      "Processing batch 93\n",
      "Completed batch 93\n",
      "Processing batch 94\n",
      "Completed batch 94\n",
      "Processing batch 95\n",
      "Completed batch 95\n",
      "Processing batch 96\n",
      "Completed batch 96\n",
      "Processing batch 97\n",
      "Completed batch 97\n",
      "Processing batch 98\n",
      "Completed batch 98\n",
      "Processing batch 99\n",
      "Completed batch 99\n",
      "Processing batch 100\n",
      "Completed batch 100\n",
      "Processing batch 101\n",
      "Completed batch 101\n",
      "Processing batch 102\n",
      "Completed batch 102\n",
      "Processing batch 103\n",
      "Completed batch 103\n",
      "Processing batch 104\n",
      "Completed batch 104\n",
      "Processing batch 105\n",
      "Completed batch 105\n",
      "Processing batch 106\n",
      "Completed batch 106\n",
      "Processing batch 107\n",
      "Completed batch 107\n",
      "Processing batch 108\n",
      "Completed batch 108\n",
      "Processing batch 109\n",
      "Completed batch 109\n",
      "Processing batch 110\n",
      "Completed batch 110\n",
      "Processing batch 111\n",
      "Completed batch 111\n",
      "Processing batch 112\n",
      "Completed batch 112\n",
      "Processing batch 113\n",
      "Completed batch 113\n",
      "Processing batch 114\n",
      "Completed batch 114\n",
      "Processing batch 115\n",
      "Completed batch 115\n",
      "Processing batch 116\n",
      "Completed batch 116\n",
      "Processing batch 117\n",
      "Completed batch 117\n",
      "Processing batch 118\n",
      "Completed batch 118\n",
      "Processing batch 119\n",
      "Completed batch 119\n",
      "Processing batch 120\n",
      "Completed batch 120\n",
      "Processing batch 121\n",
      "Completed batch 121\n",
      "Processing batch 122\n",
      "Completed batch 122\n",
      "Processing batch 123\n",
      "Completed batch 123\n",
      "Processing batch 124\n",
      "Completed batch 124\n",
      "Processing batch 125\n",
      "Completed batch 125\n",
      "Processing batch 126\n",
      "Completed batch 126\n",
      "Processing batch 127\n",
      "Completed batch 127\n",
      "Processing batch 128\n",
      "Completed batch 128\n",
      "Processing batch 129\n",
      "Completed batch 129\n",
      "Processing batch 130\n",
      "Completed batch 130\n",
      "Processing batch 131\n",
      "Completed batch 131\n",
      "Processing batch 132\n",
      "Completed batch 132\n",
      "Processing batch 133\n",
      "Completed batch 133\n",
      "Processing batch 134\n",
      "Completed batch 134\n",
      "Processing batch 135\n",
      "Completed batch 135\n",
      "Processing batch 136\n",
      "Completed batch 136\n",
      "Processing batch 137\n",
      "Completed batch 137\n",
      "Processing batch 138\n",
      "Completed batch 138\n",
      "Processing batch 139\n",
      "Completed batch 139\n",
      "Processing batch 140\n",
      "Completed batch 140\n",
      "Processing batch 141\n",
      "Completed batch 141\n",
      "Processing batch 142\n",
      "Completed batch 142\n",
      "Processing batch 143\n",
      "Completed batch 143\n",
      "Processing batch 144\n",
      "Completed batch 144\n",
      "Processing batch 145\n",
      "Completed batch 145\n",
      "Processing batch 146\n",
      "Completed batch 146\n",
      "Processing batch 147\n",
      "Completed batch 147\n",
      "Processing batch 148\n",
      "Completed batch 148\n",
      "Processing batch 149\n",
      "Completed batch 149\n",
      "Processing batch 150\n",
      "Completed batch 150\n",
      "Processing batch 151\n",
      "Completed batch 151\n",
      "Processing batch 152\n",
      "Completed batch 152\n",
      "Processing batch 153\n",
      "Completed batch 153\n",
      "Processing batch 154\n",
      "Completed batch 154\n",
      "Processing batch 155\n",
      "Completed batch 155\n",
      "Processing batch 156\n",
      "Completed batch 156\n",
      "Processing batch 157\n",
      "Completed batch 157\n",
      "Processing batch 158\n",
      "Completed batch 158\n",
      "Processing batch 159\n",
      "Completed batch 159\n",
      "Processing batch 160\n",
      "Completed batch 160\n",
      "Processing batch 161\n",
      "Completed batch 161\n",
      "Processing batch 162\n",
      "Completed batch 162\n",
      "Processing batch 163\n",
      "Completed batch 163\n",
      "Processing batch 164\n",
      "Completed batch 164\n",
      "Processing batch 165\n",
      "Completed batch 165\n",
      "Processing batch 166\n",
      "Completed batch 166\n",
      "Processing batch 167\n",
      "Completed batch 167\n",
      "Processing batch 168\n",
      "Completed batch 168\n",
      "Processing batch 169\n",
      "Completed batch 169\n",
      "Processing batch 170\n",
      "Completed batch 170\n",
      "Processing batch 171\n",
      "Completed batch 171\n",
      "Processing batch 172\n",
      "Completed batch 172\n",
      "Processing batch 173\n",
      "Completed batch 173\n",
      "Processing batch 174\n",
      "Completed batch 174\n",
      "Processing batch 175\n",
      "Completed batch 175\n",
      "Processing batch 176\n",
      "Completed batch 176\n",
      "Processing batch 177\n",
      "Completed batch 177\n",
      "Processing batch 178\n",
      "Completed batch 178\n",
      "Processing batch 179\n",
      "Completed batch 179\n",
      "Processing batch 180\n",
      "Completed batch 180\n",
      "Processing batch 181\n",
      "Completed batch 181\n",
      "Processing batch 182\n",
      "Completed batch 182\n",
      "Processing batch 183\n",
      "Completed batch 183\n",
      "Processing batch 184\n",
      "Completed batch 184\n",
      "Processing batch 185\n",
      "Completed batch 185\n",
      "Processing batch 186\n",
      "Completed batch 186\n",
      "Processing batch 187\n",
      "Completed batch 187\n",
      "Processing batch 188\n",
      "Completed batch 188\n",
      "Processing batch 189\n",
      "Completed batch 189\n",
      "Processing batch 190\n",
      "Completed batch 190\n",
      "Processing batch 191\n",
      "Completed batch 191\n",
      "Processing batch 192\n",
      "Completed batch 192\n",
      "Processing batch 193\n",
      "Completed batch 193\n",
      "Processing batch 194\n",
      "Completed batch 194\n",
      "Processing batch 195\n",
      "Completed batch 195\n",
      "Processing batch 196\n",
      "Completed batch 196\n",
      "Processing batch 197\n",
      "Completed batch 197\n",
      "Processing batch 198\n",
      "Completed batch 198\n",
      "Processing batch 199\n",
      "Completed batch 199\n",
      "Processing batch 200\n",
      "Completed batch 200\n",
      "Processing batch 201\n",
      "Completed batch 201\n",
      "Processing batch 202\n",
      "Completed batch 202\n",
      "Processing batch 203\n",
      "Completed batch 203\n",
      "Processing batch 204\n",
      "Completed batch 204\n",
      "Processing batch 205\n",
      "Completed batch 205\n",
      "Processing batch 206\n",
      "Completed batch 206\n",
      "Processing batch 207\n",
      "Completed batch 207\n",
      "Processing batch 208\n",
      "Completed batch 208\n",
      "Processing batch 209\n",
      "Completed batch 209\n",
      "Processing batch 210\n",
      "Completed batch 210\n",
      "Processing batch 211\n",
      "Completed batch 211\n",
      "Processing batch 212\n",
      "Completed batch 212\n",
      "Processing batch 213\n",
      "Completed batch 213\n",
      "Processing batch 214\n",
      "Completed batch 214\n",
      "Processing batch 215\n",
      "Completed batch 215\n",
      "Processing batch 216\n",
      "Completed batch 216\n",
      "Processing batch 217\n",
      "Completed batch 217\n",
      "Processing batch 218\n",
      "Completed batch 218\n",
      "Processing batch 219\n",
      "Completed batch 219\n",
      "Processing batch 220\n",
      "Completed batch 220\n",
      "Processing batch 221\n",
      "Completed batch 221\n",
      "Processing batch 222\n",
      "Completed batch 222\n",
      "Processing batch 223\n",
      "Completed batch 223\n",
      "Processing batch 224\n",
      "Completed batch 224\n",
      "Processing batch 225\n",
      "Completed batch 225\n",
      "Processing batch 226\n",
      "Completed batch 226\n",
      "Processing batch 227\n",
      "Completed batch 227\n",
      "Processing batch 228\n",
      "Completed batch 228\n",
      "Processing batch 229\n",
      "Completed batch 229\n",
      "Processing batch 230\n",
      "Completed batch 230\n",
      "Processing batch 231\n",
      "Completed batch 231\n",
      "Processing batch 232\n",
      "Completed batch 232\n",
      "Processing batch 233\n",
      "Completed batch 233\n",
      "Processing batch 234\n",
      "Completed batch 234\n",
      "Processing batch 235\n",
      "Completed batch 235\n",
      "Processing batch 236\n",
      "Completed batch 236\n",
      "Processing batch 237\n",
      "Completed batch 237\n",
      "Processing batch 238\n",
      "Completed batch 238\n",
      "Processing batch 239\n",
      "Completed batch 239\n",
      "Processing batch 240\n",
      "Completed batch 240\n",
      "Processing batch 241\n",
      "Completed batch 241\n",
      "Processing batch 242\n",
      "Completed batch 242\n",
      "Processing batch 243\n",
      "Completed batch 243\n",
      "Processing batch 244\n",
      "Completed batch 244\n",
      "Processing batch 245\n",
      "Completed batch 245\n",
      "Processing batch 246\n",
      "Completed batch 246\n",
      "Processing batch 247\n",
      "Completed batch 247\n",
      "Processing batch 248\n",
      "Completed batch 248\n",
      "Processing batch 249\n",
      "Completed batch 249\n",
      "Processing batch 250\n",
      "Completed batch 250\n",
      "Processing batch 251\n",
      "Completed batch 251\n",
      "Processing batch 252\n",
      "Completed batch 252\n",
      "Processing batch 253\n",
      "Completed batch 253\n",
      "Processing batch 254\n",
      "Completed batch 254\n",
      "Processing batch 255\n",
      "Completed batch 255\n",
      "Processing batch 256\n",
      "Completed batch 256\n",
      "Processing batch 257\n",
      "Completed batch 257\n",
      "Processing batch 258\n",
      "Completed batch 258\n",
      "Processing batch 259\n",
      "Completed batch 259\n",
      "Processing batch 260\n",
      "Completed batch 260\n",
      "Processing batch 261\n",
      "Completed batch 261\n",
      "Processing batch 262\n",
      "Completed batch 262\n",
      "Processing batch 263\n",
      "Completed batch 263\n",
      "Processing batch 264\n",
      "Completed batch 264\n",
      "Processing batch 265\n",
      "Completed batch 265\n",
      "Processing batch 266\n",
      "Completed batch 266\n",
      "Processing batch 267\n",
      "Completed batch 267\n",
      "Processing batch 268\n",
      "Completed batch 268\n",
      "Processing batch 269\n",
      "Completed batch 269\n",
      "Processing batch 270\n",
      "Completed batch 270\n",
      "Processing batch 271\n",
      "Completed batch 271\n",
      "Processing batch 272\n",
      "Completed batch 272\n",
      "Processing batch 273\n",
      "Completed batch 273\n",
      "Processing batch 274\n",
      "Completed batch 274\n",
      "Processing batch 275\n",
      "Completed batch 275\n",
      "Processing batch 276\n",
      "Completed batch 276\n",
      "Processing batch 277\n",
      "Completed batch 277\n",
      "Processing batch 278\n",
      "Completed batch 278\n",
      "Processing batch 279\n",
      "Completed batch 279\n",
      "Processing batch 280\n",
      "Completed batch 280\n",
      "Processing batch 281\n",
      "Completed batch 281\n",
      "Processing batch 282\n",
      "Completed batch 282\n",
      "Processing batch 283\n",
      "Completed batch 283\n",
      "Processing batch 284\n",
      "Completed batch 284\n",
      "Processing batch 285\n",
      "Completed batch 285\n",
      "Processing batch 286\n",
      "Completed batch 286\n",
      "Processing batch 287\n",
      "Completed batch 287\n",
      "Processing batch 288\n",
      "Completed batch 288\n",
      "Processing batch 289\n",
      "Completed batch 289\n",
      "Processing batch 290\n",
      "Completed batch 290\n",
      "Processing batch 291\n",
      "Completed batch 291\n",
      "Processing batch 292\n",
      "Completed batch 292\n",
      "Processing batch 293\n",
      "Completed batch 293\n",
      "Processing batch 294\n",
      "Completed batch 294\n",
      "Processing batch 295\n",
      "Completed batch 295\n",
      "Processing batch 296\n",
      "Completed batch 296\n",
      "Processing batch 297\n",
      "Completed batch 297\n",
      "Processing batch 298\n",
      "Completed batch 298\n",
      "Processing batch 299\n",
      "Completed batch 299\n",
      "Processing batch 300\n",
      "Completed batch 300\n",
      "Processing batch 301\n",
      "Completed batch 301\n",
      "Processing batch 302\n",
      "Completed batch 302\n",
      "Processing batch 303\n",
      "Completed batch 303\n",
      "Processing batch 304\n",
      "Completed batch 304\n",
      "Processing batch 305\n",
      "Completed batch 305\n",
      "Processing batch 306\n",
      "Completed batch 306\n",
      "Processing batch 307\n",
      "Completed batch 307\n",
      "Processing batch 308\n",
      "Completed batch 308\n",
      "Processing batch 309\n",
      "Completed batch 309\n",
      "Processing batch 310\n",
      "Completed batch 310\n",
      "Processing batch 311\n",
      "Completed batch 311\n",
      "Processing batch 312\n",
      "Completed batch 312\n",
      "Processing batch 313\n",
      "Completed batch 313\n",
      "Processing batch 314\n",
      "Completed batch 314\n",
      "Processing batch 315\n",
      "Completed batch 315\n",
      "Processing batch 316\n",
      "Completed batch 316\n",
      "Processing batch 317\n",
      "Completed batch 317\n",
      "Processing batch 318\n",
      "Completed batch 318\n",
      "Processing batch 319\n",
      "Completed batch 319\n",
      "Processing batch 320\n",
      "Completed batch 320\n",
      "Processing batch 321\n",
      "Completed batch 321\n",
      "Processing batch 322\n",
      "Completed batch 322\n",
      "Processing batch 323\n",
      "Completed batch 323\n",
      "Processing batch 324\n",
      "Completed batch 324\n",
      "Processing batch 325\n",
      "Completed batch 325\n",
      "Processing batch 326\n",
      "Completed batch 326\n",
      "Processing batch 327\n",
      "Completed batch 327\n",
      "Processing batch 328\n",
      "Completed batch 328\n",
      "Processing batch 329\n",
      "Completed batch 329\n",
      "Processing batch 330\n",
      "Completed batch 330\n",
      "Processing batch 331\n",
      "Completed batch 331\n",
      "Processing batch 332\n",
      "Completed batch 332\n",
      "Processing batch 333\n",
      "Completed batch 333\n",
      "Processing batch 334\n",
      "Completed batch 334\n",
      "Processing batch 335\n",
      "Completed batch 335\n",
      "Processing batch 336\n",
      "Completed batch 336\n",
      "Processing batch 337\n",
      "Completed batch 337\n",
      "Processing batch 338\n",
      "Completed batch 338\n",
      "Processing batch 339\n",
      "Completed batch 339\n",
      "Processing batch 340\n",
      "Completed batch 340\n",
      "Processing batch 341\n",
      "Completed batch 341\n",
      "Processing batch 342\n",
      "Completed batch 342\n",
      "Processing batch 343\n",
      "Completed batch 343\n",
      "Processing batch 344\n",
      "Completed batch 344\n",
      "Processing batch 345\n",
      "Completed batch 345\n",
      "Processing batch 346\n",
      "Completed batch 346\n",
      "Processing batch 347\n",
      "Completed batch 347\n",
      "Processing batch 348\n",
      "Completed batch 348\n",
      "Processing batch 349\n",
      "Completed batch 349\n",
      "Processing batch 350\n",
      "Completed batch 350\n",
      "Processing batch 351\n",
      "Completed batch 351\n",
      "Processing batch 352\n",
      "Completed batch 352\n",
      "Processing batch 353\n",
      "Completed batch 353\n",
      "Processing batch 354\n",
      "Completed batch 354\n",
      "Processing batch 355\n",
      "Completed batch 355\n",
      "Processing batch 356\n",
      "Completed batch 356\n",
      "Processing batch 357\n",
      "Completed batch 357\n",
      "Processing batch 358\n",
      "Completed batch 358\n",
      "Processing batch 359\n",
      "Completed batch 359\n",
      "Processing batch 360\n",
      "Completed batch 360\n",
      "Processing batch 361\n",
      "Completed batch 361\n",
      "Processing batch 362\n",
      "Completed batch 362\n",
      "Processing batch 363\n",
      "Completed batch 363\n",
      "Processing batch 364\n",
      "Completed batch 364\n",
      "Processing batch 365\n",
      "Completed batch 365\n",
      "Processing batch 366\n",
      "Completed batch 366\n",
      "Processing batch 367\n",
      "Completed batch 367\n",
      "Processing batch 368\n",
      "Completed batch 368\n",
      "Processing batch 369\n",
      "Completed batch 369\n",
      "Processing batch 370\n",
      "Completed batch 370\n",
      "Processing batch 371\n",
      "Completed batch 371\n",
      "Processing batch 372\n",
      "Completed batch 372\n",
      "Processing batch 373\n",
      "Completed batch 373\n",
      "Processing batch 374\n",
      "Completed batch 374\n",
      "Processing batch 375\n",
      "Completed batch 375\n",
      "Processing batch 376\n",
      "Completed batch 376\n",
      "Processing batch 377\n",
      "Completed batch 377\n",
      "Processing batch 378\n",
      "Completed batch 378\n",
      "Processing batch 379\n",
      "Completed batch 379\n",
      "Processing batch 380\n",
      "Completed batch 380\n",
      "Processing batch 381\n",
      "Completed batch 381\n",
      "Processing batch 382\n",
      "Completed batch 382\n",
      "Processing batch 383\n",
      "Completed batch 383\n",
      "Processing batch 384\n",
      "Completed batch 384\n",
      "Processing batch 385\n",
      "Completed batch 385\n",
      "Processing batch 386\n",
      "Completed batch 386\n",
      "Processing batch 387\n",
      "Completed batch 387\n",
      "Processing batch 388\n",
      "Completed batch 388\n",
      "Processing batch 389\n",
      "Completed batch 389\n",
      "Processing batch 390\n",
      "Completed batch 390\n",
      "Processing batch 391\n",
      "Completed batch 391\n",
      "Processing batch 392\n",
      "Completed batch 392\n",
      "Processing batch 393\n",
      "Completed batch 393\n",
      "Processing batch 394\n",
      "Completed batch 394\n",
      "Processing batch 395\n",
      "Completed batch 395\n",
      "Processing batch 396\n",
      "Completed batch 396\n",
      "Processing batch 397\n",
      "Completed batch 397\n",
      "Processing batch 398\n",
      "Completed batch 398\n",
      "Processing batch 399\n",
      "Completed batch 399\n",
      "Processing batch 400\n",
      "Completed batch 400\n",
      "Processing batch 401\n",
      "Completed batch 401\n",
      "Processing batch 402\n",
      "Completed batch 402\n",
      "Processing batch 403\n",
      "Completed batch 403\n",
      "Processing batch 404\n",
      "Completed batch 404\n",
      "Processing batch 405\n",
      "Completed batch 405\n",
      "Processing batch 406\n",
      "Completed batch 406\n",
      "Processing batch 407\n",
      "Completed batch 407\n",
      "Processing batch 408\n",
      "Completed batch 408\n",
      "Processing batch 409\n",
      "Completed batch 409\n",
      "Processing batch 410\n",
      "Completed batch 410\n",
      "Processing batch 411\n",
      "Completed batch 411\n",
      "Processing batch 412\n",
      "Completed batch 412\n",
      "Processing batch 413\n",
      "Completed batch 413\n",
      "Processing batch 414\n",
      "Completed batch 414\n",
      "Processing batch 415\n",
      "Completed batch 415\n",
      "Processing batch 416\n",
      "Completed batch 416\n",
      "Processing batch 417\n",
      "Completed batch 417\n",
      "Processing batch 418\n",
      "Completed batch 418\n",
      "Processing batch 419\n",
      "Completed batch 419\n",
      "Processing batch 420\n",
      "Completed batch 420\n",
      "Processing batch 421\n",
      "Completed batch 421\n",
      "Processing batch 422\n",
      "Completed batch 422\n",
      "Processing batch 423\n",
      "Completed batch 423\n",
      "Processing batch 424\n",
      "Completed batch 424\n",
      "Processing batch 425\n",
      "Completed batch 425\n",
      "Processing batch 426\n",
      "Completed batch 426\n",
      "Processing batch 427\n",
      "Completed batch 427\n",
      "Processing batch 428\n",
      "Completed batch 428\n",
      "Processing batch 429\n",
      "Completed batch 429\n",
      "Processing batch 430\n",
      "Completed batch 430\n",
      "Processing batch 431\n",
      "Completed batch 431\n",
      "Processing batch 432\n",
      "Completed batch 432\n",
      "Processing batch 433\n",
      "Completed batch 433\n",
      "Processing batch 434\n",
      "Completed batch 434\n",
      "Processing batch 435\n",
      "Completed batch 435\n",
      "Processing batch 436\n",
      "Completed batch 436\n",
      "Processing batch 437\n",
      "Completed batch 437\n",
      "Processing batch 438\n",
      "Completed batch 438\n",
      "Processing batch 439\n",
      "Completed batch 439\n",
      "Processing batch 440\n",
      "Completed batch 440\n",
      "Processing batch 441\n",
      "Completed batch 441\n",
      "Processing batch 442\n",
      "Completed batch 442\n",
      "Processing batch 443\n",
      "Completed batch 443\n",
      "Processing batch 444\n",
      "Completed batch 444\n",
      "Processing batch 445\n",
      "Completed batch 445\n",
      "Processing batch 446\n",
      "Completed batch 446\n",
      "Processing batch 447\n",
      "Completed batch 447\n",
      "Processing batch 448\n",
      "Completed batch 448\n",
      "Processing batch 449\n",
      "Completed batch 449\n",
      "Processing batch 450\n",
      "Completed batch 450\n",
      "Processing batch 451\n",
      "Completed batch 451\n",
      "Processing batch 452\n",
      "Completed batch 452\n",
      "Processing batch 453\n",
      "Completed batch 453\n",
      "Processing batch 454\n",
      "Completed batch 454\n",
      "Processing batch 455\n",
      "Completed batch 455\n",
      "Processing batch 456\n",
      "Completed batch 456\n",
      "Processing batch 457\n",
      "Completed batch 457\n",
      "Processing batch 458\n",
      "Completed batch 458\n",
      "Processing batch 459\n",
      "Completed batch 459\n",
      "Processing batch 460\n",
      "Completed batch 460\n",
      "Processing batch 461\n",
      "Completed batch 461\n",
      "Processing batch 462\n",
      "Completed batch 462\n",
      "Processing batch 463\n",
      "Completed batch 463\n",
      "Processing batch 464\n",
      "Completed batch 464\n",
      "Processing batch 465\n",
      "Completed batch 465\n",
      "Processing batch 466\n",
      "Completed batch 466\n",
      "Processing batch 467\n",
      "Completed batch 467\n",
      "Processing batch 468\n",
      "Completed batch 468\n",
      "Processing batch 469\n",
      "Completed batch 469\n",
      "Processing batch 470\n",
      "Completed batch 470\n",
      "Processing batch 471\n",
      "Completed batch 471\n",
      "Processing batch 472\n",
      "Completed batch 472\n",
      "Processing batch 473\n",
      "Completed batch 473\n",
      "Processing batch 474\n",
      "Completed batch 474\n",
      "Processing batch 475\n",
      "Completed batch 475\n",
      "Processing batch 476\n",
      "Completed batch 476\n",
      "Processing batch 477\n",
      "Completed batch 477\n",
      "Processing batch 478\n",
      "Completed batch 478\n",
      "Processing batch 479\n",
      "Completed batch 479\n",
      "Processing batch 480\n",
      "Completed batch 480\n",
      "Processing batch 481\n",
      "Completed batch 481\n",
      "Processing batch 482\n",
      "Completed batch 482\n",
      "Processing batch 483\n",
      "Completed batch 483\n",
      "Processing batch 484\n",
      "Completed batch 484\n",
      "Processing batch 485\n",
      "Completed batch 485\n",
      "Processing batch 486\n",
      "Completed batch 486\n",
      "Processing batch 487\n",
      "Completed batch 487\n",
      "Processing batch 488\n",
      "Completed batch 488\n",
      "Processing batch 489\n",
      "Completed batch 489\n",
      "Processing batch 490\n",
      "Completed batch 490\n",
      "Processing batch 491\n",
      "Completed batch 491\n",
      "Processing batch 492\n",
      "Completed batch 492\n",
      "Processing batch 493\n",
      "Completed batch 493\n",
      "Processing batch 494\n",
      "Completed batch 494\n",
      "Processing batch 495\n",
      "Completed batch 495\n",
      "Processing batch 496\n",
      "Completed batch 496\n",
      "Processing batch 497\n",
      "Completed batch 497\n",
      "Processing batch 498\n",
      "Completed batch 498\n",
      "Processing batch 499\n",
      "Completed batch 499\n",
      "Processing batch 500\n",
      "Completed batch 500\n"
     ]
    }
   ],
   "source": [
    "# from torch.amp import autocast, GradScaler\n",
    "# prev_fisher_info = None\n",
    "# prev_params = None\n",
    "# ewc_gamma = 1.0  \n",
    "\n",
    "# fisher_info = compute_fisher_info(\n",
    "#     model=model,\n",
    "#     data_loader=train_loader,\n",
    "#     prev_fisher_info=prev_fisher_info,\n",
    "#     ewc_gamma=ewc_gamma,\n",
    "#     num_epochs=1,  \n",
    "#     head_modules=None,  \n",
    "#     n_samples=None  \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb848a4b-e88c-4417-a87b-ce963878e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher Information saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#save current fisher info\n",
    "\n",
    "# import pickle\n",
    "# os.chdir('/home/pranav24/cs-546-project/')\n",
    "# with open('fisher_info_task1_best.pkl', 'wb') as f:\n",
    "#     pickle.dump(fisher_info, f)\n",
    "# print(\"Fisher Information saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf70e2a-5795-483a-b114-7b454c7d500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher Information loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "os.chdir('/home/pranav24/cs-546-project/')\n",
    "with open('fisher_info_task1_best.pkl', 'rb') as f:\n",
    "    fisher_info = pickle.load(f)\n",
    "print(\"Fisher Information loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e157fa-3d0a-4f37-a264-8c6ada0f30aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 5.2602637879317626e-05\n",
      "Layer: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 3.435642793192528e-05\n",
      "Layer: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.04396664723753929\n",
      "Layer: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 1.9068093299865723\n",
      "Layer: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.7165422832476906e-05\n",
      "Layer: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 3.820039637503214e-05\n",
      "Layer: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.0005724492366425693\n",
      "Layer: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.2568419575691223\n",
      "Layer: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.402235466230195e-05\n",
      "Layer: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00013161636888980865\n",
      "Layer: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00010108761489391327\n",
      "Layer: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.12677480280399323\n",
      "Layer: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 2.9668181014130823e-05\n",
      "Layer: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0003394090454094112\n",
      "Layer: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00013337233394850045\n",
      "Layer: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.1445675492286682\n",
      "Layer: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.6391640605870634e-05\n",
      "Layer: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005467276787385345\n",
      "Layer: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 7.884720980655402e-05\n",
      "Layer: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.12014411389827728\n",
      "Layer: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 6.617981125600636e-05\n",
      "Layer: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0002627118956297636\n",
      "Layer: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 6.65149709675461e-05\n",
      "Layer: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.16440832614898682\n",
      "Layer: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.742496483027935e-05\n",
      "Layer: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0006248564459383488\n",
      "Layer: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 4.9782320274971426e-05\n",
      "Layer: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.06834998726844788\n",
      "Layer: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 2.8815993573516607e-05\n",
      "Layer: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0004500213253777474\n",
      "Layer: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 8.342734508914873e-05\n",
      "Layer: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.08146370947360992\n",
      "Layer: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.737130878609605e-05\n",
      "Layer: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0001391813566442579\n",
      "Layer: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.6135152438655496e-05\n",
      "Layer: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.04369479417800903\n",
      "Layer: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.3299277270562015e-05\n",
      "Layer: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005417980719357729\n",
      "Layer: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 1.9183513359166682e-05\n",
      "Layer: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.03391145169734955\n",
      "Layer: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.272634057793766e-05\n",
      "Layer: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0004986814456060529\n",
      "Layer: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 1.80044153239578e-05\n",
      "Layer: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.08629052340984344\n",
      "Layer: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.12437150569167e-05\n",
      "Layer: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00025994109455496073\n",
      "Layer: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.8841335733886808e-05\n",
      "Layer: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.03757312148809433\n",
      "Layer: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.446139231120469e-05\n",
      "Layer: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00047852686839178205\n",
      "Layer: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 3.14475764753297e-05\n",
      "Layer: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.0837591290473938\n",
      "Layer: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 7.3209348556702025e-06\n",
      "Layer: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00018971582176163793\n",
      "Layer: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 1.0630872566252947e-05\n",
      "Layer: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.019279077649116516\n",
      "Layer: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.00011360496864654124\n",
      "Layer: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005517672980204225\n",
      "Layer: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 1.9704237274709158e-05\n",
      "Layer: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.043767791241407394\n",
      "Layer: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 6.680411024717614e-05\n",
      "Layer: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0003156451275572181\n",
      "Layer: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.817550557665527e-05\n",
      "Layer: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.09443880617618561\n",
      "Layer: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 4.40934527432546e-05\n",
      "Layer: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005201292806304991\n",
      "Layer: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.5703959181555547e-05\n",
      "Layer: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.030790193006396294\n",
      "Layer: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 8.474288733850699e-06\n",
      "Layer: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 2.9873091989429668e-05\n",
      "Layer: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 1.7092381312977523e-05\n",
      "Layer: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.06998402625322342\n",
      "Layer: base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.0004281359142623842\n",
      "Layer: base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.000718986033461988\n",
      "Layer: base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 3.33222487824969e-05\n",
      "Layer: base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.05546592175960541\n",
      "Layer: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 4.9505069910082966e-05\n",
      "Layer: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005041267722845078\n",
      "Layer: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 9.7485157311894e-05\n",
      "Layer: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.08594177663326263\n",
      "Layer: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 2.453555862302892e-05\n",
      "Layer: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00037591258296743035\n",
      "Layer: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 4.456274109543301e-05\n",
      "Layer: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.04761599749326706\n",
      "Layer: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.00014035419735591859\n",
      "Layer: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0008528227335773408\n",
      "Layer: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 1.2133815289416816e-05\n",
      "Layer: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.05065009370446205\n",
      "Layer: base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 2.8585389372892678e-05\n",
      "Layer: base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005206127534620464\n",
      "Layer: base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.0001310479419771582\n",
      "Layer: base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.03362802416086197\n",
      "Layer: base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 2.3925109417177737e-05\n",
      "Layer: base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0003847568586934358\n",
      "Layer: base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 8.767530744080432e-06\n",
      "Layer: base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.07013078033924103\n",
      "Layer: base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 7.815221761120483e-05\n",
      "Layer: base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0019330382347106934\n",
      "Layer: base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00021929963259026408\n",
      "Layer: base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.1827009916305542\n",
      "Layer: base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 2.3688040528213605e-05\n",
      "Layer: base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00036636937875300646\n",
      "Layer: base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00015135211287997663\n",
      "Layer: base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.07746286690235138\n",
      "Layer: base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.00012269079161342233\n",
      "Layer: base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00037084572250023484\n",
      "Layer: base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 3.286997161922045e-05\n",
      "Layer: base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.11894119530916214\n",
      "Layer: base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.0002767316182143986\n",
      "Layer: base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.001964121824130416\n",
      "Layer: base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 9.556302393320948e-05\n",
      "Layer: base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.22539173066616058\n",
      "Layer: base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 7.634907888132147e-06\n",
      "Layer: base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00029388911207206547\n",
      "Layer: base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 1.0243139513477217e-05\n",
      "Layer: base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.02245541661977768\n",
      "Layer: base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 6.597012543352321e-05\n",
      "Layer: base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0009491955861449242\n",
      "Layer: base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 6.0846301494166255e-05\n",
      "Layer: base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.06203172355890274\n",
      "Layer: base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 4.8520287236897275e-05\n",
      "Layer: base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005638765869662166\n",
      "Layer: base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 5.7721837947610766e-05\n",
      "Layer: base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.2702930271625519\n",
      "Layer: base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 4.38556817243807e-05\n",
      "Layer: base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0010734604438766837\n",
      "Layer: base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00014735173317603767\n",
      "Layer: base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.0436253622174263\n"
     ]
    }
   ],
   "source": [
    "for name, fisher_matrix in fisher_info.items():\n",
    "    print(f\"Layer: {name}, Fisher Info Mean: {fisher_matrix.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aedf2ad5-9045-4dd3-8250-b791e69e4e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for name, fisher_matrix in fisher_info_check.items():\n",
    "#     print(f\"Layer: {name}, Fisher Info Mean: {fisher_matrix.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d1b4cfa-ef40-47e7-9f88-1940c51e0c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prev_posterior_means = get_variational_posterior_means(model)\n",
    "# torch.save(prev_posterior_means, f'posterior_means_task_1_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb386a2b-56f0-4528-85ac-8161cc0e75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2493/3975504450.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prev_posterior_means = torch.load('posterior_means_task_1_best.pt')\n"
     ]
    }
   ],
   "source": [
    "prev_posterior_means = torch.load('posterior_means_task_1_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b1f5b03-41b0-4de3-8abf-17ab3765144c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0085,  0.0045,  0.0056,  ..., -0.0119, -0.0097, -0.0023],\n",
       "         [ 0.0048,  0.0048,  0.0031,  ..., -0.0147,  0.0005, -0.0037],\n",
       "         [-0.0054,  0.0068,  0.0114,  ..., -0.0055,  0.0119, -0.0177],\n",
       "         ...,\n",
       "         [-0.0124,  0.0091, -0.0005,  ...,  0.0059,  0.0076, -0.0081],\n",
       "         [-0.0143, -0.0166,  0.0034,  ...,  0.0073,  0.0097, -0.0081],\n",
       "         [-0.0076,  0.0034, -0.0077,  ..., -0.0069, -0.0010, -0.0079]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight': tensor([[-1.9633e-03, -8.7712e-04,  1.5151e-04,  ...,  8.0726e-04,\n",
       "           2.1566e-03, -6.1660e-04],\n",
       "         [-2.2402e-03, -2.6897e-03, -4.5189e-05,  ..., -1.0763e-03,\n",
       "           4.3999e-03, -1.3992e-03],\n",
       "         [-1.4060e-03, -3.1387e-03, -1.3020e-03,  ..., -8.3927e-04,\n",
       "           4.3674e-03,  4.3649e-04],\n",
       "         ...,\n",
       "         [-1.6337e-02,  1.4413e-02, -1.5060e-02,  ..., -1.5436e-02,\n",
       "          -1.5063e-02, -1.6546e-02],\n",
       "         [-1.5885e-02,  1.4334e-02, -1.4579e-02,  ..., -1.5379e-02,\n",
       "          -1.4976e-02, -1.6507e-02],\n",
       "         [-1.6789e-02,  1.4857e-02, -1.5123e-02,  ..., -1.5873e-02,\n",
       "          -1.5923e-02, -1.6964e-02]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0012, -0.0024,  0.0036,  ..., -0.0018,  0.0051,  0.0214],\n",
       "         [-0.0073, -0.0097, -0.0055,  ...,  0.0108, -0.0040, -0.0013],\n",
       "         [-0.0074,  0.0206,  0.0094,  ..., -0.0117,  0.0038, -0.0054],\n",
       "         ...,\n",
       "         [ 0.0095,  0.0162,  0.0116,  ...,  0.0043,  0.0066, -0.0091],\n",
       "         [-0.0004,  0.0037, -0.0086,  ..., -0.0126,  0.0098,  0.0106],\n",
       "         [-0.0069, -0.0132, -0.0009,  ...,  0.0076,  0.0128, -0.0094]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0060,  0.0072, -0.0010,  ..., -0.0033,  0.0072, -0.0055],\n",
       "         [-0.0066,  0.0022,  0.0020,  ...,  0.0011,  0.0016, -0.0052],\n",
       "         [-0.0032,  0.0061, -0.0033,  ...,  0.0032,  0.0049, -0.0020],\n",
       "         ...,\n",
       "         [ 0.0004,  0.0051, -0.0059,  ..., -0.0091,  0.0052, -0.0011],\n",
       "         [ 0.0015, -0.0007, -0.0003,  ..., -0.0024, -0.0008,  0.0009],\n",
       "         [ 0.0009, -0.0042,  0.0061,  ...,  0.0097, -0.0040,  0.0026]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0134,  0.0002, -0.0122,  ...,  0.0177, -0.0124,  0.0095],\n",
       "         [ 0.0017,  0.0054,  0.0041,  ...,  0.0096,  0.0133, -0.0098],\n",
       "         [-0.0117,  0.0102, -0.0064,  ..., -0.0206,  0.0093,  0.0097],\n",
       "         ...,\n",
       "         [ 0.0058, -0.0088, -0.0050,  ..., -0.0034, -0.0144, -0.0111],\n",
       "         [ 0.0003, -0.0101, -0.0018,  ..., -0.0205, -0.0064, -0.0053],\n",
       "         [-0.0019, -0.0063, -0.0059,  ...,  0.0035,  0.0120, -0.0180]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight': tensor([[ 1.0599e-03, -1.8515e-03,  2.2963e-03,  ...,  4.5197e-03,\n",
       "          -3.6071e-04, -3.5991e-05],\n",
       "         [-6.5064e-04, -1.8439e-03,  7.7540e-04,  ..., -2.6066e-07,\n",
       "          -4.7813e-04,  1.2574e-03],\n",
       "         [ 2.0145e-03, -2.5960e-03,  1.6599e-03,  ...,  4.2348e-03,\n",
       "          -1.2765e-03,  1.2089e-03],\n",
       "         ...,\n",
       "         [-3.0486e-03, -3.8272e-03, -8.6108e-04,  ..., -8.4469e-04,\n",
       "          -2.3157e-03, -8.3714e-04],\n",
       "         [-2.9867e-03, -2.5176e-03, -1.7839e-04,  ..., -2.2117e-03,\n",
       "           1.0677e-03, -4.0835e-04],\n",
       "         [ 4.3807e-04, -4.9454e-03, -1.8990e-03,  ...,  8.1418e-04,\n",
       "          -1.7983e-03,  2.4240e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight': tensor([[-6.4593e-03,  6.5254e-03,  1.6549e-02,  ...,  1.5125e-02,\n",
       "           6.2093e-03,  1.4088e-02],\n",
       "         [ 2.2100e-03, -1.0658e-02, -5.3665e-03,  ...,  8.4618e-03,\n",
       "          -8.3814e-03, -2.3526e-04],\n",
       "         [ 1.0874e-02,  1.0061e-02,  8.4061e-03,  ...,  3.9630e-03,\n",
       "           4.0879e-03,  1.7180e-03],\n",
       "         ...,\n",
       "         [-1.7429e-02, -5.0532e-03, -8.0878e-04,  ...,  1.2539e-02,\n",
       "           6.4512e-04,  1.3678e-03],\n",
       "         [ 4.0164e-03, -7.8767e-05,  9.5169e-03,  ...,  6.3285e-03,\n",
       "          -1.3828e-02, -6.6231e-04],\n",
       "         [ 5.4118e-03,  4.0195e-03, -8.9301e-03,  ...,  1.1408e-02,\n",
       "           1.2341e-02,  6.6810e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight': tensor([[ 1.8004e-03, -1.6913e-03,  2.1259e-03,  ..., -2.9936e-03,\n",
       "          -1.6057e-03, -2.8629e-03],\n",
       "         [-1.7106e-03, -4.9012e-03, -2.3264e-03,  ...,  5.1923e-05,\n",
       "          -2.1806e-03, -1.8872e-05],\n",
       "         [ 1.1369e-03, -2.9000e-03, -1.5969e-03,  ..., -1.5604e-03,\n",
       "          -3.9073e-03, -1.4901e-03],\n",
       "         ...,\n",
       "         [-2.9958e-03, -2.9351e-04, -2.8272e-03,  ...,  3.1109e-03,\n",
       "          -1.1253e-03,  2.9547e-03],\n",
       "         [ 3.9320e-03, -8.3239e-04,  1.6577e-03,  ..., -2.2358e-03,\n",
       "           4.5138e-03, -7.4888e-04],\n",
       "         [-8.8756e-04, -3.7297e-03, -9.3871e-04,  ..., -5.0856e-04,\n",
       "          -1.0815e-03,  9.6203e-04]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0136,  0.0055, -0.0176,  ...,  0.0095,  0.0109,  0.0087],\n",
       "         [-0.0065, -0.0013, -0.0009,  ..., -0.0048,  0.0108,  0.0143],\n",
       "         [-0.0045, -0.0016, -0.0037,  ...,  0.0066, -0.0015, -0.0067],\n",
       "         ...,\n",
       "         [-0.0003, -0.0132,  0.0109,  ..., -0.0077, -0.0009,  0.0057],\n",
       "         [ 0.0104, -0.0072, -0.0093,  ..., -0.0029, -0.0104,  0.0008],\n",
       "         [ 0.0014,  0.0099,  0.0025,  ..., -0.0036,  0.0081,  0.0014]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight': tensor([[ 5.6325e-03,  4.6311e-03,  2.1405e-04,  ...,  5.3463e-03,\n",
       "          -4.9653e-04, -3.3381e-03],\n",
       "         [ 6.4705e-03,  5.0862e-03,  2.7439e-03,  ...,  3.8875e-03,\n",
       "          -3.7874e-03, -3.2238e-03],\n",
       "         [ 3.0614e-03,  2.8787e-03,  1.3773e-03,  ...,  3.5978e-03,\n",
       "          -2.2746e-05, -3.3130e-03],\n",
       "         ...,\n",
       "         [ 5.3647e-04,  1.2708e-03,  7.2933e-04,  ...,  3.7654e-03,\n",
       "           5.8324e-04,  4.2776e-03],\n",
       "         [-4.5615e-03, -3.1725e-03, -2.2146e-03,  ...,  5.5769e-04,\n",
       "           8.9912e-04,  8.0612e-04],\n",
       "         [ 1.9432e-03,  1.8227e-03,  1.9379e-03,  ...,  8.0713e-04,\n",
       "           1.5983e-03,  1.0519e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight': tensor([[ 7.0509e-03, -1.5571e-02,  1.0522e-02,  ..., -1.9358e-02,\n",
       "           6.7136e-03,  1.8638e-02],\n",
       "         [-8.1571e-03,  9.1080e-03,  1.4654e-02,  ..., -1.5827e-02,\n",
       "           8.4242e-03, -2.9260e-03],\n",
       "         [ 1.2830e-02,  1.6991e-02,  1.7682e-02,  ..., -3.8635e-03,\n",
       "          -1.5142e-02, -1.9762e-02],\n",
       "         ...,\n",
       "         [-8.2373e-05,  9.0620e-04,  6.3927e-03,  ...,  2.1478e-02,\n",
       "           1.6189e-02, -1.3477e-02],\n",
       "         [-1.2054e-04, -1.3087e-03, -6.6858e-03,  ..., -1.7931e-02,\n",
       "           6.1591e-03,  1.9378e-02],\n",
       "         [ 9.7525e-05, -6.0594e-03,  1.4175e-02,  ...,  1.1426e-02,\n",
       "          -1.1643e-02, -1.0376e-02]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight': tensor([[-1.4427e-03,  2.9921e-03,  3.7131e-03,  ..., -2.1125e-03,\n",
       "          -4.5178e-03,  4.9004e-03],\n",
       "         [ 3.1528e-04, -1.0560e-03, -3.9761e-04,  ..., -6.6589e-04,\n",
       "           2.1002e-04,  7.3511e-04],\n",
       "         [ 2.1167e-03,  6.7431e-05, -9.7652e-04,  ..., -1.6561e-03,\n",
       "           1.0659e-03,  7.1843e-04],\n",
       "         ...,\n",
       "         [-1.2072e-03, -7.8002e-04,  1.1772e-03,  ...,  1.2373e-03,\n",
       "          -1.0072e-03,  7.4871e-04],\n",
       "         [-2.0380e-03, -3.4285e-03, -1.7186e-03,  ...,  3.3064e-03,\n",
       "           2.0071e-03, -6.7385e-04],\n",
       "         [ 1.4450e-03,  2.5820e-03,  2.1441e-03,  ..., -2.2822e-03,\n",
       "          -1.6361e-03,  1.7410e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0124, -0.0101,  0.0023,  ...,  0.0118,  0.0024,  0.0122],\n",
       "         [ 0.0127, -0.0042, -0.0123,  ...,  0.0110, -0.0075,  0.0023],\n",
       "         [-0.0063, -0.0093,  0.0139,  ...,  0.0096,  0.0086,  0.0014],\n",
       "         ...,\n",
       "         [-0.0110,  0.0034, -0.0058,  ...,  0.0072, -0.0140,  0.0034],\n",
       "         [-0.0119, -0.0033, -0.0142,  ...,  0.0043,  0.0019, -0.0054],\n",
       "         [ 0.0025, -0.0050, -0.0092,  ...,  0.0050,  0.0032,  0.0026]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight': tensor([[-3.8265e-03,  2.7725e-03, -2.6186e-03,  ..., -3.3353e-04,\n",
       "           3.9709e-03, -2.4433e-04],\n",
       "         [-2.9553e-03, -1.3549e-03, -1.9840e-03,  ...,  1.8099e-03,\n",
       "           1.0728e-03, -2.8620e-03],\n",
       "         [-6.5846e-04,  4.4363e-04,  1.5212e-03,  ...,  9.1625e-04,\n",
       "          -1.3751e-03,  5.6469e-05],\n",
       "         ...,\n",
       "         [ 6.2232e-03, -3.7835e-03,  7.2364e-05,  ..., -6.5101e-03,\n",
       "          -5.8516e-03,  5.4932e-03],\n",
       "         [ 1.3332e-03,  1.7810e-03,  4.1899e-03,  ..., -3.1252e-03,\n",
       "          -3.2934e-03,  4.7092e-03],\n",
       "         [-1.8426e-03,  3.4815e-03,  6.1104e-04,  ...,  4.3731e-03,\n",
       "           5.6157e-03, -5.1788e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight': tensor([[ 7.8333e-03, -2.4139e-03,  1.0028e-02,  ...,  1.9906e-02,\n",
       "           3.2342e-03,  1.2736e-02],\n",
       "         [-4.3410e-03, -9.3623e-03,  1.7136e-03,  ...,  6.9935e-03,\n",
       "          -1.7064e-02, -9.5858e-03],\n",
       "         [ 6.6904e-04, -1.5808e-03,  2.7677e-03,  ..., -1.1684e-03,\n",
       "           1.5244e-02, -2.1106e-03],\n",
       "         ...,\n",
       "         [ 4.0786e-03,  8.1133e-03, -6.7410e-03,  ..., -6.7898e-03,\n",
       "           7.7683e-03,  4.8865e-03],\n",
       "         [-2.6423e-03,  1.2781e-02, -6.0479e-03,  ..., -1.4757e-02,\n",
       "          -2.4962e-03,  1.8248e-02],\n",
       "         [ 9.4508e-03, -8.1359e-03,  2.0129e-03,  ...,  3.9993e-03,\n",
       "           1.1407e-02, -6.5976e-05]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0055, -0.0016,  0.0028,  ..., -0.0037,  0.0008,  0.0031],\n",
       "         [-0.0021,  0.0047,  0.0018,  ..., -0.0036,  0.0055, -0.0038],\n",
       "         [ 0.0014, -0.0010, -0.0002,  ..., -0.0007, -0.0008,  0.0021],\n",
       "         ...,\n",
       "         [ 0.0071, -0.0029,  0.0061,  ..., -0.0055,  0.0037,  0.0016],\n",
       "         [-0.0034,  0.0016, -0.0011,  ..., -0.0007,  0.0025,  0.0001],\n",
       "         [ 0.0004,  0.0010,  0.0018,  ..., -0.0012,  0.0014, -0.0015]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0158,  0.0150, -0.0063,  ...,  0.0120, -0.0108, -0.0144],\n",
       "         [ 0.0008,  0.0090, -0.0135,  ..., -0.0109, -0.0015,  0.0138],\n",
       "         [ 0.0053, -0.0045,  0.0006,  ..., -0.0023,  0.0076,  0.0008],\n",
       "         ...,\n",
       "         [-0.0070,  0.0115, -0.0128,  ..., -0.0005,  0.0141, -0.0152],\n",
       "         [ 0.0102,  0.0047,  0.0101,  ..., -0.0109, -0.0069,  0.0145],\n",
       "         [ 0.0038,  0.0047, -0.0072,  ..., -0.0022,  0.0096,  0.0055]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0020, -0.0027, -0.0007,  ..., -0.0022,  0.0003, -0.0028],\n",
       "         [-0.0029,  0.0019,  0.0036,  ...,  0.0050, -0.0028,  0.0049],\n",
       "         [-0.0028,  0.0042,  0.0027,  ...,  0.0018, -0.0017,  0.0045],\n",
       "         ...,\n",
       "         [ 0.0035,  0.0023, -0.0021,  ..., -0.0024,  0.0022, -0.0025],\n",
       "         [ 0.0032,  0.0027, -0.0022,  ..., -0.0028,  0.0030, -0.0014],\n",
       "         [ 0.0040,  0.0006, -0.0018,  ..., -0.0035,  0.0038, -0.0027]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0087, -0.0083, -0.0052,  ...,  0.0006,  0.0117, -0.0077],\n",
       "         [ 0.0105,  0.0042,  0.0033,  ..., -0.0049, -0.0049,  0.0111],\n",
       "         [-0.0173, -0.0157, -0.0049,  ...,  0.0135, -0.0113,  0.0094],\n",
       "         ...,\n",
       "         [ 0.0055, -0.0094, -0.0098,  ...,  0.0083, -0.0161,  0.0140],\n",
       "         [ 0.0064, -0.0127, -0.0034,  ...,  0.0099,  0.0071,  0.0101],\n",
       "         [-0.0016, -0.0191, -0.0068,  ...,  0.0033, -0.0091, -0.0147]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0007, -0.0021,  0.0044,  ...,  0.0008,  0.0040,  0.0016],\n",
       "         [ 0.0032,  0.0020, -0.0022,  ...,  0.0008, -0.0030,  0.0005],\n",
       "         [ 0.0040,  0.0040,  0.0032,  ...,  0.0039,  0.0029,  0.0036],\n",
       "         ...,\n",
       "         [ 0.0012,  0.0055, -0.0031,  ...,  0.0022, -0.0043,  0.0021],\n",
       "         [-0.0054, -0.0012, -0.0037,  ..., -0.0056, -0.0036, -0.0049],\n",
       "         [ 0.0028, -0.0009,  0.0019,  ...,  0.0027,  0.0019,  0.0022]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight': tensor([[ 1.2992e-02, -2.1435e-03,  1.5653e-03,  ...,  6.7999e-03,\n",
       "          -1.2285e-02, -1.1501e-03],\n",
       "         [ 1.1512e-03, -1.6979e-02, -9.8010e-03,  ...,  6.4858e-03,\n",
       "           5.6593e-03, -7.1369e-03],\n",
       "         [-2.1983e-03, -2.8032e-03,  4.1682e-03,  ...,  7.9253e-03,\n",
       "           3.3589e-03,  1.2200e-02],\n",
       "         ...,\n",
       "         [ 1.6879e-02,  1.3305e-02,  1.8333e-02,  ...,  1.1918e-02,\n",
       "           5.6372e-03,  5.4155e-03],\n",
       "         [-2.4273e-04, -7.8940e-05, -2.0889e-02,  ...,  1.1056e-02,\n",
       "          -1.3960e-02,  1.0859e-02],\n",
       "         [-7.7120e-03,  4.2085e-03, -1.8511e-02,  ...,  8.3395e-03,\n",
       "           2.3242e-03,  1.0219e-02]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight': tensor([[-2.6672e-03, -8.1399e-05,  1.6918e-03,  ..., -1.7845e-03,\n",
       "           2.4355e-03,  1.9214e-03],\n",
       "         [-2.8149e-04,  1.3303e-03,  2.5472e-03,  ..., -2.3201e-05,\n",
       "           1.1035e-03,  4.4706e-04],\n",
       "         [ 1.9881e-03,  1.1606e-03,  4.2105e-04,  ...,  8.4359e-05,\n",
       "          -2.0496e-03,  5.1676e-04],\n",
       "         ...,\n",
       "         [-3.9891e-04, -3.1718e-03,  1.9909e-03,  ..., -2.0165e-03,\n",
       "          -1.8224e-03,  1.7124e-03],\n",
       "         [-1.6999e-03,  1.6973e-03, -1.1810e-03,  ..., -5.8054e-04,\n",
       "           6.1748e-03, -2.7925e-04],\n",
       "         [-1.1131e-03, -4.9461e-03,  2.2078e-03,  ...,  1.7444e-03,\n",
       "          -4.9366e-03, -1.6012e-04]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0167, -0.0090,  0.0010,  ..., -0.0029, -0.0133, -0.0090],\n",
       "         [-0.0037, -0.0024, -0.0167,  ...,  0.0084, -0.0062,  0.0151],\n",
       "         [-0.0010, -0.0019,  0.0067,  ...,  0.0041,  0.0084, -0.0130],\n",
       "         ...,\n",
       "         [-0.0011,  0.0080,  0.0003,  ..., -0.0023, -0.0019,  0.0036],\n",
       "         [ 0.0087, -0.0027,  0.0103,  ..., -0.0050, -0.0055,  0.0063],\n",
       "         [ 0.0016, -0.0116,  0.0035,  ...,  0.0159, -0.0048,  0.0139]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight': tensor([[-7.9279e-04, -1.1632e-03,  1.4968e-03,  ..., -2.5311e-03,\n",
       "           1.7126e-03, -8.8132e-05],\n",
       "         [-5.6763e-04,  5.2239e-04, -1.1510e-03,  ..., -1.6223e-03,\n",
       "          -2.9086e-05, -6.1298e-06],\n",
       "         [ 2.4378e-03,  2.8262e-03, -3.3800e-03,  ...,  4.5250e-03,\n",
       "          -6.8108e-04, -3.4338e-03],\n",
       "         ...,\n",
       "         [ 4.0857e-03,  4.3962e-03, -4.2393e-03,  ...,  3.4514e-03,\n",
       "          -3.6637e-03,  2.0190e-04],\n",
       "         [-3.7033e-03, -5.6129e-03,  5.3368e-03,  ..., -3.4914e-03,\n",
       "           4.4449e-03, -4.1594e-04],\n",
       "         [ 1.1414e-03, -6.2485e-04, -5.0051e-04,  ..., -4.1953e-04,\n",
       "          -1.1102e-03,  1.1004e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0144,  0.0006, -0.0139,  ..., -0.0060, -0.0073, -0.0094],\n",
       "         [-0.0052,  0.0052, -0.0046,  ..., -0.0153, -0.0146,  0.0021],\n",
       "         [ 0.0044,  0.0108, -0.0188,  ..., -0.0054,  0.0132, -0.0089],\n",
       "         ...,\n",
       "         [ 0.0021,  0.0128,  0.0053,  ...,  0.0138, -0.0122, -0.0145],\n",
       "         [ 0.0058, -0.0034,  0.0068,  ..., -0.0029,  0.0099,  0.0024],\n",
       "         [-0.0078, -0.0091,  0.0064,  ...,  0.0142,  0.0142,  0.0159]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight': tensor([[ 1.5981e-04,  7.0873e-04,  1.8042e-03,  ..., -2.8365e-03,\n",
       "           1.8612e-03, -6.5493e-03],\n",
       "         [-4.0434e-03, -1.8013e-03, -3.2693e-03,  ..., -4.4837e-05,\n",
       "           1.3145e-03,  3.9146e-03],\n",
       "         [-8.2271e-05, -1.3880e-03, -7.3467e-04,  ...,  5.5846e-03,\n",
       "           3.6062e-03,  1.7928e-03],\n",
       "         ...,\n",
       "         [ 8.8148e-04, -2.0423e-03, -1.8196e-03,  ..., -5.2173e-03,\n",
       "           2.9900e-03,  3.5035e-03],\n",
       "         [ 1.4605e-03, -1.4326e-03, -1.9424e-04,  ...,  3.9749e-03,\n",
       "          -8.8630e-05, -4.7723e-04],\n",
       "         [ 1.6088e-03, -2.2475e-03,  3.7258e-04,  ...,  3.0739e-03,\n",
       "           3.9366e-06,  4.4756e-05]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0129, -0.0048, -0.0018,  ...,  0.0038,  0.0070, -0.0100],\n",
       "         [ 0.0075,  0.0080,  0.0116,  ...,  0.0137,  0.0034, -0.0113],\n",
       "         [ 0.0042, -0.0194, -0.0052,  ...,  0.0043,  0.0021,  0.0060],\n",
       "         ...,\n",
       "         [-0.0068,  0.0039,  0.0119,  ...,  0.0186, -0.0068,  0.0119],\n",
       "         [ 0.0035,  0.0086, -0.0103,  ...,  0.0080,  0.0042,  0.0002],\n",
       "         [ 0.0163, -0.0018, -0.0102,  ..., -0.0052, -0.0003, -0.0052]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0029, -0.0033,  0.0042,  ...,  0.0045,  0.0009, -0.0014],\n",
       "         [ 0.0008, -0.0007,  0.0014,  ...,  0.0017, -0.0019, -0.0003],\n",
       "         [ 0.0002,  0.0014, -0.0018,  ..., -0.0021, -0.0001, -0.0009],\n",
       "         ...,\n",
       "         [ 0.0034,  0.0014, -0.0014,  ..., -0.0013, -0.0026,  0.0025],\n",
       "         [-0.0008,  0.0022, -0.0012,  ..., -0.0020,  0.0012, -0.0004],\n",
       "         [ 0.0018,  0.0015, -0.0023,  ..., -0.0017, -0.0010,  0.0036]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight': tensor([[ 5.7532e-03,  1.2166e-03, -1.1019e-03,  ..., -5.3661e-05,\n",
       "           2.1155e-03,  1.9336e-03],\n",
       "         [ 9.5238e-04, -6.6426e-03, -7.8803e-03,  ..., -1.5306e-02,\n",
       "           2.4594e-03,  7.7068e-03],\n",
       "         [ 1.1941e-03, -1.4293e-02, -1.8356e-02,  ...,  5.5528e-03,\n",
       "          -1.5422e-02, -1.2118e-02],\n",
       "         ...,\n",
       "         [-1.6137e-02, -1.2180e-02,  4.1549e-03,  ..., -1.0458e-02,\n",
       "          -3.3179e-03,  1.2537e-02],\n",
       "         [ 1.4723e-02,  1.0135e-02,  1.1833e-02,  ..., -2.1869e-03,\n",
       "           6.9815e-03,  2.7746e-03],\n",
       "         [-7.2315e-04, -4.6844e-03,  1.4624e-02,  ...,  2.8433e-04,\n",
       "          -5.0981e-03, -5.7084e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight': tensor([[ 1.4005e-03, -1.1072e-03,  3.1457e-03,  ...,  7.3383e-04,\n",
       "          -9.9705e-04, -1.7884e-03],\n",
       "         [ 1.7203e-03,  3.4773e-04,  2.9400e-03,  ...,  8.3688e-04,\n",
       "          -7.4780e-04, -1.2188e-03],\n",
       "         [ 9.8919e-04,  1.2200e-03,  1.2039e-03,  ...,  1.9622e-04,\n",
       "          -2.3742e-03,  1.2468e-03],\n",
       "         ...,\n",
       "         [-4.8805e-03, -5.9140e-03,  4.1089e-05,  ..., -6.3783e-04,\n",
       "          -1.8377e-03,  5.2133e-04],\n",
       "         [ 2.2327e-03,  3.7278e-03,  2.1550e-03,  ...,  2.2810e-04,\n",
       "          -3.0874e-04, -4.9203e-03],\n",
       "         [ 1.1108e-03,  3.7905e-03,  2.4863e-03,  ...,  2.7850e-04,\n",
       "          -2.1078e-03, -5.6337e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight': tensor([[ 2.8343e-04, -2.8511e-03,  5.1521e-04,  ...,  8.4634e-03,\n",
       "          -6.4358e-03, -6.5803e-03],\n",
       "         [-3.0380e-03,  6.2551e-03, -1.0667e-02,  ..., -1.9557e-02,\n",
       "           8.7821e-03, -1.1612e-02],\n",
       "         [ 1.8102e-02, -1.8517e-02,  9.1820e-03,  ..., -2.0385e-03,\n",
       "          -1.2496e-02,  1.9874e-03],\n",
       "         ...,\n",
       "         [ 9.9312e-03,  6.5811e-03, -1.6590e-02,  ..., -9.8648e-04,\n",
       "          -7.7287e-03,  4.4097e-03],\n",
       "         [-6.9649e-03, -1.4617e-02,  1.6345e-02,  ...,  8.7716e-03,\n",
       "          -5.8215e-03,  8.6326e-05],\n",
       "         [ 1.6512e-02,  6.6699e-03, -5.1460e-03,  ..., -1.2814e-03,\n",
       "          -1.5767e-02, -9.6529e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0031, -0.0036, -0.0038,  ..., -0.0027, -0.0006, -0.0001],\n",
       "         [ 0.0012,  0.0017,  0.0005,  ...,  0.0017, -0.0046,  0.0031],\n",
       "         [ 0.0026,  0.0015,  0.0012,  ...,  0.0018, -0.0069,  0.0023],\n",
       "         ...,\n",
       "         [-0.0003,  0.0004, -0.0018,  ..., -0.0027,  0.0056, -0.0006],\n",
       "         [-0.0022,  0.0020,  0.0007,  ...,  0.0010, -0.0017, -0.0002],\n",
       "         [-0.0016,  0.0029,  0.0038,  ...,  0.0032, -0.0032,  0.0024]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0016, -0.0098,  0.0129,  ...,  0.0087,  0.0113, -0.0027],\n",
       "         [ 0.0171,  0.0097,  0.0095,  ..., -0.0041, -0.0017, -0.0053],\n",
       "         [ 0.0029,  0.0076,  0.0048,  ...,  0.0029, -0.0002, -0.0141],\n",
       "         ...,\n",
       "         [ 0.0122,  0.0057, -0.0102,  ..., -0.0112, -0.0045,  0.0030],\n",
       "         [ 0.0162, -0.0113,  0.0058,  ..., -0.0137, -0.0119,  0.0061],\n",
       "         [ 0.0094,  0.0098,  0.0057,  ..., -0.0035, -0.0105,  0.0108]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0017,  0.0010,  0.0004,  ..., -0.0005,  0.0005,  0.0017],\n",
       "         [-0.0007, -0.0015,  0.0024,  ..., -0.0003, -0.0008,  0.0018],\n",
       "         [-0.0020, -0.0024,  0.0033,  ...,  0.0012, -0.0021,  0.0010],\n",
       "         ...,\n",
       "         [ 0.0016,  0.0031, -0.0020,  ...,  0.0041,  0.0007, -0.0021],\n",
       "         [-0.0027, -0.0038,  0.0039,  ..., -0.0034, -0.0043,  0.0028],\n",
       "         [-0.0030, -0.0018, -0.0045,  ..., -0.0037,  0.0006,  0.0033]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0092,  0.0087, -0.0034,  ...,  0.0095, -0.0030, -0.0020],\n",
       "         [-0.0151,  0.0120,  0.0025,  ..., -0.0063,  0.0084, -0.0050],\n",
       "         [ 0.0061, -0.0044,  0.0107,  ..., -0.0001,  0.0137, -0.0081],\n",
       "         ...,\n",
       "         [-0.0088, -0.0050, -0.0014,  ..., -0.0119,  0.0056, -0.0103],\n",
       "         [-0.0063,  0.0081,  0.0140,  ...,  0.0067, -0.0088, -0.0004],\n",
       "         [ 0.0188, -0.0139,  0.0124,  ...,  0.0009,  0.0092, -0.0060]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0017,  0.0002,  0.0016,  ..., -0.0004, -0.0008,  0.0001],\n",
       "         [-0.0001,  0.0002,  0.0011,  ..., -0.0002, -0.0004,  0.0008],\n",
       "         [-0.0017,  0.0023,  0.0022,  ..., -0.0002, -0.0023, -0.0016],\n",
       "         ...,\n",
       "         [ 0.0018, -0.0034, -0.0031,  ...,  0.0033,  0.0023,  0.0026],\n",
       "         [ 0.0027, -0.0044, -0.0054,  ...,  0.0060,  0.0044,  0.0050],\n",
       "         [ 0.0024, -0.0031, -0.0031,  ...,  0.0020,  0.0038,  0.0024]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0088, -0.0017, -0.0025,  ..., -0.0060,  0.0165, -0.0145],\n",
       "         [ 0.0066, -0.0102, -0.0022,  ..., -0.0038, -0.0040,  0.0066],\n",
       "         [-0.0098, -0.0136,  0.0019,  ...,  0.0064, -0.0079,  0.0118],\n",
       "         ...,\n",
       "         [ 0.0178, -0.0141,  0.0079,  ..., -0.0011,  0.0067,  0.0041],\n",
       "         [-0.0088,  0.0008,  0.0070,  ...,  0.0121,  0.0024,  0.0074],\n",
       "         [ 0.0066, -0.0073,  0.0091,  ..., -0.0126,  0.0130, -0.0009]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight': tensor([[-3.4422e-04, -1.4530e-03,  1.9516e-03,  ...,  5.7434e-04,\n",
       "           2.4317e-03,  1.5060e-03],\n",
       "         [-2.3686e-04, -1.5896e-03,  2.0178e-03,  ...,  1.2291e-03,\n",
       "           1.5008e-03,  3.6545e-03],\n",
       "         [-4.3664e-03,  1.0248e-03, -3.0360e-03,  ..., -3.0060e-03,\n",
       "          -2.2170e-03,  1.2784e-03],\n",
       "         ...,\n",
       "         [-3.7533e-03, -4.1315e-04,  7.0751e-05,  ..., -2.7164e-03,\n",
       "           1.1739e-03,  7.8654e-04],\n",
       "         [ 1.0911e-03,  2.2628e-03, -2.2183e-03,  ..., -1.3845e-03,\n",
       "          -3.6420e-03, -1.6089e-03],\n",
       "         [-1.2820e-03,  2.5736e-04,  1.5123e-03,  ...,  7.7373e-04,\n",
       "           1.4469e-03,  9.7696e-04]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0174, -0.0177, -0.0030,  ..., -0.0012,  0.0094,  0.0155],\n",
       "         [ 0.0099, -0.0063, -0.0117,  ..., -0.0120, -0.0051,  0.0067],\n",
       "         [ 0.0108,  0.0111, -0.0056,  ..., -0.0039,  0.0085, -0.0105],\n",
       "         ...,\n",
       "         [ 0.0011,  0.0130,  0.0001,  ..., -0.0034,  0.0119,  0.0086],\n",
       "         [ 0.0140, -0.0186,  0.0038,  ..., -0.0181, -0.0172, -0.0070],\n",
       "         [ 0.0043, -0.0136,  0.0054,  ...,  0.0018,  0.0043, -0.0023]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0093,  0.0014, -0.0007,  ..., -0.0034,  0.0052, -0.0048],\n",
       "         [ 0.0067, -0.0018,  0.0022,  ..., -0.0007,  0.0034,  0.0023],\n",
       "         [ 0.0006, -0.0019,  0.0005,  ...,  0.0029, -0.0028, -0.0009],\n",
       "         ...,\n",
       "         [ 0.0044, -0.0024,  0.0030,  ...,  0.0002,  0.0024,  0.0046],\n",
       "         [ 0.0025, -0.0027,  0.0032,  ...,  0.0006,  0.0002,  0.0041],\n",
       "         [-0.0002,  0.0026, -0.0025,  ..., -0.0024,  0.0008,  0.0031]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight': tensor([[-7.0876e-03, -1.9017e-02,  3.7335e-03,  ...,  6.4149e-03,\n",
       "          -1.1846e-02, -1.0226e-02],\n",
       "         [ 1.8731e-03,  9.5545e-03, -2.9749e-03,  ..., -8.8055e-03,\n",
       "           1.5670e-02,  1.0777e-03],\n",
       "         [ 1.4673e-02,  8.9872e-03,  9.6650e-03,  ..., -9.0581e-03,\n",
       "          -8.2101e-03,  5.6849e-03],\n",
       "         ...,\n",
       "         [ 9.6908e-03,  1.0805e-02,  7.8483e-03,  ..., -5.6295e-05,\n",
       "          -8.7839e-03, -1.9738e-02],\n",
       "         [ 1.1651e-02,  2.7657e-03, -1.8869e-03,  ..., -1.8715e-02,\n",
       "          -1.2243e-02, -5.3796e-03],\n",
       "         [ 1.0771e-03, -1.3714e-02,  5.2442e-03,  ...,  5.1363e-03,\n",
       "           9.8876e-04,  1.3261e-02]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0034,  0.0028,  0.0038,  ...,  0.0035, -0.0033, -0.0046],\n",
       "         [ 0.0002, -0.0017, -0.0011,  ..., -0.0011,  0.0021,  0.0020],\n",
       "         [-0.0028,  0.0023,  0.0024,  ...,  0.0022, -0.0016, -0.0030],\n",
       "         ...,\n",
       "         [ 0.0012,  0.0010,  0.0002,  ...,  0.0010, -0.0015, -0.0001],\n",
       "         [-0.0018,  0.0029,  0.0009,  ...,  0.0043, -0.0040, -0.0039],\n",
       "         [ 0.0024, -0.0025, -0.0026,  ..., -0.0032,  0.0015,  0.0051]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0167,  0.0085, -0.0091,  ..., -0.0010, -0.0221, -0.0122],\n",
       "         [-0.0065, -0.0087,  0.0007,  ...,  0.0133, -0.0115, -0.0154],\n",
       "         [-0.0104, -0.0089,  0.0073,  ..., -0.0078,  0.0093,  0.0049],\n",
       "         ...,\n",
       "         [ 0.0036, -0.0064,  0.0102,  ..., -0.0080,  0.0054, -0.0139],\n",
       "         [ 0.0093, -0.0054,  0.0020,  ...,  0.0044,  0.0042, -0.0184],\n",
       "         [-0.0057,  0.0171,  0.0060,  ..., -0.0075, -0.0064,  0.0047]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight': tensor([[ 6.9851e-03, -1.7639e-03,  4.5989e-03,  ...,  1.0936e-03,\n",
       "           6.4698e-03,  3.1579e-03],\n",
       "         [-3.2020e-03, -4.2744e-04, -2.9281e-03,  ..., -1.3368e-03,\n",
       "          -7.0614e-03, -2.7031e-03],\n",
       "         [-6.0038e-04, -3.2074e-03, -3.4774e-04,  ..., -2.8027e-03,\n",
       "           1.1000e-03, -1.6184e-03],\n",
       "         ...,\n",
       "         [ 1.2960e-03,  2.0734e-03,  4.8879e-03,  ...,  3.3234e-03,\n",
       "           8.1207e-04,  2.8708e-03],\n",
       "         [ 3.9503e-05,  2.7701e-03,  1.9347e-03,  ...,  1.1008e-03,\n",
       "           2.4040e-03,  2.3505e-03],\n",
       "         [-3.4487e-03, -5.1289e-03, -4.5130e-03,  ..., -5.7860e-03,\n",
       "          -1.6712e-03, -5.5969e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0163,  0.0101,  0.0166,  ...,  0.0055,  0.0006,  0.0022],\n",
       "         [ 0.0148,  0.0082,  0.0116,  ..., -0.0165,  0.0190,  0.0050],\n",
       "         [ 0.0031,  0.0010,  0.0132,  ...,  0.0171,  0.0099, -0.0109],\n",
       "         ...,\n",
       "         [ 0.0070,  0.0123,  0.0161,  ...,  0.0093,  0.0076,  0.0133],\n",
       "         [-0.0068,  0.0013,  0.0118,  ...,  0.0036,  0.0045, -0.0147],\n",
       "         [-0.0201,  0.0089,  0.0131,  ..., -0.0007,  0.0137, -0.0179]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight': tensor([[ 8.0993e-05,  6.6799e-04, -1.6372e-03,  ...,  4.4391e-04,\n",
       "          -3.6135e-03,  2.3319e-04],\n",
       "         [ 4.3864e-03, -5.5695e-04, -4.4700e-04,  ...,  3.5374e-04,\n",
       "          -2.0303e-03, -5.7437e-04],\n",
       "         [ 4.4210e-03, -1.3267e-03, -2.8814e-04,  ..., -2.0546e-04,\n",
       "           1.8450e-03, -1.2354e-03],\n",
       "         ...,\n",
       "         [-3.9381e-03,  8.5074e-04, -2.2318e-03,  ..., -2.3662e-03,\n",
       "           3.5747e-04, -3.4819e-04],\n",
       "         [-3.4852e-03, -2.0827e-03,  3.3076e-04,  ..., -2.2424e-03,\n",
       "           1.0134e-03,  1.3275e-04],\n",
       "         [ 1.8138e-03,  8.6605e-04, -6.1223e-03,  ...,  3.0228e-03,\n",
       "          -3.4603e-03,  1.9623e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0137, -0.0076,  0.0072,  ...,  0.0135,  0.0069, -0.0002],\n",
       "         [-0.0013,  0.0136, -0.0040,  ...,  0.0178,  0.0027, -0.0082],\n",
       "         [-0.0001,  0.0077, -0.0115,  ...,  0.0028, -0.0014,  0.0083],\n",
       "         ...,\n",
       "         [-0.0025,  0.0092,  0.0107,  ...,  0.0031,  0.0053, -0.0076],\n",
       "         [-0.0142,  0.0149,  0.0171,  ...,  0.0139,  0.0034,  0.0023],\n",
       "         [ 0.0034, -0.0138, -0.0134,  ...,  0.0036, -0.0098, -0.0089]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0062,  0.0027,  0.0010,  ...,  0.0028,  0.0041, -0.0015],\n",
       "         [ 0.0055,  0.0051,  0.0050,  ...,  0.0044,  0.0062, -0.0061],\n",
       "         [ 0.0039,  0.0012, -0.0018,  ...,  0.0007,  0.0018, -0.0003],\n",
       "         ...,\n",
       "         [-0.0006, -0.0042, -0.0057,  ..., -0.0023, -0.0038,  0.0040],\n",
       "         [ 0.0016,  0.0020,  0.0007,  ...,  0.0027,  0.0033, -0.0031],\n",
       "         [-0.0028, -0.0014,  0.0007,  ..., -0.0011, -0.0009, -0.0004]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight': tensor([[-8.3188e-04, -3.5008e-03,  3.9648e-03,  ...,  9.0445e-03,\n",
       "          -7.8493e-03, -1.3580e-02],\n",
       "         [-9.1202e-03,  6.0006e-03, -4.9528e-03,  ..., -1.9105e-03,\n",
       "          -6.9121e-03, -6.3595e-03],\n",
       "         [ 5.7356e-03, -4.9147e-03, -7.0023e-03,  ...,  5.7573e-03,\n",
       "           8.4941e-03,  1.4276e-03],\n",
       "         ...,\n",
       "         [ 1.3615e-02, -9.8364e-03,  8.1765e-06,  ..., -8.2869e-03,\n",
       "          -2.0924e-02, -5.4305e-03],\n",
       "         [-5.8186e-03, -1.1727e-02,  2.7047e-03,  ..., -1.1322e-03,\n",
       "          -3.2637e-04, -7.3507e-03],\n",
       "         [-1.1279e-02, -2.9803e-04, -4.9602e-03,  ..., -1.8657e-02,\n",
       "           1.5875e-02,  7.5745e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight': tensor([[ 5.0964e-03,  6.6547e-03,  5.0853e-03,  ...,  4.6520e-03,\n",
       "          -5.8566e-03, -6.6550e-03],\n",
       "         [-1.9343e-03, -4.1727e-03, -5.4242e-03,  ..., -4.8110e-03,\n",
       "           4.4460e-03,  2.3223e-03],\n",
       "         [-7.4249e-03, -7.1433e-03, -6.3184e-03,  ..., -3.8908e-03,\n",
       "           5.6579e-03,  5.9369e-03],\n",
       "         ...,\n",
       "         [-1.1387e-03, -1.1408e-03, -3.3820e-04,  ...,  9.8963e-04,\n",
       "          -2.0109e-03,  2.1138e-03],\n",
       "         [ 3.7827e-03,  9.4469e-04,  3.5250e-04,  ..., -4.2036e-03,\n",
       "          -2.2137e-05, -1.8578e-03],\n",
       "         [-3.7831e-03, -1.3509e-03, -1.1239e-03,  ...,  3.8387e-03,\n",
       "          -2.8527e-03,  2.9070e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0146,  0.0013, -0.0191,  ..., -0.0033, -0.0044, -0.0019],\n",
       "         [-0.0101,  0.0085, -0.0076,  ..., -0.0107, -0.0036, -0.0134],\n",
       "         [-0.0079,  0.0005,  0.0128,  ..., -0.0168, -0.0138, -0.0081],\n",
       "         ...,\n",
       "         [ 0.0016, -0.0113,  0.0126,  ..., -0.0128,  0.0043,  0.0110],\n",
       "         [ 0.0017,  0.0056, -0.0013,  ...,  0.0095, -0.0111, -0.0018],\n",
       "         [-0.0002, -0.0046,  0.0026,  ...,  0.0178, -0.0108,  0.0071]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0035,  0.0045, -0.0018,  ...,  0.0043, -0.0054, -0.0034],\n",
       "         [-0.0036, -0.0027, -0.0037,  ..., -0.0022,  0.0025, -0.0010],\n",
       "         [-0.0028, -0.0016, -0.0041,  ..., -0.0008,  0.0020,  0.0030],\n",
       "         ...,\n",
       "         [ 0.0050,  0.0042, -0.0036,  ...,  0.0038, -0.0051, -0.0033],\n",
       "         [ 0.0046,  0.0040,  0.0064,  ...,  0.0006, -0.0034, -0.0028],\n",
       "         [ 0.0050,  0.0017,  0.0048,  ...,  0.0007, -0.0026, -0.0002]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0101,  0.0160, -0.0034,  ...,  0.0114,  0.0146,  0.0059],\n",
       "         [ 0.0059,  0.0108,  0.0152,  ...,  0.0096, -0.0115,  0.0047],\n",
       "         [-0.0037,  0.0027, -0.0052,  ...,  0.0053, -0.0150,  0.0048],\n",
       "         ...,\n",
       "         [ 0.0075,  0.0149, -0.0021,  ..., -0.0106,  0.0100,  0.0077],\n",
       "         [ 0.0071,  0.0138,  0.0145,  ...,  0.0058, -0.0035,  0.0123],\n",
       "         [ 0.0058, -0.0130,  0.0012,  ..., -0.0033, -0.0024, -0.0030]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight': tensor([[ 2.2312e-04, -2.7312e-03, -8.5717e-05,  ..., -3.5737e-03,\n",
       "          -5.0109e-03,  4.1352e-03],\n",
       "         [ 4.0152e-04, -3.5595e-03, -1.0788e-03,  ..., -2.3026e-03,\n",
       "          -3.3810e-03,  2.1692e-03],\n",
       "         [ 4.4475e-04, -2.9481e-03,  6.4348e-04,  ..., -5.7491e-04,\n",
       "          -1.0469e-03,  1.0827e-03],\n",
       "         ...,\n",
       "         [ 2.0892e-03, -3.5461e-03, -3.8762e-03,  ..., -2.3575e-03,\n",
       "          -1.8913e-03,  3.3133e-03],\n",
       "         [-3.7558e-03,  1.9275e-03,  3.4212e-03,  ...,  3.2412e-04,\n",
       "           3.5057e-03, -2.5259e-03],\n",
       "         [ 9.5638e-04,  2.8507e-03,  3.2237e-03,  ...,  3.1576e-03,\n",
       "           2.1155e-03, -2.1634e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0121, -0.0032,  0.0027,  ...,  0.0111, -0.0125,  0.0163],\n",
       "         [ 0.0011, -0.0022, -0.0032,  ...,  0.0063,  0.0033, -0.0100],\n",
       "         [-0.0167,  0.0034,  0.0035,  ...,  0.0078,  0.0037,  0.0067],\n",
       "         ...,\n",
       "         [ 0.0114, -0.0051, -0.0044,  ..., -0.0195, -0.0127,  0.0099],\n",
       "         [-0.0050, -0.0092,  0.0076,  ...,  0.0065, -0.0114, -0.0112],\n",
       "         [-0.0128,  0.0071,  0.0083,  ...,  0.0059,  0.0157, -0.0030]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight': tensor([[ 4.1692e-04,  1.8730e-05,  2.8048e-03,  ...,  1.1657e-03,\n",
       "           1.7387e-03, -4.7014e-04],\n",
       "         [ 1.8616e-03, -1.9799e-03,  2.3654e-03,  ...,  2.9510e-03,\n",
       "           1.1030e-03, -2.4633e-03],\n",
       "         [-1.2412e-03,  1.1349e-04, -2.2403e-03,  ..., -8.2895e-04,\n",
       "          -2.5265e-03, -3.5663e-04],\n",
       "         ...,\n",
       "         [-8.0403e-04,  5.5264e-04,  8.0262e-04,  ...,  7.7620e-04,\n",
       "           5.9341e-04, -1.5185e-03],\n",
       "         [-7.1982e-04, -8.7501e-05, -1.1871e-03,  ...,  1.1043e-03,\n",
       "           1.8182e-04, -9.5792e-04],\n",
       "         [ 1.9322e-03, -1.0697e-03, -2.4017e-04,  ..., -4.6032e-03,\n",
       "           1.2529e-03,  5.2001e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0015, -0.0050,  0.0032,  ..., -0.0020, -0.0196, -0.0092],\n",
       "         [-0.0090, -0.0135,  0.0023,  ..., -0.0017, -0.0117, -0.0027],\n",
       "         [ 0.0064, -0.0045, -0.0132,  ...,  0.0133,  0.0068,  0.0014],\n",
       "         ...,\n",
       "         [ 0.0151,  0.0111, -0.0036,  ..., -0.0102, -0.0084, -0.0130],\n",
       "         [ 0.0032, -0.0090,  0.0027,  ..., -0.0068,  0.0097, -0.0029],\n",
       "         [-0.0145, -0.0149,  0.0041,  ..., -0.0096, -0.0170,  0.0026]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight': tensor([[-1.1402e-03, -4.0548e-04, -7.4556e-05,  ...,  1.7395e-03,\n",
       "          -5.2418e-04,  3.5269e-03],\n",
       "         [ 1.3829e-03,  7.5322e-04,  9.8644e-04,  ..., -4.1206e-03,\n",
       "          -8.0313e-04,  1.5613e-03],\n",
       "         [-6.1238e-06, -1.5057e-03, -1.7889e-03,  ...,  2.6219e-03,\n",
       "          -3.5962e-03,  1.0949e-03],\n",
       "         ...,\n",
       "         [ 1.5655e-03, -3.1836e-03,  2.7781e-03,  ..., -3.4731e-03,\n",
       "          -2.1795e-03,  3.6225e-03],\n",
       "         [-5.0027e-04,  3.3136e-03, -3.2076e-04,  ..., -2.0172e-03,\n",
       "           2.8688e-03, -1.5949e-03],\n",
       "         [ 1.3274e-03,  3.2017e-03, -3.5609e-03,  ...,  8.5888e-04,\n",
       "           1.0595e-03, -2.2613e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0073, -0.0074,  0.0083,  ..., -0.0063, -0.0016, -0.0022],\n",
       "         [ 0.0054, -0.0077,  0.0157,  ..., -0.0131,  0.0067, -0.0073],\n",
       "         [-0.0098, -0.0101,  0.0100,  ..., -0.0211, -0.0045, -0.0055],\n",
       "         ...,\n",
       "         [-0.0030, -0.0006, -0.0101,  ...,  0.0062,  0.0158, -0.0177],\n",
       "         [ 0.0051, -0.0116, -0.0059,  ..., -0.0097, -0.0008, -0.0133],\n",
       "         [ 0.0139, -0.0168,  0.0185,  ..., -0.0036, -0.0097, -0.0125]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight': tensor([[ 1.9550e-03, -3.0218e-03, -2.0178e-03,  ...,  1.4057e-03,\n",
       "          -2.4243e-03,  1.9637e-03],\n",
       "         [ 4.9849e-04,  1.3672e-03,  1.7379e-03,  ...,  8.0055e-04,\n",
       "           2.3057e-03,  6.3008e-04],\n",
       "         [ 2.0670e-03,  6.7310e-04,  1.6476e-03,  ..., -1.3123e-03,\n",
       "          -9.2791e-04,  4.5947e-03],\n",
       "         ...,\n",
       "         [ 4.8726e-03, -4.9895e-03, -4.0231e-03,  ...,  5.2202e-03,\n",
       "          -5.2540e-03, -3.2411e-03],\n",
       "         [ 4.1709e-03, -1.7219e-03, -3.8262e-03,  ...,  3.8617e-03,\n",
       "          -4.7761e-03, -3.7834e-03],\n",
       "         [ 5.1807e-05,  8.2818e-05, -3.8425e-04,  ...,  2.6722e-04,\n",
       "          -1.2945e-04,  2.5110e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0053,  0.0101, -0.0155,  ..., -0.0083,  0.0060, -0.0033],\n",
       "         [-0.0209, -0.0058, -0.0117,  ..., -0.0012,  0.0054, -0.0092],\n",
       "         [ 0.0142, -0.0141, -0.0161,  ...,  0.0084, -0.0133,  0.0067],\n",
       "         ...,\n",
       "         [-0.0049,  0.0172,  0.0084,  ..., -0.0036,  0.0051,  0.0096],\n",
       "         [-0.0127, -0.0020, -0.0176,  ...,  0.0083, -0.0137, -0.0065],\n",
       "         [ 0.0098,  0.0153, -0.0024,  ...,  0.0022,  0.0115,  0.0079]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight': tensor([[-4.1704e-03,  2.3565e-03, -3.4251e-03,  ...,  3.2809e-03,\n",
       "          -1.5059e-03,  4.2591e-03],\n",
       "         [ 2.1371e-04,  1.4086e-03, -2.6173e-03,  ...,  1.6701e-03,\n",
       "          -3.1139e-03,  3.6008e-04],\n",
       "         [ 4.5396e-04,  1.4900e-03, -2.7720e-03,  ...,  2.4478e-03,\n",
       "          -2.8823e-03,  6.9789e-04],\n",
       "         ...,\n",
       "         [ 5.5668e-04, -2.5816e-03,  2.1122e-03,  ...,  1.5647e-03,\n",
       "           4.2360e-04, -6.7755e-04],\n",
       "         [-3.5367e-03,  7.9857e-04, -1.6125e-03,  ...,  2.2722e-03,\n",
       "           2.1346e-03,  1.2741e-03],\n",
       "         [-1.4707e-03,  2.0108e-05,  1.8377e-03,  ...,  2.3681e-03,\n",
       "           1.1171e-03, -8.3127e-04]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0042, -0.0148,  0.0051,  ...,  0.0028,  0.0097,  0.0116],\n",
       "         [-0.0015, -0.0040, -0.0036,  ..., -0.0080, -0.0045,  0.0064],\n",
       "         [-0.0025, -0.0067,  0.0028,  ...,  0.0144,  0.0180, -0.0103],\n",
       "         ...,\n",
       "         [-0.0145,  0.0127, -0.0040,  ...,  0.0074, -0.0013, -0.0061],\n",
       "         [ 0.0150,  0.0113,  0.0117,  ...,  0.0031,  0.0099,  0.0203],\n",
       "         [ 0.0116, -0.0024, -0.0101,  ..., -0.0071, -0.0051,  0.0055]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0009, -0.0018,  0.0028,  ..., -0.0012,  0.0011,  0.0025],\n",
       "         [-0.0014, -0.0007,  0.0043,  ..., -0.0011,  0.0003,  0.0022],\n",
       "         [-0.0031, -0.0040, -0.0045,  ...,  0.0030, -0.0060, -0.0038],\n",
       "         ...,\n",
       "         [ 0.0021,  0.0008, -0.0001,  ...,  0.0032,  0.0022, -0.0035],\n",
       "         [-0.0020, -0.0016,  0.0004,  ...,  0.0042, -0.0020,  0.0023],\n",
       "         [ 0.0035, -0.0007,  0.0069,  ..., -0.0079,  0.0006,  0.0027]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight': tensor([[-4.8828e-03,  1.2685e-02, -1.2732e-02,  ..., -1.1452e-02,\n",
       "          -5.5082e-03, -1.1117e-02],\n",
       "         [ 8.1062e-03, -1.0532e-02,  4.8128e-03,  ...,  7.5071e-03,\n",
       "           1.1242e-02, -1.7803e-03],\n",
       "         [-7.3012e-03,  4.6304e-05,  1.4724e-03,  ..., -1.9896e-02,\n",
       "          -9.8727e-03,  7.9510e-03],\n",
       "         ...,\n",
       "         [ 6.1162e-03,  1.6466e-02, -1.2104e-02,  ..., -3.1978e-03,\n",
       "           7.0673e-03,  1.1543e-02],\n",
       "         [-7.1842e-04, -7.6254e-03,  1.8933e-02,  ...,  9.9658e-03,\n",
       "          -1.4472e-02,  3.2124e-03],\n",
       "         [-5.4487e-03, -3.1460e-03,  1.6769e-02,  ..., -5.4122e-04,\n",
       "           5.8436e-03, -1.9125e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight': tensor([[-3.6357e-03,  4.9374e-03, -2.4294e-03,  ...,  3.3792e-03,\n",
       "          -1.6790e-03,  2.8788e-03],\n",
       "         [ 1.3689e-03,  1.2947e-03,  9.8350e-05,  ...,  2.6609e-04,\n",
       "           4.0837e-03, -2.0078e-03],\n",
       "         [-3.8954e-03,  4.3838e-03, -3.0318e-03,  ...,  4.1002e-03,\n",
       "          -1.0923e-03,  4.2262e-03],\n",
       "         ...,\n",
       "         [-2.9445e-04, -2.9870e-03,  2.5338e-03,  ...,  1.7847e-03,\n",
       "           2.6937e-03, -4.4819e-03],\n",
       "         [-2.4234e-03,  1.9480e-03, -9.1647e-04,  ...,  6.1143e-03,\n",
       "           4.3221e-03,  1.4483e-03],\n",
       "         [-2.2883e-03,  4.4041e-04, -1.4738e-03,  ...,  8.9657e-04,\n",
       "           9.2404e-04, -5.8876e-05]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0184,  0.0039,  0.0072,  ...,  0.0062, -0.0028,  0.0055],\n",
       "         [-0.0074,  0.0017,  0.0016,  ...,  0.0071,  0.0024, -0.0038],\n",
       "         [ 0.0148, -0.0095,  0.0077,  ..., -0.0125, -0.0107, -0.0045],\n",
       "         ...,\n",
       "         [-0.0067,  0.0056, -0.0114,  ...,  0.0084,  0.0111,  0.0023],\n",
       "         [-0.0204, -0.0020,  0.0124,  ..., -0.0041,  0.0128, -0.0035],\n",
       "         [ 0.0089, -0.0127, -0.0202,  ..., -0.0136, -0.0144, -0.0094]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0004, -0.0007, -0.0038,  ..., -0.0040,  0.0044, -0.0022],\n",
       "         [-0.0010,  0.0013,  0.0022,  ...,  0.0016, -0.0018,  0.0042],\n",
       "         [ 0.0020,  0.0007, -0.0012,  ...,  0.0001,  0.0007, -0.0043],\n",
       "         ...,\n",
       "         [ 0.0019,  0.0021, -0.0064,  ..., -0.0016,  0.0066, -0.0083],\n",
       "         [ 0.0067,  0.0018,  0.0018,  ...,  0.0007,  0.0002,  0.0004],\n",
       "         [ 0.0029,  0.0063,  0.0006,  ...,  0.0032,  0.0019, -0.0024]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0126, -0.0062, -0.0069,  ..., -0.0012,  0.0119, -0.0117],\n",
       "         [ 0.0157,  0.0003,  0.0142,  ...,  0.0081,  0.0109,  0.0041],\n",
       "         [-0.0017,  0.0147,  0.0116,  ..., -0.0145, -0.0044, -0.0056],\n",
       "         ...,\n",
       "         [ 0.0135, -0.0146,  0.0012,  ...,  0.0137, -0.0127,  0.0006],\n",
       "         [-0.0021, -0.0097, -0.0165,  ...,  0.0142,  0.0023, -0.0067],\n",
       "         [ 0.0050, -0.0003,  0.0016,  ..., -0.0050, -0.0117, -0.0128]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0007, -0.0007, -0.0003,  ...,  0.0029,  0.0001,  0.0015],\n",
       "         [-0.0016,  0.0004, -0.0009,  ...,  0.0011, -0.0004,  0.0019],\n",
       "         [ 0.0005,  0.0002,  0.0014,  ..., -0.0004, -0.0005,  0.0021],\n",
       "         ...,\n",
       "         [-0.0020,  0.0006, -0.0026,  ...,  0.0035, -0.0031,  0.0010],\n",
       "         [ 0.0023, -0.0003,  0.0029,  ..., -0.0047,  0.0019, -0.0013],\n",
       "         [ 0.0009, -0.0011,  0.0016,  ...,  0.0023,  0.0004, -0.0015]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0124,  0.0006,  0.0116,  ...,  0.0214, -0.0017, -0.0064],\n",
       "         [-0.0103,  0.0019, -0.0100,  ...,  0.0001, -0.0059,  0.0016],\n",
       "         [-0.0141, -0.0116, -0.0053,  ..., -0.0067, -0.0016, -0.0005],\n",
       "         ...,\n",
       "         [-0.0054,  0.0131, -0.0115,  ..., -0.0142, -0.0031,  0.0098],\n",
       "         [-0.0099, -0.0140, -0.0047,  ...,  0.0125,  0.0023,  0.0050],\n",
       "         [-0.0058,  0.0129, -0.0077,  ...,  0.0106, -0.0129,  0.0128]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight': tensor([[-4.4897e-03,  4.0520e-03, -2.6823e-03,  ...,  2.2857e-03,\n",
       "           2.9430e-03, -2.9605e-03],\n",
       "         [ 2.4383e-04,  6.4485e-03, -7.4973e-03,  ...,  8.2077e-03,\n",
       "           7.8349e-03, -7.1071e-03],\n",
       "         [-7.4781e-03,  1.9336e-03,  2.9004e-03,  ..., -2.3622e-04,\n",
       "          -1.4823e-03, -8.2195e-05],\n",
       "         ...,\n",
       "         [ 7.6103e-03, -5.4134e-03,  2.8149e-03,  ..., -6.0652e-03,\n",
       "          -2.8985e-03,  5.4170e-03],\n",
       "         [-4.8573e-05, -1.3552e-03,  6.0537e-04,  ...,  4.9686e-04,\n",
       "           2.0791e-04, -1.0495e-04],\n",
       "         [ 6.6785e-03,  5.3012e-04,  2.3411e-03,  ..., -4.8432e-03,\n",
       "          -3.1028e-03,  5.5873e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0109,  0.0093, -0.0084,  ...,  0.0039,  0.0085, -0.0063],\n",
       "         [ 0.0161,  0.0038,  0.0156,  ...,  0.0117,  0.0117,  0.0100],\n",
       "         [ 0.0180, -0.0060, -0.0053,  ...,  0.0178, -0.0009,  0.0028],\n",
       "         ...,\n",
       "         [ 0.0125, -0.0066, -0.0167,  ..., -0.0109,  0.0137,  0.0090],\n",
       "         [ 0.0010,  0.0172,  0.0130,  ..., -0.0035, -0.0049,  0.0197],\n",
       "         [ 0.0177,  0.0202,  0.0083,  ...,  0.0095, -0.0064,  0.0106]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0005,  0.0026,  0.0038,  ..., -0.0015,  0.0039,  0.0036],\n",
       "         [ 0.0042,  0.0038,  0.0050,  ..., -0.0019,  0.0067,  0.0081],\n",
       "         [ 0.0014, -0.0028, -0.0026,  ...,  0.0028, -0.0030, -0.0038],\n",
       "         ...,\n",
       "         [ 0.0021,  0.0023,  0.0030,  ..., -0.0036,  0.0020,  0.0016],\n",
       "         [ 0.0010,  0.0006,  0.0002,  ...,  0.0019, -0.0008, -0.0024],\n",
       "         [-0.0011, -0.0007, -0.0024,  ...,  0.0041, -0.0012, -0.0007]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0150,  0.0051,  0.0077,  ..., -0.0041,  0.0109,  0.0135],\n",
       "         [ 0.0035, -0.0196, -0.0179,  ...,  0.0130, -0.0062, -0.0040],\n",
       "         [ 0.0078,  0.0196,  0.0139,  ..., -0.0025, -0.0030,  0.0128],\n",
       "         ...,\n",
       "         [-0.0079, -0.0064,  0.0100,  ..., -0.0141, -0.0223, -0.0108],\n",
       "         [ 0.0087,  0.0047,  0.0048,  ..., -0.0013,  0.0047, -0.0058],\n",
       "         [ 0.0042,  0.0022,  0.0035,  ...,  0.0043, -0.0034, -0.0115]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0031, -0.0004, -0.0018,  ..., -0.0040,  0.0004, -0.0029],\n",
       "         [ 0.0020, -0.0018,  0.0020,  ...,  0.0020,  0.0020,  0.0030],\n",
       "         [ 0.0023, -0.0007,  0.0017,  ...,  0.0021,  0.0005,  0.0015],\n",
       "         ...,\n",
       "         [-0.0012,  0.0003, -0.0019,  ..., -0.0013, -0.0021, -0.0024],\n",
       "         [-0.0028,  0.0050, -0.0037,  ..., -0.0061, -0.0028, -0.0036],\n",
       "         [ 0.0020,  0.0044, -0.0009,  ..., -0.0010, -0.0013,  0.0020]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0152,  0.0031, -0.0094,  ..., -0.0078, -0.0154, -0.0072],\n",
       "         [-0.0091,  0.0132, -0.0046,  ..., -0.0108, -0.0090, -0.0077],\n",
       "         [ 0.0087,  0.0050,  0.0086,  ..., -0.0107, -0.0144, -0.0201],\n",
       "         ...,\n",
       "         [ 0.0044, -0.0090, -0.0037,  ..., -0.0041,  0.0112,  0.0089],\n",
       "         [-0.0134,  0.0068, -0.0029,  ...,  0.0035,  0.0023, -0.0022],\n",
       "         [-0.0156, -0.0135,  0.0038,  ..., -0.0018,  0.0169,  0.0096]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight': tensor([[ 3.9500e-03, -6.9716e-04,  6.4734e-04,  ...,  1.9996e-04,\n",
       "          -1.4630e-03,  2.1430e-03],\n",
       "         [-2.8172e-03,  2.7123e-04,  8.3186e-04,  ..., -4.7396e-04,\n",
       "           1.9932e-03,  7.2044e-04],\n",
       "         [ 1.7795e-03, -5.9195e-03,  5.3283e-03,  ...,  6.1332e-03,\n",
       "          -5.8898e-03, -5.5754e-03],\n",
       "         ...,\n",
       "         [ 3.7349e-04, -3.7345e-03,  1.7049e-03,  ...,  8.7423e-05,\n",
       "           2.4411e-03,  3.9986e-03],\n",
       "         [ 2.9691e-03, -1.0568e-03,  1.6121e-04,  ...,  1.1731e-03,\n",
       "          -1.2069e-03,  5.4655e-04],\n",
       "         [ 7.8242e-04, -1.3000e-03, -2.1679e-05,  ...,  2.1272e-04,\n",
       "          -1.8558e-04, -1.1331e-04]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0017,  0.0004, -0.0030,  ..., -0.0014, -0.0018, -0.0020],\n",
       "         [-0.0213,  0.0120,  0.0096,  ...,  0.0082, -0.0026, -0.0105],\n",
       "         [-0.0118,  0.0052,  0.0022,  ...,  0.0023, -0.0039,  0.0116],\n",
       "         ...,\n",
       "         [-0.0006,  0.0108,  0.0043,  ..., -0.0149, -0.0070,  0.0160],\n",
       "         [ 0.0055, -0.0106, -0.0205,  ...,  0.0016,  0.0158, -0.0018],\n",
       "         [ 0.0056,  0.0122, -0.0013,  ...,  0.0119, -0.0071,  0.0106]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight': tensor([[ 4.4296e-03, -4.7382e-03, -4.2070e-03,  ...,  4.4664e-03,\n",
       "          -5.0536e-03,  4.2191e-03],\n",
       "         [-2.1209e-03,  2.3526e-03,  1.5794e-03,  ..., -2.1653e-03,\n",
       "           2.5535e-03,  6.6514e-04],\n",
       "         [-7.1481e-04,  1.0764e-03, -4.9911e-05,  ..., -3.1968e-03,\n",
       "           8.4924e-04, -2.9502e-03],\n",
       "         ...,\n",
       "         [ 1.0432e-03, -7.3960e-04,  3.4471e-04,  ...,  9.9389e-05,\n",
       "          -3.6582e-03, -1.1997e-03],\n",
       "         [ 8.0462e-04, -2.6208e-03,  5.7676e-04,  ...,  2.0477e-03,\n",
       "          -3.5443e-03,  1.9133e-03],\n",
       "         [-1.8438e-03,  1.3018e-03,  2.3855e-03,  ..., -1.2610e-03,\n",
       "           2.2651e-03, -1.9245e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0165,  0.0061, -0.0102,  ..., -0.0156, -0.0120,  0.0133],\n",
       "         [ 0.0028, -0.0073,  0.0154,  ...,  0.0007, -0.0167,  0.0016],\n",
       "         [ 0.0071, -0.0088,  0.0129,  ..., -0.0109, -0.0025, -0.0137],\n",
       "         ...,\n",
       "         [-0.0050, -0.0055, -0.0179,  ...,  0.0107,  0.0123, -0.0128],\n",
       "         [-0.0089,  0.0031, -0.0076,  ...,  0.0076, -0.0049, -0.0062],\n",
       "         [-0.0167,  0.0108,  0.0068,  ...,  0.0048, -0.0173,  0.0169]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0037, -0.0055,  0.0002,  ...,  0.0040, -0.0006,  0.0005],\n",
       "         [-0.0005, -0.0008, -0.0011,  ...,  0.0011, -0.0004, -0.0037],\n",
       "         [-0.0007,  0.0036, -0.0008,  ..., -0.0042, -0.0016,  0.0028],\n",
       "         ...,\n",
       "         [-0.0006,  0.0007,  0.0011,  ..., -0.0040,  0.0007,  0.0006],\n",
       "         [-0.0031, -0.0044, -0.0043,  ...,  0.0036,  0.0031, -0.0059],\n",
       "         [-0.0031, -0.0028, -0.0008,  ...,  0.0037, -0.0002, -0.0018]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0020,  0.0201,  0.0151,  ...,  0.0173,  0.0028,  0.0164],\n",
       "         [-0.0132, -0.0196,  0.0010,  ...,  0.0171,  0.0043, -0.0018],\n",
       "         [-0.0121, -0.0020, -0.0124,  ..., -0.0002, -0.0063, -0.0109],\n",
       "         ...,\n",
       "         [ 0.0142,  0.0075, -0.0075,  ...,  0.0149,  0.0208, -0.0112],\n",
       "         [-0.0046,  0.0090,  0.0108,  ...,  0.0011, -0.0029, -0.0018],\n",
       "         [ 0.0006, -0.0139, -0.0207,  ..., -0.0012, -0.0045, -0.0118]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0033,  0.0033, -0.0004,  ...,  0.0045, -0.0019, -0.0013],\n",
       "         [ 0.0079, -0.0035, -0.0007,  ...,  0.0065, -0.0017, -0.0077],\n",
       "         [-0.0057, -0.0024,  0.0052,  ..., -0.0079, -0.0042,  0.0054],\n",
       "         ...,\n",
       "         [ 0.0013,  0.0010, -0.0014,  ...,  0.0074,  0.0031, -0.0047],\n",
       "         [ 0.0001,  0.0029,  0.0032,  ...,  0.0024, -0.0055,  0.0003],\n",
       "         [-0.0010,  0.0001, -0.0028,  ..., -0.0054, -0.0008,  0.0033]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0012, -0.0074, -0.0040,  ...,  0.0051, -0.0105,  0.0004],\n",
       "         [-0.0027,  0.0171, -0.0107,  ..., -0.0101, -0.0062,  0.0126],\n",
       "         [ 0.0016,  0.0138, -0.0092,  ...,  0.0079, -0.0086, -0.0016],\n",
       "         ...,\n",
       "         [-0.0073,  0.0169,  0.0021,  ..., -0.0075,  0.0042, -0.0098],\n",
       "         [ 0.0161, -0.0125,  0.0030,  ..., -0.0052, -0.0112, -0.0079],\n",
       "         [ 0.0088, -0.0122,  0.0011,  ...,  0.0151, -0.0097,  0.0034]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight': tensor([[ 1.3451e-03, -6.7516e-05,  2.8859e-03,  ..., -4.2404e-03,\n",
       "           7.7606e-04,  1.7311e-03],\n",
       "         [-3.0383e-03, -3.2832e-03, -5.3771e-03,  ..., -1.0202e-03,\n",
       "          -3.4453e-03, -8.0152e-04],\n",
       "         [-3.1087e-03,  3.2780e-03, -1.7042e-03,  ...,  1.8386e-03,\n",
       "          -1.6318e-03,  1.7080e-03],\n",
       "         ...,\n",
       "         [-3.8203e-04,  1.5808e-04, -2.2510e-03,  ..., -1.1414e-03,\n",
       "          -2.1010e-03,  4.2922e-04],\n",
       "         [ 4.0296e-03,  6.6834e-03,  6.9323e-03,  ...,  3.9137e-03,\n",
       "           4.5434e-03, -5.2451e-03],\n",
       "         [-3.6606e-03, -4.5642e-03, -4.2408e-03,  ..., -4.3415e-03,\n",
       "          -4.2496e-03,  2.1071e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0061,  0.0061,  0.0144,  ..., -0.0146,  0.0072,  0.0152],\n",
       "         [-0.0142, -0.0025, -0.0142,  ...,  0.0101,  0.0064,  0.0081],\n",
       "         [-0.0013, -0.0053, -0.0027,  ...,  0.0122, -0.0139, -0.0041],\n",
       "         ...,\n",
       "         [-0.0067,  0.0116, -0.0086,  ..., -0.0025,  0.0146,  0.0032],\n",
       "         [-0.0021, -0.0067, -0.0074,  ..., -0.0047, -0.0066,  0.0114],\n",
       "         [ 0.0085, -0.0141, -0.0011,  ...,  0.0078,  0.0170,  0.0096]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0026,  0.0012,  0.0026,  ...,  0.0009,  0.0008,  0.0032],\n",
       "         [-0.0050, -0.0045, -0.0011,  ..., -0.0057, -0.0036, -0.0051],\n",
       "         [-0.0047, -0.0041, -0.0049,  ..., -0.0034, -0.0057, -0.0025],\n",
       "         ...,\n",
       "         [ 0.0020,  0.0023, -0.0027,  ...,  0.0033,  0.0019,  0.0016],\n",
       "         [-0.0007, -0.0012, -0.0047,  ...,  0.0002, -0.0051,  0.0011],\n",
       "         [-0.0021, -0.0009,  0.0070,  ..., -0.0041,  0.0029, -0.0030]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0107,  0.0072,  0.0042,  ..., -0.0146, -0.0019, -0.0008],\n",
       "         [-0.0025, -0.0028, -0.0056,  ...,  0.0091, -0.0136,  0.0125],\n",
       "         [ 0.0064, -0.0012,  0.0046,  ...,  0.0025,  0.0049,  0.0041],\n",
       "         ...,\n",
       "         [ 0.0099, -0.0009,  0.0024,  ...,  0.0041,  0.0022,  0.0156],\n",
       "         [-0.0114,  0.0043,  0.0003,  ...,  0.0168, -0.0109,  0.0181],\n",
       "         [ 0.0102,  0.0062, -0.0065,  ..., -0.0031,  0.0109, -0.0151]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight': tensor([[-6.4167e-04, -1.7828e-03,  3.2001e-03,  ...,  2.1806e-03,\n",
       "          -2.2321e-03, -4.6237e-04],\n",
       "         [ 2.1242e-03,  2.7004e-03, -4.6171e-04,  ..., -8.9821e-04,\n",
       "          -1.2331e-03, -1.1523e-03],\n",
       "         [-5.8680e-03,  3.9290e-03,  2.5891e-03,  ...,  1.3264e-03,\n",
       "          -1.8636e-03, -2.8638e-03],\n",
       "         ...,\n",
       "         [-5.6682e-03,  3.4359e-03,  4.3610e-03,  ...,  3.8487e-03,\n",
       "          -5.8058e-03, -5.2257e-03],\n",
       "         [-2.5378e-03,  8.8326e-04,  3.8632e-03,  ...,  3.0931e-03,\n",
       "           7.7747e-05, -3.7498e-03],\n",
       "         [ 2.8033e-03, -4.2295e-03, -4.9943e-04,  ..., -2.9986e-03,\n",
       "          -3.3891e-04,  1.2331e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0049,  0.0115,  0.0062,  ..., -0.0131, -0.0229,  0.0103],\n",
       "         [-0.0004,  0.0075, -0.0195,  ...,  0.0094,  0.0042,  0.0074],\n",
       "         [-0.0143,  0.0158, -0.0011,  ...,  0.0185,  0.0107, -0.0149],\n",
       "         ...,\n",
       "         [-0.0107, -0.0050, -0.0133,  ...,  0.0013, -0.0131, -0.0090],\n",
       "         [ 0.0005, -0.0054,  0.0134,  ..., -0.0004,  0.0011, -0.0115],\n",
       "         [-0.0051,  0.0116, -0.0070,  ...,  0.0136,  0.0029, -0.0046]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight': tensor([[ 2.2250e-03, -2.5292e-05,  4.2896e-03,  ...,  1.1717e-03,\n",
       "          -3.9512e-03,  5.0803e-03],\n",
       "         [-4.1526e-03,  4.2204e-03, -6.3284e-03,  ..., -3.7302e-03,\n",
       "           7.4040e-03, -4.5142e-03],\n",
       "         [-8.8680e-03, -5.0039e-03, -2.4140e-03,  ..., -9.5535e-03,\n",
       "           2.9425e-03,  8.4056e-04],\n",
       "         ...,\n",
       "         [ 1.7722e-03,  3.3961e-03, -3.0915e-03,  ...,  1.1355e-03,\n",
       "           3.0612e-03, -3.3453e-03],\n",
       "         [-2.5066e-03,  3.5690e-03, -6.1011e-03,  ..., -3.3937e-03,\n",
       "           7.0592e-03, -5.2433e-03],\n",
       "         [-2.4060e-03, -3.5590e-03,  2.4534e-03,  ..., -1.9706e-04,\n",
       "          -1.0737e-03,  1.1879e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0050,  0.0047,  0.0115,  ..., -0.0086,  0.0055,  0.0181],\n",
       "         [-0.0036, -0.0014,  0.0093,  ..., -0.0120,  0.0179,  0.0071],\n",
       "         [-0.0027,  0.0135,  0.0033,  ..., -0.0100,  0.0074,  0.0056],\n",
       "         ...,\n",
       "         [-0.0133,  0.0124, -0.0139,  ..., -0.0146, -0.0109,  0.0022],\n",
       "         [ 0.0004,  0.0126,  0.0128,  ...,  0.0027, -0.0018,  0.0215],\n",
       "         [-0.0098,  0.0069,  0.0022,  ..., -0.0014,  0.0142, -0.0133]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0040, -0.0022,  0.0021,  ..., -0.0014, -0.0024,  0.0030],\n",
       "         [ 0.0027, -0.0015,  0.0034,  ..., -0.0020,  0.0005,  0.0022],\n",
       "         [-0.0011,  0.0014, -0.0024,  ...,  0.0031,  0.0003,  0.0004],\n",
       "         ...,\n",
       "         [-0.0028,  0.0008,  0.0020,  ..., -0.0041,  0.0005,  0.0004],\n",
       "         [-0.0031, -0.0009, -0.0004,  ...,  0.0033, -0.0028,  0.0009],\n",
       "         [-0.0036, -0.0016,  0.0003,  ..., -0.0006, -0.0053,  0.0004]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0169, -0.0101,  0.0054,  ..., -0.0139,  0.0095,  0.0144],\n",
       "         [-0.0184,  0.0096, -0.0166,  ..., -0.0086,  0.0030,  0.0067],\n",
       "         [ 0.0032, -0.0041,  0.0201,  ...,  0.0074, -0.0023, -0.0112],\n",
       "         ...,\n",
       "         [ 0.0124,  0.0012,  0.0005,  ..., -0.0100,  0.0235, -0.0194],\n",
       "         [-0.0018,  0.0014, -0.0067,  ..., -0.0040, -0.0059, -0.0220],\n",
       "         [ 0.0061, -0.0039,  0.0168,  ...,  0.0172, -0.0127, -0.0001]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0083,  0.0043, -0.0041,  ...,  0.0001, -0.0011,  0.0009],\n",
       "         [-0.0054,  0.0052, -0.0042,  ...,  0.0041,  0.0048, -0.0044],\n",
       "         [ 0.0018, -0.0061,  0.0047,  ..., -0.0044, -0.0062,  0.0035],\n",
       "         ...,\n",
       "         [-0.0064, -0.0031,  0.0046,  ..., -0.0075, -0.0048,  0.0077],\n",
       "         [-0.0075,  0.0070, -0.0062,  ...,  0.0005,  0.0037, -0.0041],\n",
       "         [-0.0010, -0.0043,  0.0042,  ..., -0.0047, -0.0045,  0.0070]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0088, -0.0036,  0.0083,  ...,  0.0081, -0.0148,  0.0141],\n",
       "         [-0.0080,  0.0057,  0.0162,  ...,  0.0096,  0.0174,  0.0159],\n",
       "         [-0.0100,  0.0140,  0.0118,  ...,  0.0053, -0.0125,  0.0144],\n",
       "         ...,\n",
       "         [ 0.0069, -0.0108, -0.0123,  ...,  0.0056,  0.0151, -0.0130],\n",
       "         [-0.0093,  0.0158,  0.0118,  ...,  0.0005, -0.0139, -0.0171],\n",
       "         [-0.0012,  0.0094, -0.0041,  ...,  0.0052, -0.0101, -0.0050]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight': tensor([[ 2.0528e-05, -1.2380e-03, -4.1250e-03,  ...,  4.8172e-03,\n",
       "          -2.1292e-03, -1.4984e-03],\n",
       "         [-1.0042e-03,  2.7324e-03,  2.7020e-03,  ..., -3.3829e-03,\n",
       "           6.6232e-04,  4.0369e-03],\n",
       "         [ 2.7696e-04, -1.4796e-04, -3.9267e-03,  ...,  4.6618e-03,\n",
       "          -7.5198e-04, -1.1660e-03],\n",
       "         ...,\n",
       "         [-8.0641e-04,  1.9350e-03, -1.7179e-03,  ..., -2.9280e-03,\n",
       "          -7.3754e-04, -3.0366e-05],\n",
       "         [-5.0172e-04, -3.7089e-03,  6.9161e-04,  ...,  2.3137e-04,\n",
       "           5.0937e-04, -2.7455e-03],\n",
       "         [-2.7901e-03, -8.8747e-04,  2.4329e-03,  ..., -1.2657e-03,\n",
       "          -1.2635e-03,  7.8806e-04]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0030, -0.0089,  0.0086,  ..., -0.0010, -0.0152,  0.0181],\n",
       "         [ 0.0181, -0.0049, -0.0199,  ..., -0.0069,  0.0088, -0.0063],\n",
       "         [ 0.0144, -0.0036, -0.0080,  ...,  0.0121, -0.0011,  0.0035],\n",
       "         ...,\n",
       "         [-0.0195, -0.0095,  0.0074,  ..., -0.0107, -0.0155,  0.0173],\n",
       "         [-0.0044,  0.0010,  0.0029,  ...,  0.0200, -0.0003, -0.0125],\n",
       "         [-0.0039,  0.0002, -0.0008,  ..., -0.0151, -0.0043, -0.0021]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight': tensor([[ 6.1252e-04, -2.1125e-03, -1.8460e-03,  ...,  9.9293e-04,\n",
       "          -1.5069e-05, -1.0246e-03],\n",
       "         [-2.6026e-03,  2.2453e-03, -1.5066e-03,  ..., -3.3363e-03,\n",
       "           2.8551e-03,  7.3748e-04],\n",
       "         [-4.4762e-03, -5.7071e-03, -4.8333e-03,  ...,  4.7178e-03,\n",
       "           4.6354e-03, -5.6745e-03],\n",
       "         ...,\n",
       "         [-3.9596e-04, -4.0520e-03, -1.8539e-03,  ...,  1.1371e-03,\n",
       "          -3.9527e-04, -3.5087e-03],\n",
       "         [-3.8035e-03, -3.0703e-03, -6.6839e-03,  ...,  7.5190e-04,\n",
       "           8.5749e-03, -4.4131e-03],\n",
       "         [ 6.4717e-05, -7.9584e-03, -1.9198e-03,  ...,  3.1230e-03,\n",
       "          -4.9940e-03, -2.6652e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0029,  0.0017, -0.0023,  ...,  0.0113,  0.0119,  0.0036],\n",
       "         [ 0.0022, -0.0038,  0.0085,  ..., -0.0006,  0.0039, -0.0066],\n",
       "         [-0.0185, -0.0067,  0.0014,  ..., -0.0134,  0.0086, -0.0046],\n",
       "         ...,\n",
       "         [ 0.0058,  0.0053, -0.0118,  ...,  0.0127,  0.0154, -0.0067],\n",
       "         [-0.0008, -0.0065,  0.0174,  ...,  0.0143,  0.0048,  0.0191],\n",
       "         [-0.0153,  0.0007, -0.0134,  ...,  0.0027, -0.0110,  0.0096]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight': tensor([[-4.1064e-03,  1.7617e-03,  5.4520e-04,  ...,  1.4508e-03,\n",
       "          -5.1612e-03, -2.0999e-03],\n",
       "         [ 8.1599e-04, -2.4923e-03,  2.1250e-03,  ...,  2.2777e-03,\n",
       "          -1.9837e-03,  1.2020e-03],\n",
       "         [ 2.8488e-03, -2.9890e-03, -1.3819e-03,  ..., -1.8073e-03,\n",
       "           4.3817e-03,  3.1604e-03],\n",
       "         ...,\n",
       "         [-3.2933e-04, -2.2337e-03,  8.4221e-03,  ...,  1.1118e-03,\n",
       "           1.8130e-03, -8.1720e-04],\n",
       "         [ 1.1124e-03, -1.2859e-03,  3.9577e-05,  ...,  3.8442e-04,\n",
       "           1.2528e-03,  2.3382e-03],\n",
       "         [-3.1039e-03,  1.1538e-03, -6.5969e-03,  ..., -3.4722e-03,\n",
       "          -3.0999e-03, -1.9740e-04]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0140,  0.0202,  0.0057,  ...,  0.0012, -0.0205, -0.0134],\n",
       "         [-0.0021,  0.0025,  0.0175,  ...,  0.0029,  0.0002,  0.0127],\n",
       "         [-0.0047,  0.0018,  0.0111,  ..., -0.0061,  0.0301,  0.0118],\n",
       "         ...,\n",
       "         [-0.0180, -0.0062,  0.0046,  ..., -0.0052,  0.0075, -0.0044],\n",
       "         [-0.0045, -0.0048, -0.0058,  ..., -0.0062,  0.0077,  0.0015],\n",
       "         [-0.0163, -0.0013,  0.0118,  ...,  0.0162, -0.0063,  0.0106]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight': tensor([[-5.7534e-03,  7.0350e-03,  5.8558e-03,  ...,  3.7729e-03,\n",
       "           1.5274e-03, -2.2141e-03],\n",
       "         [-2.3046e-03,  4.8458e-03,  9.2555e-03,  ..., -1.6097e-04,\n",
       "          -4.5790e-06, -6.0952e-04],\n",
       "         [ 7.0629e-03, -7.0722e-03, -1.0994e-03,  ..., -4.5616e-03,\n",
       "          -3.1666e-03,  4.4203e-03],\n",
       "         ...,\n",
       "         [ 3.1805e-03, -7.9821e-03, -9.3318e-03,  ...,  7.2533e-03,\n",
       "           7.6830e-03, -7.4796e-03],\n",
       "         [ 4.8951e-03, -7.1528e-04, -1.4854e-04,  ..., -1.9415e-03,\n",
       "          -1.2144e-03,  1.8855e-03],\n",
       "         [ 5.6860e-03, -9.7859e-04,  7.4258e-04,  ..., -1.0487e-03,\n",
       "          -6.3144e-04,  1.8425e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0160, -0.0042, -0.0052,  ..., -0.0049,  0.0110, -0.0062],\n",
       "         [-0.0040, -0.0020, -0.0085,  ..., -0.0036, -0.0119, -0.0081],\n",
       "         [-0.0104, -0.0034, -0.0013,  ...,  0.0061,  0.0167,  0.0107],\n",
       "         ...,\n",
       "         [-0.0015,  0.0086, -0.0192,  ...,  0.0066, -0.0161,  0.0113],\n",
       "         [-0.0176, -0.0069, -0.0103,  ..., -0.0069, -0.0200, -0.0059],\n",
       "         [ 0.0033,  0.0022,  0.0015,  ..., -0.0122, -0.0031, -0.0009]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight': tensor([[-2.4585e-03,  7.5315e-05,  9.6021e-04,  ...,  3.3902e-03,\n",
       "           3.4922e-04,  1.8345e-03],\n",
       "         [ 2.6055e-03, -1.7591e-03,  6.7816e-04,  ..., -3.1821e-04,\n",
       "          -4.8616e-03, -1.2208e-03],\n",
       "         [-3.3133e-03,  1.3080e-03, -3.8554e-04,  ...,  1.9496e-03,\n",
       "           5.4604e-03, -3.1905e-04],\n",
       "         ...,\n",
       "         [-3.6327e-03,  3.3693e-03,  1.5920e-03,  ...,  1.4400e-04,\n",
       "           1.0395e-03,  2.6722e-03],\n",
       "         [ 3.0938e-03, -4.1950e-03, -4.0314e-03,  ..., -4.6978e-03,\n",
       "          -3.8151e-03, -4.0729e-03],\n",
       "         [-4.8387e-03,  4.6504e-03,  4.6293e-03,  ...,  5.3927e-03,\n",
       "           5.8632e-03,  6.5383e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0028, -0.0100,  0.0080,  ..., -0.0032,  0.0191,  0.0059],\n",
       "         [ 0.0103, -0.0179, -0.0094,  ...,  0.0039,  0.0017, -0.0143],\n",
       "         [-0.0043,  0.0078, -0.0084,  ..., -0.0180,  0.0143,  0.0074],\n",
       "         ...,\n",
       "         [-0.0102,  0.0220,  0.0062,  ...,  0.0139,  0.0050,  0.0104],\n",
       "         [ 0.0016,  0.0124, -0.0128,  ..., -0.0204,  0.0068, -0.0091],\n",
       "         [ 0.0097, -0.0024,  0.0044,  ...,  0.0037,  0.0230, -0.0050]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight': tensor([[ 5.3592e-04,  9.5835e-04, -1.1404e-03,  ...,  9.2088e-04,\n",
       "          -1.9800e-03,  2.0261e-03],\n",
       "         [-1.7511e-03,  2.9676e-05, -5.9845e-04,  ...,  6.9938e-04,\n",
       "          -1.9219e-03,  3.3780e-04],\n",
       "         [-5.3034e-03, -6.2817e-03, -6.9130e-03,  ...,  7.2750e-03,\n",
       "          -6.4514e-03, -6.0882e-03],\n",
       "         ...,\n",
       "         [-1.3697e-04, -4.6169e-04,  2.0551e-04,  ..., -1.1451e-03,\n",
       "           8.1169e-04, -3.0185e-03],\n",
       "         [-9.1194e-04, -2.7829e-03, -3.4725e-05,  ...,  2.7385e-03,\n",
       "           1.3668e-03, -5.5289e-04],\n",
       "         [ 3.6172e-03,  1.2589e-03,  3.4634e-03,  ..., -3.3607e-03,\n",
       "           5.0636e-03,  3.0261e-05]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0092, -0.0002, -0.0052,  ...,  0.0170, -0.0136,  0.0075],\n",
       "         [-0.0092, -0.0162, -0.0027,  ...,  0.0139, -0.0113, -0.0061],\n",
       "         [-0.0066, -0.0066, -0.0025,  ..., -0.0071, -0.0124, -0.0086],\n",
       "         ...,\n",
       "         [-0.0002, -0.0114, -0.0082,  ...,  0.0077,  0.0120,  0.0046],\n",
       "         [-0.0081,  0.0182, -0.0115,  ..., -0.0092, -0.0010, -0.0058],\n",
       "         [ 0.0163, -0.0024,  0.0089,  ..., -0.0050, -0.0094,  0.0006]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight': tensor([[ 2.0259e-04, -2.2269e-04,  2.4685e-03,  ...,  1.2220e-03,\n",
       "          -1.4930e-03, -3.9498e-04],\n",
       "         [-1.0841e-03,  1.8189e-03, -5.4854e-03,  ...,  3.0569e-04,\n",
       "          -1.1128e-03, -3.7312e-03],\n",
       "         [-2.9563e-03, -3.2523e-04,  2.3343e-04,  ...,  1.0563e-03,\n",
       "          -8.0342e-05, -8.6917e-04],\n",
       "         ...,\n",
       "         [-3.3382e-04, -3.1187e-03,  2.3542e-03,  ..., -8.5864e-04,\n",
       "           3.1752e-03,  4.1499e-03],\n",
       "         [-1.4906e-03,  3.1347e-03,  9.6870e-04,  ...,  7.2803e-04,\n",
       "           1.0149e-03, -1.2035e-03],\n",
       "         [-1.2734e-03,  1.4470e-03, -5.3675e-04,  ...,  5.1776e-04,\n",
       "           4.1528e-05, -3.7511e-03]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight': tensor([[ 1.4386e-03, -1.8049e-02, -1.8404e-02,  ..., -4.4480e-03,\n",
       "          -1.1006e-02,  8.8637e-04],\n",
       "         [-9.8128e-03, -2.7538e-03,  4.1469e-03,  ..., -8.5887e-03,\n",
       "          -1.2576e-02,  1.9418e-03],\n",
       "         [-1.8855e-02,  9.1562e-03, -2.7637e-03,  ..., -1.2971e-02,\n",
       "          -4.7053e-03, -7.0608e-03],\n",
       "         ...,\n",
       "         [ 1.0720e-02, -3.4137e-03,  1.3531e-02,  ...,  1.5417e-02,\n",
       "           8.3670e-03, -6.8742e-03],\n",
       "         [ 1.1476e-03,  1.1089e-02,  1.7088e-02,  ...,  3.2478e-04,\n",
       "          -6.8327e-03, -1.7262e-03],\n",
       "         [ 1.5192e-02,  9.0167e-03,  2.6216e-03,  ..., -3.5385e-03,\n",
       "          -2.6142e-02,  6.1147e-05]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0058, -0.0067, -0.0045,  ...,  0.0017,  0.0059, -0.0067],\n",
       "         [ 0.0067, -0.0007,  0.0065,  ..., -0.0068, -0.0060,  0.0005],\n",
       "         [ 0.0094,  0.0086,  0.0064,  ..., -0.0065, -0.0084,  0.0120],\n",
       "         ...,\n",
       "         [ 0.0006, -0.0027,  0.0046,  ..., -0.0039, -0.0003, -0.0029],\n",
       "         [-0.0041,  0.0031, -0.0035,  ...,  0.0033,  0.0029,  0.0028],\n",
       "         [ 0.0048, -0.0012,  0.0037,  ..., -0.0035, -0.0046, -0.0012]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0099,  0.0031,  0.0203,  ..., -0.0010, -0.0080, -0.0014],\n",
       "         [ 0.0098, -0.0175, -0.0025,  ..., -0.0097, -0.0077,  0.0020],\n",
       "         [ 0.0105,  0.0080, -0.0016,  ...,  0.0172,  0.0117, -0.0193],\n",
       "         ...,\n",
       "         [ 0.0047, -0.0039,  0.0088,  ...,  0.0022,  0.0059, -0.0116],\n",
       "         [ 0.0017,  0.0086,  0.0064,  ..., -0.0079,  0.0141,  0.0111],\n",
       "         [ 0.0070,  0.0089, -0.0181,  ..., -0.0100, -0.0019,  0.0098]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0051,  0.0032,  0.0040,  ...,  0.0050,  0.0048,  0.0051],\n",
       "         [-0.0039,  0.0019,  0.0011,  ...,  0.0047,  0.0018,  0.0044],\n",
       "         [-0.0063,  0.0030,  0.0028,  ...,  0.0054,  0.0031,  0.0034],\n",
       "         ...,\n",
       "         [ 0.0043, -0.0071, -0.0044,  ..., -0.0053, -0.0043, -0.0042],\n",
       "         [-0.0026,  0.0029,  0.0020,  ...,  0.0028,  0.0050,  0.0040],\n",
       "         [-0.0062,  0.0061,  0.0069,  ...,  0.0067,  0.0040,  0.0036]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0008,  0.0186,  0.0012,  ...,  0.0031,  0.0085,  0.0064],\n",
       "         [-0.0099, -0.0187,  0.0053,  ..., -0.0037,  0.0107, -0.0020],\n",
       "         [-0.0079, -0.0166, -0.0055,  ...,  0.0093,  0.0202, -0.0086],\n",
       "         ...,\n",
       "         [-0.0043, -0.0088, -0.0069,  ...,  0.0107,  0.0090,  0.0171],\n",
       "         [-0.0057,  0.0075, -0.0064,  ..., -0.0153, -0.0268,  0.0021],\n",
       "         [-0.0160, -0.0127, -0.0034,  ...,  0.0025,  0.0150, -0.0087]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0029, -0.0036, -0.0034,  ...,  0.0042,  0.0005, -0.0023],\n",
       "         [-0.0040,  0.0042, -0.0017,  ..., -0.0005,  0.0022, -0.0027],\n",
       "         [ 0.0014, -0.0012, -0.0072,  ...,  0.0032,  0.0097, -0.0096],\n",
       "         ...,\n",
       "         [ 0.0024, -0.0026, -0.0077,  ...,  0.0073,  0.0052, -0.0071],\n",
       "         [-0.0041,  0.0046,  0.0015,  ..., -0.0038,  0.0033, -0.0040],\n",
       "         [-0.0040,  0.0061, -0.0093,  ..., -0.0004,  0.0118, -0.0124]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0114,  0.0051,  0.0162,  ...,  0.0019,  0.0164, -0.0040],\n",
       "         [ 0.0066, -0.0171,  0.0017,  ...,  0.0073,  0.0046,  0.0032],\n",
       "         [ 0.0081, -0.0155, -0.0023,  ...,  0.0091, -0.0053,  0.0003],\n",
       "         ...,\n",
       "         [ 0.0151,  0.0090,  0.0085,  ...,  0.0091,  0.0098, -0.0075],\n",
       "         [-0.0138, -0.0026,  0.0056,  ...,  0.0096, -0.0099, -0.0137],\n",
       "         [-0.0031,  0.0059, -0.0104,  ...,  0.0126, -0.0167,  0.0124]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0046, -0.0021,  0.0023,  ...,  0.0025, -0.0014,  0.0026],\n",
       "         [-0.0033, -0.0052,  0.0046,  ...,  0.0051, -0.0059,  0.0033],\n",
       "         [-0.0046, -0.0049,  0.0049,  ...,  0.0050, -0.0061,  0.0040],\n",
       "         ...,\n",
       "         [-0.0050,  0.0054,  0.0047,  ..., -0.0059,  0.0044, -0.0044],\n",
       "         [ 0.0041, -0.0042, -0.0046,  ...,  0.0046, -0.0030,  0.0044],\n",
       "         [-0.0030,  0.0024,  0.0049,  ..., -0.0026,  0.0043, -0.0016]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0107, -0.0024, -0.0071,  ...,  0.0008,  0.0061, -0.0009],\n",
       "         [ 0.0010, -0.0051, -0.0041,  ...,  0.0127, -0.0158, -0.0063],\n",
       "         [ 0.0129,  0.0176,  0.0005,  ...,  0.0071,  0.0047,  0.0140],\n",
       "         ...,\n",
       "         [ 0.0024, -0.0096, -0.0167,  ..., -0.0124, -0.0171, -0.0065],\n",
       "         [ 0.0207,  0.0050, -0.0225,  ...,  0.0025,  0.0145,  0.0004],\n",
       "         [ 0.0188, -0.0078,  0.0049,  ..., -0.0175, -0.0012,  0.0099]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0014,  0.0020,  0.0022,  ..., -0.0022, -0.0024, -0.0018],\n",
       "         [ 0.0045,  0.0021,  0.0019,  ...,  0.0010,  0.0007,  0.0002],\n",
       "         [ 0.0014,  0.0010,  0.0014,  ..., -0.0024,  0.0031,  0.0033],\n",
       "         ...,\n",
       "         [ 0.0011,  0.0044,  0.0045,  ..., -0.0005, -0.0084, -0.0074],\n",
       "         [ 0.0033,  0.0038,  0.0062,  ..., -0.0018, -0.0060, -0.0061],\n",
       "         [-0.0056, -0.0015, -0.0046,  ...,  0.0043, -0.0015,  0.0005]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0061, -0.0036,  0.0091,  ...,  0.0144, -0.0044, -0.0088],\n",
       "         [-0.0088, -0.0093,  0.0080,  ..., -0.0127, -0.0077, -0.0110],\n",
       "         [ 0.0191,  0.0063, -0.0007,  ..., -0.0017, -0.0055,  0.0147],\n",
       "         ...,\n",
       "         [-0.0119,  0.0122, -0.0049,  ..., -0.0167,  0.0106,  0.0063],\n",
       "         [ 0.0094,  0.0091,  0.0044,  ...,  0.0013, -0.0054, -0.0121],\n",
       "         [-0.0076, -0.0119, -0.0058,  ...,  0.0087,  0.0050,  0.0078]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0044,  0.0046, -0.0059,  ...,  0.0026, -0.0010,  0.0036],\n",
       "         [ 0.0014,  0.0006,  0.0031,  ..., -0.0032,  0.0027, -0.0014],\n",
       "         [ 0.0034, -0.0042,  0.0065,  ..., -0.0013,  0.0008, -0.0042],\n",
       "         ...,\n",
       "         [-0.0029, -0.0035,  0.0037,  ...,  0.0041,  0.0029, -0.0051],\n",
       "         [-0.0058,  0.0062, -0.0038,  ...,  0.0064, -0.0024,  0.0037],\n",
       "         [-0.0032,  0.0040, -0.0022,  ...,  0.0033, -0.0022,  0.0069]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0133,  0.0097, -0.0087,  ..., -0.0037, -0.0082,  0.0042],\n",
       "         [-0.0121, -0.0026,  0.0109,  ..., -0.0025, -0.0016, -0.0199],\n",
       "         [-0.0029, -0.0039,  0.0139,  ...,  0.0041, -0.0089,  0.0009],\n",
       "         ...,\n",
       "         [-0.0158, -0.0012,  0.0091,  ...,  0.0058,  0.0121, -0.0105],\n",
       "         [ 0.0047,  0.0093,  0.0001,  ...,  0.0005,  0.0134, -0.0003],\n",
       "         [-0.0147,  0.0055, -0.0047,  ..., -0.0051, -0.0169,  0.0168]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0050,  0.0019, -0.0036,  ...,  0.0038, -0.0044, -0.0043],\n",
       "         [-0.0083,  0.0085, -0.0034,  ...,  0.0078, -0.0020, -0.0075],\n",
       "         [ 0.0001, -0.0041, -0.0083,  ..., -0.0015, -0.0052, -0.0024],\n",
       "         ...,\n",
       "         [ 0.0059, -0.0064,  0.0013,  ..., -0.0097, -0.0039,  0.0069],\n",
       "         [-0.0024,  0.0072,  0.0103,  ..., -0.0024,  0.0097,  0.0035],\n",
       "         [ 0.0074, -0.0087, -0.0112,  ..., -0.0019, -0.0120,  0.0015]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight': tensor([[ 1.0128e-02,  1.2305e-02,  5.2838e-03,  ...,  8.2124e-03,\n",
       "           1.3441e-02, -8.8277e-03],\n",
       "         [ 9.0358e-03,  5.8479e-03,  7.8985e-03,  ...,  8.8081e-03,\n",
       "          -2.1296e-02,  1.5658e-02],\n",
       "         [-2.2872e-03, -1.9811e-03, -2.4106e-03,  ...,  9.5012e-03,\n",
       "          -6.5448e-03,  5.6969e-04],\n",
       "         ...,\n",
       "         [ 4.9881e-03, -2.2916e-04,  1.9923e-03,  ...,  1.5122e-02,\n",
       "          -3.4237e-03,  1.9092e-02],\n",
       "         [ 1.7993e-02, -1.1401e-02,  4.4127e-03,  ...,  4.2020e-06,\n",
       "          -6.6201e-03,  1.7423e-02],\n",
       "         [ 1.1677e-02,  3.0456e-03,  1.2310e-02,  ..., -1.2209e-02,\n",
       "           4.2731e-03,  1.4677e-02]], device='cuda:0'),\n",
       " 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0051, -0.0059, -0.0016,  ...,  0.0035,  0.0046, -0.0048],\n",
       "         [-0.0046,  0.0052,  0.0034,  ..., -0.0029, -0.0048,  0.0042],\n",
       "         [ 0.0030, -0.0050, -0.0040,  ...,  0.0015,  0.0052, -0.0047],\n",
       "         ...,\n",
       "         [-0.0051,  0.0041, -0.0016,  ..., -0.0062, -0.0043,  0.0052],\n",
       "         [ 0.0018, -0.0021, -0.0019,  ...,  0.0054,  0.0071, -0.0023],\n",
       "         [-0.0067,  0.0072, -0.0033,  ..., -0.0056, -0.0030,  0.0063]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0048,  0.0199,  0.0101,  ...,  0.0079,  0.0024, -0.0127],\n",
       "         [ 0.0050, -0.0145, -0.0067,  ...,  0.0043,  0.0054, -0.0145],\n",
       "         [ 0.0249,  0.0107, -0.0099,  ..., -0.0106,  0.0013,  0.0175],\n",
       "         ...,\n",
       "         [ 0.0184,  0.0175, -0.0026,  ..., -0.0045,  0.0156,  0.0031],\n",
       "         [-0.0243, -0.0124, -0.0107,  ...,  0.0160,  0.0005,  0.0027],\n",
       "         [ 0.0139, -0.0049,  0.0042,  ..., -0.0012, -0.0066,  0.0087]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0022, -0.0019, -0.0002,  ...,  0.0043,  0.0031,  0.0017],\n",
       "         [-0.0083,  0.0075, -0.0118,  ..., -0.0111,  0.0074, -0.0046],\n",
       "         [-0.0102,  0.0096, -0.0089,  ..., -0.0113,  0.0102, -0.0097],\n",
       "         ...,\n",
       "         [-0.0007,  0.0003,  0.0081,  ...,  0.0033, -0.0015, -0.0019],\n",
       "         [ 0.0048, -0.0041,  0.0006,  ...,  0.0035, -0.0031,  0.0048],\n",
       "         [-0.0099,  0.0090, -0.0109,  ..., -0.0118,  0.0110, -0.0091]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_posterior_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234530c-a2c0-4698-b7f2-8a9e390585de",
   "metadata": {},
   "source": [
    "### Task 2: QA+SA EVCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0bd22e-e909-48d8-ac98-23e524827601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from torch.optim import AdamW\n",
    "import torch.cuda.amp as amp\n",
    "from transformers import get_scheduler\n",
    "from pyro.optim import ExponentialLR\n",
    "evaluation_loss=[]\n",
    "\n",
    "def run_lora_evcl_2(\n",
    "    combined_loader,  \n",
    "    eval_loader,\n",
    "    num_epochs: int = 100,\n",
    "    batch_size: int = 2,\n",
    "    learning_rate: float = 1e-5,\n",
    "    logging_steps: int = 100,\n",
    "    eval_steps: int = 200,\n",
    "    save_steps: int = 500,\n",
    "    output_dir: str = \"finetuned-weights-LoRA-EVCL-Final-Task2\",\n",
    "    load_pyro: bool = False,\n",
    "    best_output_dir=\"finetuned-weights-LoRA-EVCL-Final-Task2_EVCL_best\",\n",
    "    prev_fisher_info: dict = None,            \n",
    "    prev_posterior_means: dict = None,        \n",
    "    ewc_lambda: float = 0.0,                  \n",
    "    synthetic_data_loader=None,               \n",
    "    tokenizer=None,\n",
    "    model=None\n",
    "):\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Ensure all parameters require gradients\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lora' in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False  # Freeze non-LoRA parameters\n",
    "\n",
    "    def bayesian_guide(input_ids, attention_mask, labels, epoch, warmup_epochs=10, min_scale_factor=0.1):\n",
    "\n",
    "        annealing_factor = max(1.0 - (epoch / warmup_epochs), min_scale_factor)\n",
    "        \n",
    "        # Define variational distributions over the LoRA parameters\n",
    "        for name, module in model.named_modules():\n",
    "            if hasattr(module, 'lora_A'):\n",
    "                for key in module.lora_A:\n",
    "                    param_name = f\"{name}.lora_A.{key}\"\n",
    "                    lora_A_param = module.lora_A[key].weight\n",
    "                    device = lora_A_param.device\n",
    "\n",
    "                    # Ensure initial values are leaf tensors with requires_grad=True\n",
    "                    loc_init = lora_A_param.detach().clone().to(device).requires_grad_()\n",
    "                    scale_init = (0.01 * torch.ones_like(lora_A_param)).to(device).requires_grad_()\n",
    "\n",
    "                    loc = pyro.param(\n",
    "                        f\"{param_name}_loc\",\n",
    "                        loc_init\n",
    "                    )\n",
    "                    scale = pyro.param(\n",
    "                        f\"{param_name}_scale\",\n",
    "                        scale_init,\n",
    "                        constraint=dist.constraints.positive\n",
    "                    )\n",
    "                    \n",
    "                    adjusted_scale = scale * annealing_factor\n",
    "                    \n",
    "                    pyro.sample(\n",
    "                        param_name,\n",
    "                        dist.Normal(loc, adjusted_scale).to_event(lora_A_param.dim())\n",
    "                    )\n",
    "            if hasattr(module, 'lora_B'):\n",
    "                for key in module.lora_B:\n",
    "                    param_name = f\"{name}.lora_B.{key}\"\n",
    "                    lora_B_param = module.lora_B[key].weight\n",
    "                    device = lora_B_param.device\n",
    "\n",
    "                    # Ensure initial values are leaf tensors with requires_grad=True\n",
    "                    loc_init = lora_B_param.detach().clone().to(device).requires_grad_()\n",
    "                    scale_init = (0.01 * torch.ones_like(lora_B_param)).to(device).requires_grad_()\n",
    "\n",
    "                    loc = pyro.param(\n",
    "                        f\"{param_name}_loc\",\n",
    "                        loc_init\n",
    "                    )\n",
    "                    scale = pyro.param(\n",
    "                        f\"{param_name}_scale\",\n",
    "                        scale_init,\n",
    "                        constraint=dist.constraints.positive\n",
    "                    )\n",
    "                    \n",
    "                    adjusted_scale = scale * annealing_factor\n",
    "                    \n",
    "                    pyro.sample(\n",
    "                        param_name,\n",
    "                        dist.Normal(loc, adjusted_scale).to_event(lora_B_param.dim())\n",
    "                    )\n",
    "                        \n",
    "    def bayesian_model(input_ids, attention_mask, labels):\n",
    "        # Define a function to sample and substitute LoRA parameters\n",
    "        def model_with_sampled_lora():\n",
    "            # Sample LoRA parameters and set them in the model\n",
    "            for name, module in model.named_modules():\n",
    "                if hasattr(module, 'lora_A'):\n",
    "                    for key in module.lora_A:\n",
    "                        param_name = f\"{name}.lora_A.{key}\"\n",
    "                        lora_A_module = module.lora_A[key]\n",
    "                        device = lora_A_module.weight.device\n",
    "    \n",
    "                        # Sample from the prior\n",
    "                        sampled_weight = pyro.sample(\n",
    "                            param_name,\n",
    "                            dist.Normal(\n",
    "                                lora_A_module.weight.detach().to(device),\n",
    "                                (0.1 * torch.ones_like(lora_A_module.weight)).to(device)\n",
    "                            ).to_event(lora_A_module.weight.dim())\n",
    "                        )\n",
    "    \n",
    "                        # Assign the sampled weight to the module\n",
    "                        with torch.no_grad():\n",
    "                            lora_A_module.weight.copy_(sampled_weight)\n",
    "    \n",
    "                if hasattr(module, 'lora_B'):\n",
    "                    for key in module.lora_B:\n",
    "                        param_name = f\"{name}.lora_B.{key}\"\n",
    "                        lora_B_module = module.lora_B[key]\n",
    "                        device = lora_B_module.weight.device\n",
    "    \n",
    "                        # Sample from the prior\n",
    "                        sampled_weight = pyro.sample(\n",
    "                            param_name,\n",
    "                            dist.Normal(\n",
    "                                lora_B_module.weight.detach().to(device),\n",
    "                                (0.1 * torch.ones_like(lora_B_module.weight)).to(device)\n",
    "                            ).to_event(lora_B_module.weight.dim())\n",
    "                        )\n",
    "    \n",
    "                        # Assign the sampled weight to the module\n",
    "                        with torch.no_grad():\n",
    "                            lora_B_module.weight.copy_(sampled_weight)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Add EWC penalty if previous Fisher info and posterior means are provided\n",
    "            if prev_fisher_info is not None and prev_posterior_means is not None and ewc_lambda > 0.0:\n",
    "                ewc_penalty = 0.0\n",
    "                for name, param in model.named_parameters():\n",
    "                    if 'lora' in name and name in prev_fisher_info:\n",
    "                        fisher = prev_fisher_info[name].to(DEVICE)\n",
    "                        prev_mean = prev_posterior_means[name].to(DEVICE)\n",
    "                        ewc_penalty += (fisher * (param - prev_mean) ** 2).sum()\n",
    "                        # print('penalty of ewc')\n",
    "                        # print(ewc_penalty)\n",
    "                loss += ewc_lambda * ewc_penalty\n",
    "\n",
    "            return loss\n",
    "\n",
    "        # Use the modified model with sampled LoRA parameters\n",
    "        return model_with_sampled_lora()\n",
    "\n",
    "    # Set up SVI\n",
    "    if load_pyro:\n",
    "        print('using previous pyro params')\n",
    "        pyro.get_param_store().load('pyro_param_store_task1_evcl_best.pt')\n",
    "    else:\n",
    "        print('not using previous pyro params')\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "    optim = pyro.optim.PyroOptim(AdamW, {\"lr\": learning_rate, \"weight_decay\": 1e-5})\n",
    "  \n",
    "    scheduler = ExponentialLR({'optimizer': AdamW, 'optim_args': {'lr': learning_rate}, 'gamma': 0.1})\n",
    "    elbo = TraceMeanField_ELBO()\n",
    "    svi = SVI(bayesian_model, bayesian_guide, scheduler, loss=elbo)\n",
    "    evaluation_loss=[]\n",
    "\n",
    "    # optim = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "    # elbo = TraceMeanField_ELBO()\n",
    "    # svi = SVI(bayesian_model, bayesian_guide, optim, loss=elbo)\n",
    "\n",
    "    # Training loop\n",
    "    print(f\"Training on Task 2...\")\n",
    "    max_wait=20\n",
    "    best_eval_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        svi = SVI(bayesian_model, lambda *args, **kwargs: bayesian_guide(*args, **kwargs, epoch=epoch), scheduler, loss=elbo)\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for num_batches, batch in enumerate(combined_loader, 1):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            loss = svi.step(input_ids, attention_mask, labels)\n",
    "            total_loss += loss\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            scheduler.step()\n",
    "\n",
    "            # Logging\n",
    "            if num_batches % logging_steps == 0:\n",
    "                avg_loss = total_loss / num_batches\n",
    "                print(f\"Epoch {epoch + 1}, Step {num_batches}, Loss: {avg_loss}\")\n",
    "\n",
    "            # Evaluation\n",
    "            if num_batches % eval_steps == 0:\n",
    "                eval_loss=evaluate_model(model, eval_loader)\n",
    "                evaluation_loss.append(eval_loss)\n",
    "\n",
    "            # Save checkpoints\n",
    "            # if num_batches % save_steps == 0:\n",
    "            #     save_trained_model(model, tokenizer, output_dir)\n",
    "\n",
    "        avg_epoch_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_epoch_loss}\")\n",
    "\n",
    "\n",
    "        if epoch%25==0:\n",
    "            save_trained_model(model, tokenizer, output_dir)\n",
    "            pyro.get_param_store().save('pyro_param_store_task2_evcl.pt')\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=30,  \n",
    "                min_length=10,  \n",
    "                no_repeat_ngram_size=2,  \n",
    "                num_return_sequences=1,\n",
    "                top_p=0.9,  \n",
    "                temperature=0.7  \n",
    "            )\n",
    "            batch_predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            # print(batch_predictions)\n",
    "\n",
    "            data = {\n",
    "                        \"batch_predictions\": batch_predictions,\n",
    "                    }\n",
    "\n",
    "\n",
    "            with open(f\"/home/pranav24/cs-546-project/Testing/predictions_EVCL_2_epoch_{epoch}_{num_batches}.json\", \"w\") as json_file:\n",
    "                json.dump(data, json_file, indent=4)\n",
    "\n",
    "\n",
    "        if eval_loss<best_eval_loss:\n",
    "            best_eval_loss=eval_loss\n",
    "            no_improvement=0\n",
    "            save_trained_model(model, tokenizer, best_output_dir)\n",
    "            pyro.get_param_store().save('pyro_param_store_task2_evcl_best.pt')\n",
    "        else:\n",
    "            no_improvement+=1\n",
    "\n",
    "        if no_improvement>=max_wait and epoch>=99:\n",
    "            print(f'early stopping at epoch: {epoch}')\n",
    "            break\n",
    "\n",
    "    # Save the final trained model after the task\n",
    "    save_trained_model(model, tokenizer, output_dir)\n",
    "    pyro.get_param_store().save('pyro_param_store_task2_evcl.pt')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089c452-0279-4e06-9349-8d3935302f63",
   "metadata": {},
   "source": [
    "### SA Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dcdfc7d-7765-4548-aeef-6c7032d5961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given a sentence describing an experience. You need to classify its sentiment, which could only be either positive or negative. \n",
      "Experience: I love the brand, my brother has one, and i thought this was great... good brand, well known and the smaller units must not be made to the same standards.\n",
      "Sentiment: \n",
      "negative\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71b107636614904ae8bf6dd7f93d73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav24/cs-546-project/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/pranav24/cs-546-project/SSR/Latest_Weights/QA_QG_Weights')\n",
    "target_file = \"task1312_amazonreview_polarity_classification.json\"\n",
    "\n",
    "with open(target_file, 'r', encoding='utf-8-sig') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "instances = json_data['Instances'][0:2500]\n",
    "instruct1=\"You will be given a sentence describing an experience. You need to classify its sentiment, which could only be either positive or negative. \\nExperience: \"\n",
    "instruct2=\"\\nSentiment: \"\n",
    "input_texts = [str(instruct1+instance['input']+instruct2) for instance in instances]\n",
    "output_texts = [str(instance['output'][0]) if instance['output'] else \"\" for instance in instances]\n",
    "\n",
    "print(input_texts[0])\n",
    "print(output_texts[0])\n",
    "\n",
    "# Create Hugging Face Dataset\n",
    "ds = Dataset.from_dict({'input': input_texts, 'output': output_texts})\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"output\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs[\"attention_mask\"] = model_inputs.get(\"attention_mask\", None)\n",
    "    return model_inputs\n",
    "\n",
    "# Apply tokenization and set format\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Split dataset into train and eval\n",
    "train_size = int(0.8 * len(tokenized_datasets))\n",
    "train_dataset = tokenized_datasets.select(range(train_size))\n",
    "eval_dataset = tokenized_datasets.select(range(train_size, len(tokenized_datasets)))\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8  \n",
    "train_loader_2 = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_loader_2 = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1370b9d7-8f04-4a2c-a48f-f6f0b8500c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: json_repair in /opt/conda/lib/python3.11/site-packages (0.30.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install json_repair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd52b9-8cc9-4709-aa6d-7342da74ecb5",
   "metadata": {},
   "source": [
    "#### Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65bd9af2-9f5c-45b4-b1ba-7e8ea4c2ee50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df7956d366f4b6c907cdcaaf311a4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json_repair \n",
    "os.chdir('/home/pranav24/cs-546-project/SSR/Synthethic_Data_Generation/')\n",
    "target_file = \"final_sampled.jsonl\"\n",
    "\n",
    "with open(target_file, 'r', encoding='utf-8-sig') as f:\n",
    "    json_data = json_repair.loads(f.read())\n",
    "\n",
    "instances = json_data\n",
    "input_texts = [\"\\nContext: \"+instance['context']+ \"\\nQuestion: \" + instance['question'] for instance in instances]\n",
    "output_texts = [instance[\"refined_answer\"] for instance in instances]\n",
    "\n",
    "\n",
    "ds = Dataset.from_dict({'input': input_texts, 'output': output_texts})\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_size = int(1.0 * len(tokenized_datasets))\n",
    "synthetic_train_dataset = tokenized_datasets.select(range(train_size))\n",
    "batch_size = 8  \n",
    "synthetic_loader_1 = DataLoader(synthetic_train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e88a10a-ba60-4900-8ce0-42141087c768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nContext: A couple of the shirts I got were $ 4.95 and I was discounted off of that ! How sweet is that ? ? Then Andy got home and the circus is in town .\\nQuestion: Why would the narrator buy the shirts that they did ?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845eb255-10f5-40f9-adaf-9712d70c2699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The narrator would buy those shirts because they were on sale.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98e0db01-be03-419b-abde-11df8e635b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pranav24/cs-546-project/SSR/Synthethic_Data_Generation\n",
      "/home/pranav24/cs-546-project\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('/home/pranav24/cs-546-project/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8ad22aa-217f-4d30-9ef2-c882368a26f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined dataloader\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "\n",
    "# Combine datasets\n",
    "if synthetic_loader_1 is not None:\n",
    "    print('combined dataloader')\n",
    "    combined_dataset = ConcatDataset([train_loader_2.dataset, synthetic_loader_1.dataset])\n",
    "    combined_loader = DataLoader(combined_dataset, batch_size=8, shuffle=True)\n",
    "else:\n",
    "    print('not combined dataloader')\n",
    "    combined_loader = train_loader_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5211d71-2108-4c2e-b790-758068ced9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using previous pyro params\n",
      "Training on Task 2...\n",
      "Epoch 1, Step 100, Loss: 6175517.62\n",
      "Epoch 1, Step 200, Loss: 6175513.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2493/2792350256.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 8.1355\n",
      "Epoch 1 completed. Average Loss: 6175512.047101449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-CORRECT-Task2\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-CORRECT-Task2_best\n",
      "Epoch 2, Step 100, Loss: 6528081.025\n",
      "Epoch 2, Step 200, Loss: 6528080.5975\n",
      "Evaluation Loss: 8.1299\n",
      "Epoch 2 completed. Average Loss: 6528081.650362318\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-CORRECT-Task2_best\n",
      "Epoch 3, Step 100, Loss: 6923669.66\n",
      "Epoch 3, Step 200, Loss: 6923670.825\n",
      "Evaluation Loss: 8.1887\n",
      "Epoch 3 completed. Average Loss: 6923671.139492754\n",
      "Epoch 4, Step 100, Loss: 7373613.465\n",
      "Epoch 4, Step 200, Loss: 7373613.7575\n",
      "Evaluation Loss: 8.2134\n",
      "Epoch 4 completed. Average Loss: 7373613.525362318\n",
      "Epoch 5, Step 100, Loss: 7894504.605\n",
      "Epoch 5, Step 200, Loss: 7894504.755\n",
      "Evaluation Loss: 8.1887\n",
      "Epoch 5 completed. Average Loss: 7894504.853260869\n",
      "Epoch 6, Step 100, Loss: 8512081.38\n",
      "Epoch 6, Step 200, Loss: 8512081.245\n",
      "Evaluation Loss: 8.2966\n",
      "Epoch 6 completed. Average Loss: 8512081.15942029\n",
      "Epoch 7, Step 100, Loss: 9269455.17\n",
      "Epoch 7, Step 200, Loss: 9269455.215\n",
      "Evaluation Loss: 8.2212\n",
      "Epoch 7 completed. Average Loss: 9269455.13768116\n",
      "Epoch 8, Step 100, Loss: 10247446.46\n",
      "Epoch 8, Step 200, Loss: 10247446.465\n",
      "Evaluation Loss: 8.2273\n",
      "Epoch 8 completed. Average Loss: 10247446.576086957\n",
      "Epoch 9, Step 100, Loss: 11627518.13\n",
      "Epoch 9, Step 200, Loss: 11627518.125\n",
      "Evaluation Loss: 8.0339\n",
      "Epoch 9 completed. Average Loss: 11627518.094202898\n",
      "Model and tokenizer saved to finetuned-weights-LoRA-EVCL-CORRECT-Task2_best\n",
      "Epoch 10, Step 100, Loss: 13988652.22\n",
      "Epoch 10, Step 200, Loss: 13988652.195\n",
      "Evaluation Loss: 8.2139\n",
      "Epoch 10 completed. Average Loss: 13988652.235507246\n",
      "Epoch 11, Step 100, Loss: 13988652.17\n",
      "Epoch 11, Step 200, Loss: 13988652.21\n",
      "Evaluation Loss: 8.0739\n",
      "Epoch 11 completed. Average Loss: 13988652.217391305\n",
      "Epoch 12, Step 100, Loss: 13988652.2\n",
      "Epoch 12, Step 200, Loss: 13988652.205\n",
      "Evaluation Loss: 8.1671\n",
      "Epoch 12 completed. Average Loss: 13988652.224637682\n",
      "Epoch 13, Step 100, Loss: 13988652.21\n",
      "Epoch 13, Step 200, Loss: 13988652.215\n",
      "Evaluation Loss: 8.1610\n",
      "Epoch 13 completed. Average Loss: 13988652.264492754\n",
      "Epoch 14, Step 100, Loss: 13988652.26\n",
      "Epoch 14, Step 200, Loss: 13988652.245\n",
      "Evaluation Loss: 8.1155\n",
      "Epoch 14 completed. Average Loss: 13988652.246376812\n",
      "Epoch 15, Step 100, Loss: 13988652.23\n",
      "Epoch 15, Step 200, Loss: 13988652.22\n",
      "Evaluation Loss: 8.2272\n",
      "Epoch 15 completed. Average Loss: 13988652.20289855\n"
     ]
    }
   ],
   "source": [
    "ewc_lambda = 50.0\n",
    "model_task_2=run_lora_evcl_2(\n",
    "    combined_loader=combined_loader,\n",
    "    eval_loader=eval_loader_2,\n",
    "    num_epochs= 100,\n",
    "    batch_size=8,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=100,\n",
    "    eval_steps=200,\n",
    "    save_steps=500,\n",
    "    output_dir=\"finetuned-weights-LoRA-EVCL-CORRECT-Task2\",\n",
    "    load_pyro=True,\n",
    "    best_output_dir=\"finetuned-weights-LoRA-EVCL-CORRECT-Task2_best\",\n",
    "    prev_fisher_info=fisher_info,\n",
    "    prev_posterior_means=prev_posterior_means,\n",
    "    ewc_lambda=ewc_lambda,\n",
    "    synthetic_data_loader=synthetic_loader_1,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f8618-bbcc-4004-80d9-2dfbae7d5695",
   "metadata": {},
   "source": [
    "### Task 3 QA+SA+SU (EVCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89919ef9-216e-44d2-a83a-c2458951d58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav24/cs-546-project/venv/lib/python3.11/site-packages/pyro/params/param_store.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(input_file, map_location)\n",
      "Unused kwargs: ['device_map', 'offload_folder', 'offload_state_dict']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22fc921d70a4262876d156c7579d1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling,BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import PeftConfig, PeftModel\n",
    "from accelerate import init_empty_weights\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "from peft.tuners.lora import LoraLayer\n",
    "from pyro.nn.module import to_pyro_module_\n",
    "import bitsandbytes\n",
    "\n",
    "os.chdir(r'/home/pranav24/cs-546-project')\n",
    "pyro.get_param_store().load('pyro_param_store_task2_evcl_best.pt')\n",
    "login(\"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\")\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "base_model_repo_id = \"meta-llama/Meta-Llama-3-8B\"  \n",
    "adapter_model_dir = r\"/home/pranav24/cs-546-project/finetuned-weights-LoRA-EVCL-CORRECT-Task2_best\"\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  \n",
    "    device_map=\"auto\",  \n",
    "    offload_folder=\"offload\",  \n",
    "    offload_state_dict=True,  \n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_repo_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_repo_id,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16, \n",
    ")\n",
    "# model.config.reduction = \"mean\" \n",
    "\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(adapter_model_dir)\n",
    "model = PeftModel.from_pretrained(model, adapter_model_dir, config=peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844525ac-9677-4cc2-846d-bae8ebb87667",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff5196c-c6b6-4b46-81c5-13ccf6327a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,033,669,120 || trainable%: 0.0424\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ce4e831-c24d-4215-975b-eb595d287eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher Information loaded successfully.\n",
      "Starting Epoch 1/1\n",
      "Processing batch 1\n",
      "Completed batch 1\n",
      "Processing batch 2\n",
      "Completed batch 2\n",
      "Processing batch 3\n",
      "Completed batch 3\n",
      "Processing batch 4\n",
      "Completed batch 4\n",
      "Processing batch 5\n",
      "Completed batch 5\n",
      "Processing batch 6\n",
      "Completed batch 6\n",
      "Processing batch 7\n",
      "Completed batch 7\n",
      "Processing batch 8\n",
      "Completed batch 8\n",
      "Processing batch 9\n",
      "Completed batch 9\n",
      "Processing batch 10\n",
      "Completed batch 10\n",
      "Processing batch 11\n",
      "Completed batch 11\n",
      "Processing batch 12\n",
      "Completed batch 12\n",
      "Processing batch 13\n",
      "Completed batch 13\n",
      "Processing batch 14\n",
      "Completed batch 14\n",
      "Processing batch 15\n",
      "Completed batch 15\n",
      "Processing batch 16\n",
      "Completed batch 16\n",
      "Processing batch 17\n",
      "Completed batch 17\n",
      "Processing batch 18\n",
      "Completed batch 18\n",
      "Processing batch 19\n",
      "Completed batch 19\n",
      "Processing batch 20\n",
      "Completed batch 20\n",
      "Processing batch 21\n",
      "Completed batch 21\n",
      "Processing batch 22\n",
      "Completed batch 22\n",
      "Processing batch 23\n",
      "Completed batch 23\n",
      "Processing batch 24\n",
      "Completed batch 24\n",
      "Processing batch 25\n",
      "Completed batch 25\n",
      "Processing batch 26\n",
      "Completed batch 26\n",
      "Processing batch 27\n",
      "Completed batch 27\n",
      "Processing batch 28\n",
      "Completed batch 28\n",
      "Processing batch 29\n",
      "Completed batch 29\n",
      "Processing batch 30\n",
      "Completed batch 30\n",
      "Processing batch 31\n",
      "Completed batch 31\n",
      "Processing batch 32\n",
      "Completed batch 32\n",
      "Processing batch 33\n",
      "Completed batch 33\n",
      "Processing batch 34\n",
      "Completed batch 34\n",
      "Processing batch 35\n",
      "Completed batch 35\n",
      "Processing batch 36\n",
      "Completed batch 36\n",
      "Processing batch 37\n",
      "Completed batch 37\n",
      "Processing batch 38\n",
      "Completed batch 38\n",
      "Processing batch 39\n",
      "Completed batch 39\n",
      "Processing batch 40\n",
      "Completed batch 40\n",
      "Processing batch 41\n",
      "Completed batch 41\n",
      "Processing batch 42\n",
      "Completed batch 42\n",
      "Processing batch 43\n",
      "Completed batch 43\n",
      "Processing batch 44\n",
      "Completed batch 44\n",
      "Processing batch 45\n",
      "Completed batch 45\n",
      "Processing batch 46\n",
      "Completed batch 46\n",
      "Processing batch 47\n",
      "Completed batch 47\n",
      "Processing batch 48\n",
      "Completed batch 48\n",
      "Processing batch 49\n",
      "Completed batch 49\n",
      "Processing batch 50\n",
      "Completed batch 50\n",
      "Processing batch 51\n",
      "Completed batch 51\n",
      "Processing batch 52\n",
      "Completed batch 52\n",
      "Processing batch 53\n",
      "Completed batch 53\n",
      "Processing batch 54\n",
      "Completed batch 54\n",
      "Processing batch 55\n",
      "Completed batch 55\n",
      "Processing batch 56\n",
      "Completed batch 56\n",
      "Processing batch 57\n",
      "Completed batch 57\n",
      "Processing batch 58\n",
      "Completed batch 58\n",
      "Processing batch 59\n",
      "Completed batch 59\n",
      "Processing batch 60\n",
      "Completed batch 60\n",
      "Processing batch 61\n",
      "Completed batch 61\n",
      "Processing batch 62\n",
      "Completed batch 62\n",
      "Processing batch 63\n",
      "Completed batch 63\n",
      "Processing batch 64\n",
      "Completed batch 64\n",
      "Processing batch 65\n",
      "Completed batch 65\n",
      "Processing batch 66\n",
      "Completed batch 66\n",
      "Processing batch 67\n",
      "Completed batch 67\n",
      "Processing batch 68\n",
      "Completed batch 68\n",
      "Processing batch 69\n",
      "Completed batch 69\n",
      "Processing batch 70\n",
      "Completed batch 70\n",
      "Processing batch 71\n",
      "Completed batch 71\n",
      "Processing batch 72\n",
      "Completed batch 72\n",
      "Processing batch 73\n",
      "Completed batch 73\n",
      "Processing batch 74\n",
      "Completed batch 74\n",
      "Processing batch 75\n",
      "Completed batch 75\n",
      "Processing batch 76\n",
      "Completed batch 76\n",
      "Processing batch 77\n",
      "Completed batch 77\n",
      "Processing batch 78\n",
      "Completed batch 78\n",
      "Processing batch 79\n",
      "Completed batch 79\n",
      "Processing batch 80\n",
      "Completed batch 80\n",
      "Processing batch 81\n",
      "Completed batch 81\n",
      "Processing batch 82\n",
      "Completed batch 82\n",
      "Processing batch 83\n",
      "Completed batch 83\n",
      "Processing batch 84\n",
      "Completed batch 84\n",
      "Processing batch 85\n",
      "Completed batch 85\n",
      "Processing batch 86\n",
      "Completed batch 86\n",
      "Processing batch 87\n",
      "Completed batch 87\n",
      "Processing batch 88\n",
      "Completed batch 88\n",
      "Processing batch 89\n",
      "Completed batch 89\n",
      "Processing batch 90\n",
      "Completed batch 90\n",
      "Processing batch 91\n",
      "Completed batch 91\n",
      "Processing batch 92\n",
      "Completed batch 92\n",
      "Processing batch 93\n",
      "Completed batch 93\n",
      "Processing batch 94\n",
      "Completed batch 94\n",
      "Processing batch 95\n",
      "Completed batch 95\n",
      "Processing batch 96\n",
      "Completed batch 96\n",
      "Processing batch 97\n",
      "Completed batch 97\n",
      "Processing batch 98\n",
      "Completed batch 98\n",
      "Processing batch 99\n",
      "Completed batch 99\n",
      "Processing batch 100\n",
      "Completed batch 100\n",
      "Processing batch 101\n",
      "Completed batch 101\n",
      "Processing batch 102\n",
      "Completed batch 102\n",
      "Processing batch 103\n",
      "Completed batch 103\n",
      "Processing batch 104\n",
      "Completed batch 104\n",
      "Processing batch 105\n",
      "Completed batch 105\n",
      "Processing batch 106\n",
      "Completed batch 106\n",
      "Processing batch 107\n",
      "Completed batch 107\n",
      "Processing batch 108\n",
      "Completed batch 108\n",
      "Processing batch 109\n",
      "Completed batch 109\n",
      "Processing batch 110\n",
      "Completed batch 110\n",
      "Processing batch 111\n",
      "Completed batch 111\n",
      "Processing batch 112\n",
      "Completed batch 112\n",
      "Processing batch 113\n",
      "Completed batch 113\n",
      "Processing batch 114\n",
      "Completed batch 114\n",
      "Processing batch 115\n",
      "Completed batch 115\n",
      "Processing batch 116\n",
      "Completed batch 116\n",
      "Processing batch 117\n",
      "Completed batch 117\n",
      "Processing batch 118\n",
      "Completed batch 118\n",
      "Processing batch 119\n",
      "Completed batch 119\n",
      "Processing batch 120\n",
      "Completed batch 120\n",
      "Processing batch 121\n",
      "Completed batch 121\n",
      "Processing batch 122\n",
      "Completed batch 122\n",
      "Processing batch 123\n",
      "Completed batch 123\n",
      "Processing batch 124\n",
      "Completed batch 124\n",
      "Processing batch 125\n",
      "Completed batch 125\n",
      "Processing batch 126\n",
      "Completed batch 126\n",
      "Processing batch 127\n",
      "Completed batch 127\n",
      "Processing batch 128\n",
      "Completed batch 128\n",
      "Processing batch 129\n",
      "Completed batch 129\n",
      "Processing batch 130\n",
      "Completed batch 130\n",
      "Processing batch 131\n",
      "Completed batch 131\n",
      "Processing batch 132\n",
      "Completed batch 132\n",
      "Processing batch 133\n",
      "Completed batch 133\n",
      "Processing batch 134\n",
      "Completed batch 134\n",
      "Processing batch 135\n",
      "Completed batch 135\n",
      "Processing batch 136\n",
      "Completed batch 136\n",
      "Processing batch 137\n",
      "Completed batch 137\n",
      "Processing batch 138\n",
      "Completed batch 138\n",
      "Processing batch 139\n",
      "Completed batch 139\n",
      "Processing batch 140\n",
      "Completed batch 140\n",
      "Processing batch 141\n",
      "Completed batch 141\n",
      "Processing batch 142\n",
      "Completed batch 142\n",
      "Processing batch 143\n",
      "Completed batch 143\n",
      "Processing batch 144\n",
      "Completed batch 144\n",
      "Processing batch 145\n",
      "Completed batch 145\n",
      "Processing batch 146\n",
      "Completed batch 146\n",
      "Processing batch 147\n",
      "Completed batch 147\n",
      "Processing batch 148\n",
      "Completed batch 148\n",
      "Processing batch 149\n",
      "Completed batch 149\n",
      "Processing batch 150\n",
      "Completed batch 150\n",
      "Processing batch 151\n",
      "Completed batch 151\n",
      "Processing batch 152\n",
      "Completed batch 152\n",
      "Processing batch 153\n",
      "Completed batch 153\n",
      "Processing batch 154\n",
      "Completed batch 154\n",
      "Processing batch 155\n",
      "Completed batch 155\n",
      "Processing batch 156\n",
      "Completed batch 156\n",
      "Processing batch 157\n",
      "Completed batch 157\n",
      "Processing batch 158\n",
      "Completed batch 158\n",
      "Processing batch 159\n",
      "Completed batch 159\n",
      "Processing batch 160\n",
      "Completed batch 160\n",
      "Processing batch 161\n",
      "Completed batch 161\n",
      "Processing batch 162\n",
      "Completed batch 162\n",
      "Processing batch 163\n",
      "Completed batch 163\n",
      "Processing batch 164\n",
      "Completed batch 164\n",
      "Processing batch 165\n",
      "Completed batch 165\n",
      "Processing batch 166\n",
      "Completed batch 166\n",
      "Processing batch 167\n",
      "Completed batch 167\n",
      "Processing batch 168\n",
      "Completed batch 168\n",
      "Processing batch 169\n",
      "Completed batch 169\n",
      "Processing batch 170\n",
      "Completed batch 170\n",
      "Processing batch 171\n",
      "Completed batch 171\n",
      "Processing batch 172\n",
      "Completed batch 172\n",
      "Processing batch 173\n",
      "Completed batch 173\n",
      "Processing batch 174\n",
      "Completed batch 174\n",
      "Processing batch 175\n",
      "Completed batch 175\n",
      "Processing batch 176\n",
      "Completed batch 176\n",
      "Processing batch 177\n",
      "Completed batch 177\n",
      "Processing batch 178\n",
      "Completed batch 178\n",
      "Processing batch 179\n",
      "Completed batch 179\n",
      "Processing batch 180\n",
      "Completed batch 180\n",
      "Processing batch 181\n",
      "Completed batch 181\n",
      "Processing batch 182\n",
      "Completed batch 182\n",
      "Processing batch 183\n",
      "Completed batch 183\n",
      "Processing batch 184\n",
      "Completed batch 184\n",
      "Processing batch 185\n",
      "Completed batch 185\n",
      "Processing batch 186\n",
      "Completed batch 186\n",
      "Processing batch 187\n",
      "Completed batch 187\n",
      "Processing batch 188\n",
      "Completed batch 188\n",
      "Processing batch 189\n",
      "Completed batch 189\n",
      "Processing batch 190\n",
      "Completed batch 190\n",
      "Processing batch 191\n",
      "Completed batch 191\n",
      "Processing batch 192\n",
      "Completed batch 192\n",
      "Processing batch 193\n",
      "Completed batch 193\n",
      "Processing batch 194\n",
      "Completed batch 194\n",
      "Processing batch 195\n",
      "Completed batch 195\n",
      "Processing batch 196\n",
      "Completed batch 196\n",
      "Processing batch 197\n",
      "Completed batch 197\n",
      "Processing batch 198\n",
      "Completed batch 198\n",
      "Processing batch 199\n",
      "Completed batch 199\n",
      "Processing batch 200\n",
      "Completed batch 200\n",
      "Processing batch 201\n",
      "Completed batch 201\n",
      "Processing batch 202\n",
      "Completed batch 202\n",
      "Processing batch 203\n",
      "Completed batch 203\n",
      "Processing batch 204\n",
      "Completed batch 204\n",
      "Processing batch 205\n",
      "Completed batch 205\n",
      "Processing batch 206\n",
      "Completed batch 206\n",
      "Processing batch 207\n",
      "Completed batch 207\n",
      "Processing batch 208\n",
      "Completed batch 208\n",
      "Processing batch 209\n",
      "Completed batch 209\n",
      "Processing batch 210\n",
      "Completed batch 210\n",
      "Processing batch 211\n",
      "Completed batch 211\n",
      "Processing batch 212\n",
      "Completed batch 212\n",
      "Processing batch 213\n",
      "Completed batch 213\n",
      "Processing batch 214\n",
      "Completed batch 214\n",
      "Processing batch 215\n",
      "Completed batch 215\n",
      "Processing batch 216\n",
      "Completed batch 216\n",
      "Processing batch 217\n",
      "Completed batch 217\n",
      "Processing batch 218\n",
      "Completed batch 218\n",
      "Processing batch 219\n",
      "Completed batch 219\n",
      "Processing batch 220\n",
      "Completed batch 220\n",
      "Processing batch 221\n",
      "Completed batch 221\n",
      "Processing batch 222\n",
      "Completed batch 222\n",
      "Processing batch 223\n",
      "Completed batch 223\n",
      "Processing batch 224\n",
      "Completed batch 224\n",
      "Processing batch 225\n",
      "Completed batch 225\n",
      "Processing batch 226\n",
      "Completed batch 226\n",
      "Processing batch 227\n",
      "Completed batch 227\n",
      "Processing batch 228\n",
      "Completed batch 228\n",
      "Processing batch 229\n",
      "Completed batch 229\n",
      "Processing batch 230\n",
      "Completed batch 230\n",
      "Processing batch 231\n",
      "Completed batch 231\n",
      "Processing batch 232\n",
      "Completed batch 232\n",
      "Processing batch 233\n",
      "Completed batch 233\n",
      "Processing batch 234\n",
      "Completed batch 234\n",
      "Processing batch 235\n",
      "Completed batch 235\n",
      "Processing batch 236\n",
      "Completed batch 236\n",
      "Processing batch 237\n",
      "Completed batch 237\n",
      "Processing batch 238\n",
      "Completed batch 238\n",
      "Processing batch 239\n",
      "Completed batch 239\n",
      "Processing batch 240\n",
      "Completed batch 240\n",
      "Processing batch 241\n",
      "Completed batch 241\n",
      "Processing batch 242\n",
      "Completed batch 242\n",
      "Processing batch 243\n",
      "Completed batch 243\n",
      "Processing batch 244\n",
      "Completed batch 244\n",
      "Processing batch 245\n",
      "Completed batch 245\n",
      "Processing batch 246\n",
      "Completed batch 246\n",
      "Processing batch 247\n",
      "Completed batch 247\n",
      "Processing batch 248\n",
      "Completed batch 248\n",
      "Processing batch 249\n",
      "Completed batch 249\n",
      "Processing batch 250\n",
      "Completed batch 250\n",
      "Processing batch 251\n",
      "Completed batch 251\n",
      "Processing batch 252\n",
      "Completed batch 252\n",
      "Processing batch 253\n",
      "Completed batch 253\n",
      "Processing batch 254\n",
      "Completed batch 254\n",
      "Processing batch 255\n",
      "Completed batch 255\n",
      "Processing batch 256\n",
      "Completed batch 256\n",
      "Processing batch 257\n",
      "Completed batch 257\n",
      "Processing batch 258\n",
      "Completed batch 258\n",
      "Processing batch 259\n",
      "Completed batch 259\n",
      "Processing batch 260\n",
      "Completed batch 260\n",
      "Processing batch 261\n",
      "Completed batch 261\n",
      "Processing batch 262\n",
      "Completed batch 262\n",
      "Processing batch 263\n",
      "Completed batch 263\n",
      "Processing batch 264\n",
      "Completed batch 264\n",
      "Processing batch 265\n",
      "Completed batch 265\n",
      "Processing batch 266\n",
      "Completed batch 266\n",
      "Processing batch 267\n",
      "Completed batch 267\n",
      "Processing batch 268\n",
      "Completed batch 268\n",
      "Processing batch 269\n",
      "Completed batch 269\n",
      "Processing batch 270\n",
      "Completed batch 270\n",
      "Processing batch 271\n",
      "Completed batch 271\n",
      "Processing batch 272\n",
      "Completed batch 272\n",
      "Processing batch 273\n",
      "Completed batch 273\n",
      "Processing batch 274\n",
      "Completed batch 274\n",
      "Processing batch 275\n",
      "Completed batch 275\n",
      "Processing batch 276\n",
      "Completed batch 276\n"
     ]
    }
   ],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "import pickle\n",
    "os.chdir('/home/pranav24/cs-546-project/')\n",
    "with open('fisher_info_task1_best.pkl', 'rb') as f:\n",
    "    prev_fisher_info = pickle.load(f)\n",
    "print(\"Fisher Information loaded successfully.\")\n",
    "ewc_gamma = 1.0  \n",
    "\n",
    "fisher_info = compute_fisher_info(\n",
    "    model=model,\n",
    "    data_loader=combined_loader,\n",
    "    prev_fisher_info=prev_fisher_info,\n",
    "    ewc_gamma=ewc_gamma,\n",
    "    num_epochs=1,  \n",
    "    head_modules=None,  \n",
    "    n_samples=None  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ce9791f-9757-4218-b063-3a8f6c54845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher Information saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#save current fisher info\n",
    "import pickle\n",
    "os.chdir('/home/pranav24/cs-546-project/')\n",
    "with open('fisher_info_task2_best.pkl', 'wb') as f:\n",
    "    pickle.dump(fisher_info, f)\n",
    "print(\"Fisher Information saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626b349d-ae3b-4314-84cd-a0beec87ad2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 5.6093216699082404e-05\n",
      "Layer: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 3.758061211556196e-05\n",
      "Layer: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.05713948607444763\n",
      "Layer: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 2.163088321685791\n",
      "Layer: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 2.030828909482807e-05\n",
      "Layer: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 4.127507418161258e-05\n",
      "Layer: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.0006349364412017167\n",
      "Layer: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.2751418352127075\n",
      "Layer: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.7123151337727904e-05\n",
      "Layer: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00014436469064094126\n",
      "Layer: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00019240776600781828\n",
      "Layer: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.14796987175941467\n",
      "Layer: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.207471308996901e-05\n",
      "Layer: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0003527531516738236\n",
      "Layer: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.0002418475050944835\n",
      "Layer: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.1577342003583908\n",
      "Layer: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 4.384175917948596e-05\n",
      "Layer: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0006025820039212704\n",
      "Layer: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00010466577077750117\n",
      "Layer: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.12800750136375427\n",
      "Layer: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 7.661627023480833e-05\n",
      "Layer: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0003154997539240867\n",
      "Layer: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 8.659032027935609e-05\n",
      "Layer: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.17317873239517212\n",
      "Layer: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.931580431526527e-05\n",
      "Layer: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0006450637010857463\n",
      "Layer: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 5.376289482228458e-05\n",
      "Layer: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.07233663648366928\n",
      "Layer: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.19394312100485e-05\n",
      "Layer: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0004952197778038681\n",
      "Layer: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 9.20265301829204e-05\n",
      "Layer: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.08722493797540665\n",
      "Layer: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.9657341908896342e-05\n",
      "Layer: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00015680640353821218\n",
      "Layer: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.9163558792788535e-05\n",
      "Layer: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.046585459262132645\n",
      "Layer: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.4983084838604555e-05\n",
      "Layer: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005817810306325555\n",
      "Layer: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 3.109642420895398e-05\n",
      "Layer: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.0367460660636425\n",
      "Layer: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.84819031751249e-05\n",
      "Layer: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0006098956800997257\n",
      "Layer: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.2546113541466184e-05\n",
      "Layer: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.09270293265581131\n",
      "Layer: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.530003596097231e-05\n",
      "Layer: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00029301128233782947\n",
      "Layer: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 8.002537651918828e-05\n",
      "Layer: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.04230909049510956\n",
      "Layer: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.7026888599502854e-05\n",
      "Layer: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005058895330876112\n",
      "Layer: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 4.373014235170558e-05\n",
      "Layer: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.08992481231689453\n",
      "Layer: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 1.0702466170187108e-05\n",
      "Layer: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0002260916371596977\n",
      "Layer: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.1545823983615264e-05\n",
      "Layer: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.022026443853974342\n",
      "Layer: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.00012739392695948482\n",
      "Layer: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0006354706129059196\n",
      "Layer: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.20381079998333e-05\n",
      "Layer: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.04879286140203476\n",
      "Layer: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 7.079811621224508e-05\n",
      "Layer: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00034247071016579866\n",
      "Layer: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 4.109945075470023e-05\n",
      "Layer: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.10050420463085175\n",
      "Layer: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 5.468404560815543e-05\n",
      "Layer: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005657393485307693\n",
      "Layer: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 3.845206447294913e-05\n",
      "Layer: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.03523753583431244\n",
      "Layer: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 8.911109034670517e-06\n",
      "Layer: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 3.224497413611971e-05\n",
      "Layer: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.685326398932375e-05\n",
      "Layer: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.07432501018047333\n",
      "Layer: base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.0004320091102272272\n",
      "Layer: base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0007285045576281846\n",
      "Layer: base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 4.716238618129864e-05\n",
      "Layer: base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.058115556836128235\n",
      "Layer: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 5.1100709242746234e-05\n",
      "Layer: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.000538820750080049\n",
      "Layer: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00010987916903104633\n",
      "Layer: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.09085527807474136\n",
      "Layer: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 2.815809057210572e-05\n",
      "Layer: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00044073903700336814\n",
      "Layer: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 6.647926056757569e-05\n",
      "Layer: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.05421275645494461\n",
      "Layer: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.00014858452777843922\n",
      "Layer: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0009107890073210001\n",
      "Layer: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.225825664936565e-05\n",
      "Layer: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.055320315062999725\n",
      "Layer: base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.040296542167198e-05\n",
      "Layer: base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005487226299010217\n",
      "Layer: base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00016668890020810068\n",
      "Layer: base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.03674826771020889\n",
      "Layer: base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 3.398329499759711e-05\n",
      "Layer: base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0005592732923105359\n",
      "Layer: base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 2.5094806915149093e-05\n",
      "Layer: base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.07813559472560883\n",
      "Layer: base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 8.036586223170161e-05\n",
      "Layer: base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0021025200840085745\n",
      "Layer: base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00027599965687841177\n",
      "Layer: base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.19449135661125183\n",
      "Layer: base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 5.260542093310505e-05\n",
      "Layer: base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.00040812656516209245\n",
      "Layer: base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.0002025985741056502\n",
      "Layer: base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.09111778438091278\n",
      "Layer: base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.00012394358054734766\n",
      "Layer: base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0003986824303865433\n",
      "Layer: base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 4.426928353495896e-05\n",
      "Layer: base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.13511312007904053\n",
      "Layer: base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.00028172522434033453\n",
      "Layer: base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0021248897537589073\n",
      "Layer: base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00012179951590951532\n",
      "Layer: base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.24572020769119263\n",
      "Layer: base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 8.177075869753025e-06\n",
      "Layer: base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0003096263390034437\n",
      "Layer: base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 1.6053802028181963e-05\n",
      "Layer: base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.02845124900341034\n",
      "Layer: base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 0.00011697008449118584\n",
      "Layer: base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0015050711808726192\n",
      "Layer: base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 6.986028893152252e-05\n",
      "Layer: base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.0727277398109436\n",
      "Layer: base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 5.476640581036918e-05\n",
      "Layer: base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.0007620616815984249\n",
      "Layer: base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 7.425570220220834e-05\n",
      "Layer: base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.31711143255233765\n",
      "Layer: base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight, Fisher Info Mean: 5.10462632519193e-05\n",
      "Layer: base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight, Fisher Info Mean: 0.001168274087831378\n",
      "Layer: base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight, Fisher Info Mean: 0.00020124641014263034\n",
      "Layer: base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight, Fisher Info Mean: 0.06315212696790695\n"
     ]
    }
   ],
   "source": [
    "for name, fisher_matrix in fisher_info.items():\n",
    "    print(f\"Layer: {name}, Fisher Info Mean: {fisher_matrix.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02230991-0178-415a-859a-72a703afd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_posterior_means = get_variational_posterior_means(model)\n",
    "torch.save(prev_posterior_means, f'posterior_means_task_2_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df3922be-7461-4615-b20f-4c0ff1555688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from torch.optim import AdamW\n",
    "import torch.cuda.amp as amp\n",
    "from transformers import get_scheduler\n",
    "from pyro.optim import ExponentialLR\n",
    "evaluation_loss=[]\n",
    "\n",
    "def run_lora_evcl_2(\n",
    "    combined_loader,  \n",
    "    eval_loader,\n",
    "    num_epochs: int = 100,\n",
    "    batch_size: int = 2,\n",
    "    learning_rate: float = 1e-5,\n",
    "    logging_steps: int = 100,\n",
    "    eval_steps: int = 200,\n",
    "    save_steps: int = 500,\n",
    "    output_dir: str = \"finetuned-weights-LoRA-EVCL-Final-Task3\",\n",
    "    load_pyro: bool = False,\n",
    "    best_output_dir=\"finetuned-weights-LoRA-EVCL-Final-Task3_EVCL_best\",\n",
    "    prev_fisher_info: dict = None,            \n",
    "    prev_posterior_means: dict = None,        \n",
    "    ewc_lambda: float = 0.0,                  \n",
    "    synthetic_data_loader=None,               \n",
    "    tokenizer=None,\n",
    "    model=None\n",
    "):\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Ensure all parameters require gradients\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lora' in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False  # Freeze non-LoRA parameters\n",
    "\n",
    "    def bayesian_guide(input_ids, attention_mask, labels, epoch, warmup_epochs=10, min_scale_factor=0.1):\n",
    "\n",
    "        annealing_factor = max(1.0 - (epoch / warmup_epochs), min_scale_factor)\n",
    "        \n",
    "        # Define variational distributions over the LoRA parameters\n",
    "        for name, module in model.named_modules():\n",
    "            if hasattr(module, 'lora_A'):\n",
    "                for key in module.lora_A:\n",
    "                    param_name = f\"{name}.lora_A.{key}\"\n",
    "                    lora_A_param = module.lora_A[key].weight\n",
    "                    device = lora_A_param.device\n",
    "\n",
    "                    # Ensure initial values are leaf tensors with requires_grad=True\n",
    "                    loc_init = lora_A_param.detach().clone().to(device).requires_grad_()\n",
    "                    scale_init = (0.01 * torch.ones_like(lora_A_param)).to(device).requires_grad_()\n",
    "\n",
    "                    loc = pyro.param(\n",
    "                        f\"{param_name}_loc\",\n",
    "                        loc_init\n",
    "                    )\n",
    "                    scale = pyro.param(\n",
    "                        f\"{param_name}_scale\",\n",
    "                        scale_init,\n",
    "                        constraint=dist.constraints.positive\n",
    "                    )\n",
    "                    \n",
    "                    adjusted_scale = scale * annealing_factor\n",
    "                    \n",
    "                    pyro.sample(\n",
    "                        param_name,\n",
    "                        dist.Normal(loc, adjusted_scale).to_event(lora_A_param.dim())\n",
    "                    )\n",
    "            if hasattr(module, 'lora_B'):\n",
    "                for key in module.lora_B:\n",
    "                    param_name = f\"{name}.lora_B.{key}\"\n",
    "                    lora_B_param = module.lora_B[key].weight\n",
    "                    device = lora_B_param.device\n",
    "\n",
    "                    # Ensure initial values are leaf tensors with requires_grad=True\n",
    "                    loc_init = lora_B_param.detach().clone().to(device).requires_grad_()\n",
    "                    scale_init = (0.01 * torch.ones_like(lora_B_param)).to(device).requires_grad_()\n",
    "\n",
    "                    loc = pyro.param(\n",
    "                        f\"{param_name}_loc\",\n",
    "                        loc_init\n",
    "                    )\n",
    "                    scale = pyro.param(\n",
    "                        f\"{param_name}_scale\",\n",
    "                        scale_init,\n",
    "                        constraint=dist.constraints.positive\n",
    "                    )\n",
    "                    \n",
    "                    adjusted_scale = scale * annealing_factor\n",
    "                    \n",
    "                    pyro.sample(\n",
    "                        param_name,\n",
    "                        dist.Normal(loc, adjusted_scale).to_event(lora_B_param.dim())\n",
    "                    )\n",
    "                        \n",
    "    def bayesian_model(input_ids, attention_mask, labels):\n",
    "        # Define a function to sample and substitute LoRA parameters\n",
    "        def model_with_sampled_lora():\n",
    "            # Sample LoRA parameters and set them in the model\n",
    "            for name, module in model.named_modules():\n",
    "                if hasattr(module, 'lora_A'):\n",
    "                    for key in module.lora_A:\n",
    "                        param_name = f\"{name}.lora_A.{key}\"\n",
    "                        lora_A_module = module.lora_A[key]\n",
    "                        device = lora_A_module.weight.device\n",
    "    \n",
    "                        # Sample from the prior\n",
    "                        sampled_weight = pyro.sample(\n",
    "                            param_name,\n",
    "                            dist.Normal(\n",
    "                                lora_A_module.weight.detach().to(device),\n",
    "                                (0.1 * torch.ones_like(lora_A_module.weight)).to(device)\n",
    "                            ).to_event(lora_A_module.weight.dim())\n",
    "                        )\n",
    "    \n",
    "                        # Assign the sampled weight to the module\n",
    "                        with torch.no_grad():\n",
    "                            lora_A_module.weight.copy_(sampled_weight)\n",
    "    \n",
    "                if hasattr(module, 'lora_B'):\n",
    "                    for key in module.lora_B:\n",
    "                        param_name = f\"{name}.lora_B.{key}\"\n",
    "                        lora_B_module = module.lora_B[key]\n",
    "                        device = lora_B_module.weight.device\n",
    "    \n",
    "                        # Sample from the prior\n",
    "                        sampled_weight = pyro.sample(\n",
    "                            param_name,\n",
    "                            dist.Normal(\n",
    "                                lora_B_module.weight.detach().to(device),\n",
    "                                (0.1 * torch.ones_like(lora_B_module.weight)).to(device)\n",
    "                            ).to_event(lora_B_module.weight.dim())\n",
    "                        )\n",
    "    \n",
    "                        # Assign the sampled weight to the module\n",
    "                        with torch.no_grad():\n",
    "                            lora_B_module.weight.copy_(sampled_weight)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Add EWC penalty if previous Fisher info and posterior means are provided\n",
    "            if prev_fisher_info is not None and prev_posterior_means is not None and ewc_lambda > 0.0:\n",
    "                ewc_penalty = 0.0\n",
    "                for name, param in model.named_parameters():\n",
    "                    if 'lora' in name and name in prev_fisher_info:\n",
    "                        fisher = prev_fisher_info[name].to(DEVICE)\n",
    "                        prev_mean = prev_posterior_means[name].to(DEVICE)\n",
    "                        ewc_penalty += (fisher * (param - prev_mean) ** 2).sum()\n",
    "                        # print('penalty of ewc')\n",
    "                        # print(ewc_penalty)\n",
    "                loss += ewc_lambda * ewc_penalty\n",
    "\n",
    "            return loss\n",
    "\n",
    "        # Use the modified model with sampled LoRA parameters\n",
    "        return model_with_sampled_lora()\n",
    "\n",
    "    # Set up SVI\n",
    "    if load_pyro:\n",
    "        print('using previous pyro params')\n",
    "        pyro.get_param_store().load('pyro_param_store_task2_evcl_best.pt')\n",
    "    else:\n",
    "        print('not using previous pyro params')\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "    optim = pyro.optim.PyroOptim(AdamW, {\"lr\": learning_rate, \"weight_decay\": 1e-5})\n",
    "  \n",
    "    scheduler = ExponentialLR({'optimizer': AdamW, 'optim_args': {'lr': learning_rate}, 'gamma': 0.1})\n",
    "    elbo = TraceMeanField_ELBO()\n",
    "    svi = SVI(bayesian_model, bayesian_guide, scheduler, loss=elbo)\n",
    "    evaluation_loss=[]\n",
    "\n",
    "    # optim = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "    # elbo = TraceMeanField_ELBO()\n",
    "    # svi = SVI(bayesian_model, bayesian_guide, optim, loss=elbo)\n",
    "\n",
    "    # Training loop\n",
    "    print(f\"Training on Task 2...\")\n",
    "    max_wait=20\n",
    "    best_eval_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        svi = SVI(bayesian_model, lambda *args, **kwargs: bayesian_guide(*args, **kwargs, epoch=epoch), scheduler, loss=elbo)\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for num_batches, batch in enumerate(combined_loader, 1):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            loss = svi.step(input_ids, attention_mask, labels)\n",
    "            total_loss += loss\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            scheduler.step()\n",
    "\n",
    "            # Logging\n",
    "            if num_batches % logging_steps == 0:\n",
    "                avg_loss = total_loss / num_batches\n",
    "                print(f\"Epoch {epoch + 1}, Step {num_batches}, Loss: {avg_loss}\")\n",
    "\n",
    "            # Evaluation\n",
    "            if num_batches % eval_steps == 0:\n",
    "                eval_loss=evaluate_model(model, eval_loader)\n",
    "                evaluation_loss.append(eval_loss)\n",
    "\n",
    "            # Save checkpoints\n",
    "            # if num_batches % save_steps == 0:\n",
    "            #     save_trained_model(model, tokenizer, output_dir)\n",
    "\n",
    "        avg_epoch_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_epoch_loss}\")\n",
    "\n",
    "\n",
    "        if epoch%25==0:\n",
    "            save_trained_model(model, tokenizer, output_dir)\n",
    "            pyro.get_param_store().save('pyro_param_store_task3_evcl.pt')\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=30,  \n",
    "                min_length=10,  \n",
    "                no_repeat_ngram_size=2,  \n",
    "                num_return_sequences=1,\n",
    "                top_p=0.9,  \n",
    "                temperature=0.7  \n",
    "            )\n",
    "            batch_predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            # print(batch_predictions)\n",
    "\n",
    "            data = {\n",
    "                        \"batch_predictions\": batch_predictions,\n",
    "                    }\n",
    "\n",
    "\n",
    "            with open(f\"/home/pranav24/cs-546-project/Testing/predictions_EVCL_3_epoch_{epoch}_{num_batches}.json\", \"w\") as json_file:\n",
    "                json.dump(data, json_file, indent=4)\n",
    "\n",
    "\n",
    "        if eval_loss<best_eval_loss:\n",
    "            best_eval_loss=eval_loss\n",
    "            no_improvement=0\n",
    "            save_trained_model(model, tokenizer, best_output_dir)\n",
    "            pyro.get_param_store().save('pyro_param_store_task3_evcl_best.pt')\n",
    "        else:\n",
    "            no_improvement+=1\n",
    "\n",
    "        if no_improvement>=max_wait and epoch>=99:\n",
    "            print(f'early stopping at epoch: {epoch}')\n",
    "            break\n",
    "\n",
    "    # Save the final trained model after the task\n",
    "    save_trained_model(model, tokenizer, output_dir)\n",
    "    pyro.get_param_store().save('pyro_param_store_task3_evcl.pt')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7b163-2482-45cd-a04c-f2332cd9e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/pranav24/cs-546-project/SSR/Latest_Weights/QA_QG_Weights')\n",
    "target_file = \"task1312_amazonreview_polarity_classification.json\"\n",
    "\n",
    "with open(target_file, 'r', encoding='utf-8-sig') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "instances = json_data['Instances'][0:2500]\n",
    "instruct1=\"You will be given a sentence describing an experience. You need to classify its sentiment, which could only be either positive or negative. \\nExperience: \"\n",
    "instruct2=\"\\nSentiment: \"\n",
    "input_texts = [str(instruct1+instance['input']+instruct2) for instance in instances]\n",
    "output_texts = [str(instance['output'][0]) if instance['output'] else \"\" for instance in instances]\n",
    "\n",
    "print(input_texts[0])\n",
    "print(output_texts[0])\n",
    "\n",
    "# Create Hugging Face Dataset\n",
    "ds = Dataset.from_dict({'input': input_texts, 'output': output_texts})\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"output\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs[\"attention_mask\"] = model_inputs.get(\"attention_mask\", None)\n",
    "    return model_inputs\n",
    "\n",
    "# Apply tokenization and set format\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Split dataset into train and eval\n",
    "train_size = int(0.8 * len(tokenized_datasets))\n",
    "train_dataset = tokenized_datasets.select(range(train_size))\n",
    "eval_dataset = tokenized_datasets.select(range(train_size, len(tokenized_datasets)))\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8  \n",
    "train_loader_2 = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_loader_2 = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8ecd5-8e80-4b2f-8637-a7d6d01d3e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bceb6-8a2a-49c1-b086-ed66b52b1bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74496102-d49e-42e9-8025-2ec7c659d67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c641d2d-4c83-4438-979e-6b8d58229ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d2058-83cd-4ea5-993f-37d5507d66df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_546)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
