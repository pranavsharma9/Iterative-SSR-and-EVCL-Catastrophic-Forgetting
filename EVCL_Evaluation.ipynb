{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4a3ccd-6f64-4fbd-bfc6-f28c1478118a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020bd05314de4cedbe01bf64e68774f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4023f381f47d47bb9c6ee051dcff89ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c27d5040ac4306af333ff00fc3b52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav24/cs-546-project/venv/lib/python3.11/site-packages/pyro/params/param_store.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(input_file, map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/tmp/ipykernel_9238/2559409691.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|▎         | 1/32 [02:18<1:11:26, 138.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|▋         | 2/32 [04:37<1:09:28, 138.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|▉         | 3/32 [06:56<1:07:11, 139.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 12%|█▎        | 4/32 [09:11<1:04:08, 137.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 16%|█▌        | 5/32 [11:35<1:02:47, 139.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 19%|█▉        | 6/32 [13:44<58:57, 136.07s/it]  Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 22%|██▏       | 7/32 [15:58<56:29, 135.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 25%|██▌       | 8/32 [18:16<54:25, 136.06s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 28%|██▊       | 9/32 [20:55<54:55, 143.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|███▏      | 10/32 [23:48<55:53, 152.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|███▍      | 11/32 [26:28<54:14, 154.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 38%|███▊      | 12/32 [29:03<51:37, 154.86s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 41%|████      | 13/32 [31:43<49:33, 156.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 44%|████▍     | 14/32 [34:28<47:42, 159.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 47%|████▋     | 15/32 [37:09<45:12, 159.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 50%|█████     | 16/32 [40:02<43:36, 163.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 53%|█████▎    | 17/32 [42:42<40:39, 162.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 56%|█████▋    | 18/32 [45:32<38:28, 164.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 59%|█████▉    | 19/32 [48:20<35:53, 165.65s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 62%|██████▎   | 20/32 [51:12<33:30, 167.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|██████▌   | 21/32 [53:59<30:40, 167.31s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|██████▉   | 22/32 [56:50<28:06, 168.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 72%|███████▏  | 23/32 [59:39<25:18, 168.73s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 75%|███████▌  | 24/32 [1:01:53<21:05, 158.18s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 78%|███████▊  | 25/32 [1:04:09<17:40, 151.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 81%|████████▏ | 26/32 [1:06:22<14:37, 146.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 84%|████████▍ | 27/32 [1:08:37<11:52, 142.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 88%|████████▊ | 28/32 [1:11:09<09:42, 145.50s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|█████████ | 29/32 [1:14:01<07:40, 153.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████▍| 30/32 [1:16:34<05:06, 153.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|█████████▋| 31/32 [1:18:54<02:29, 149.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████| 32/32 [1:21:04<00:00, 152.02s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = \"/home/pranav24/cs-546-project/SSR/Latest_Weights/QA_Weights/task024_cosmosqa_answer_generation.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract input-output pairs from JSON\n",
    "instances = data[\"Instances\"][2500:5000]\n",
    "inputs = [instance[\"input\"] for instance in instances]\n",
    "outputs = [instance[\"output\"][0] for instance in instances]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_inputs, test_inputs, train_outputs, test_outputs = train_test_split(\n",
    "    inputs, outputs, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert data to Hugging Face Dataset format\n",
    "train_ds = Dataset.from_dict({\"input\": train_inputs, \"output\": train_outputs})\n",
    "test_ds = Dataset.from_dict({\"input\": test_inputs, \"output\": test_outputs})\n",
    "\n",
    "# Tokenizer setup\n",
    "base_model_path = \"meta-llama/Meta-Llama-3-8B\"  # Replace with actual model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "# Check if tokenizer has a padding token, if not, set the eos_token as padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"output\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )[\"input_ids\"]\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train_ds = train_ds.map(tokenize_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "tokenized_test_ds = test_ds.map(tokenize_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "\n",
    "# Convert datasets to PyTorch format\n",
    "tokenized_train_ds.set_format(\"torch\")\n",
    "tokenized_test_ds.set_format(\"torch\")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16  # Adjust as needed\n",
    "train_loader = DataLoader(tokenized_train_ds, batch_size=batch_size, shuffle=True)\n",
    "eval_loader = DataLoader(tokenized_test_ds, batch_size=batch_size)\n",
    "\n",
    "# Define the model and load weights\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True,\n",
    ")\n",
    "fine_tuned_weights_path = \"/home/pranav24/cs-546-project/finetuned-weights-LoRA-EVCL-Final-Task2_EVCL_best\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, fine_tuned_weights_path)\n",
    "pyro.get_param_store().load('pyro_param_store_task2_vcl_best.pt')\n",
    "\n",
    "# Ensure compatibility with the unchanged part of the code\n",
    "DEVICE = model.device\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "references = []\n",
    "sampled_weights_log = []  # Store sampled weights\n",
    "\n",
    "print(\"Generating predictions:\")\n",
    "\n",
    "for i in tqdm(range(0, len(test_inputs), batch_size)):  # Loop in batches\n",
    "    batch_inputs = test_inputs[i:i + batch_size]\n",
    "    batch_references = test_outputs[i:i + batch_size]\n",
    "\n",
    "    # Tokenize the inputs in a batch\n",
    "    inputs_tokenized = tokenizer(batch_inputs, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Apply Pyro parameters to LoRA layers\n",
    "            for name, module in model.named_modules():\n",
    "                if hasattr(module, \"lora_A\"):\n",
    "                    for key in module.lora_A:\n",
    "                        loc = pyro.param(f\"{name}.lora_A.{key}_loc\")\n",
    "                        scale = pyro.param(f\"{name}.lora_A.{key}_scale\")\n",
    "                        sampled_weight = pyro.sample(\n",
    "                            f\"{name}.lora_A.{key}\",\n",
    "                            dist.Normal(loc, scale).to_event(loc.dim())\n",
    "                        )\n",
    "                        sampled_weights_log.append(\n",
    "                            (name, key, sampled_weight.clone().cpu().numpy())\n",
    "                        )\n",
    "                        module.lora_A[key].weight.data.copy_(sampled_weight)\n",
    "\n",
    "                if hasattr(module, \"lora_B\"):\n",
    "                    for key in module.lora_B:\n",
    "                        loc = pyro.param(f\"{name}.lora_B.{key}_loc\")\n",
    "                        scale = pyro.param(f\"{name}.lora_B.{key}_scale\")\n",
    "                        sampled_weight = pyro.sample(\n",
    "                            f\"{name}.lora_B.{key}\",\n",
    "                            dist.Normal(loc, scale).to_event(loc.dim())\n",
    "                        )\n",
    "                        sampled_weights_log.append(\n",
    "                            (name, key, sampled_weight.clone().cpu().numpy())\n",
    "                        )\n",
    "                        module.lora_B[key].weight.data.copy_(sampled_weight)\n",
    "\n",
    "            # Generate predictions using the tokenized inputs\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=inputs_tokenized[\"input_ids\"],\n",
    "                attention_mask=inputs_tokenized[\"attention_mask\"],\n",
    "                max_length=1000,  # Adjust as needed\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True  # Optional: Sampling for diverse generations\n",
    "            )\n",
    "\n",
    "        # Decode generated IDs\n",
    "        batch_predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        predictions.extend(batch_predictions)\n",
    "        references.extend(batch_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dc1b165-6ffb-425b-9370-9b616c36934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b197bf84df0b4ecd9b06c9934f7c99fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_9238/197527174.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "100%|██████████| 1/1 [01:55<00:00, 115.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# test_inputs=[\"Context: Then I drove all around to the used DVD stores to get season 2. ( which I found for 20 bucks! ) I have been watching a disk a night, and not going to bed until 3 am because I knew that the new season was starting soon and I didn't want to be behind. I just finished season 2 and was on the edge of my seat the whole last episode. Yesterday I taped what was on tv. Question: What does the narrator think about the price of the DVD set purchased?\"]\n",
    "test_inputs=[\"Context: Good Old War and person L : I saw both of these bands Wednesday night , and they both blew me away . seriously . Good Old War is acoustic and makes me smile . I really can not help but be happy when I listen to them ; I think it 's the fact that they seemed so happy themselves when they played . Question: In the future , will this person go to see other bands play ?\"]\n",
    "batch_size=1\n",
    "final_answer=[]\n",
    "\n",
    "base_model_path = \"meta-llama/Meta-Llama-3-8B\"\n",
    "# fine_tuned_weights_path = \"/home/pranav24/cs-546-project/finetuned-weights-LoRA-EVCL-Final-Task1_VCL_best\"\n",
    "\n",
    "fine_tuned_weights_path=\"/home/pranav24/cs-546-project/SSR/Latest_Weights/QA_Weights/finetuned-weights/QA_Final\"\n",
    "pyro.clear_param_store()\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, fine_tuned_weights_path)\n",
    "# pyro.get_param_store().load('pyro_param_store_task1_vcl_best.pt')\n",
    "# pyro.get_param_store().load('pyro_param_store_task1_vcl_best.pt')\n",
    "\n",
    "# Ensure compatibility with the unchanged part of the code\n",
    "DEVICE = model.device\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, len(test_inputs), batch_size)):  # Loop in batches\n",
    "    batch_inputs = test_inputs[i:i + batch_size]\n",
    "    # batch_references = test_outputs[i:i + batch_size]\n",
    "\n",
    "    # Tokenize the inputs in a batch\n",
    "    inputs_tokenized = tokenizer(batch_inputs, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Apply Pyro parameters to LoRA layers\n",
    "            # for name, module in model.named_modules():\n",
    "            #     if hasattr(module, \"lora_A\"):\n",
    "            #         for key in module.lora_A:\n",
    "            #             loc = pyro.param(f\"{name}.lora_A.{key}_loc\")\n",
    "            #             scale = pyro.param(f\"{name}.lora_A.{key}_scale\")\n",
    "            #             sampled_weight = pyro.sample(\n",
    "            #                 f\"{name}.lora_A.{key}\",\n",
    "            #                 dist.Normal(loc, scale).to_event(loc.dim())\n",
    "            #             )\n",
    "            #             sampled_weights_log.append(\n",
    "            #                 (name, key, sampled_weight.clone().cpu().numpy())\n",
    "            #             )\n",
    "            #             module.lora_A[key].weight.data.copy_(sampled_weight)\n",
    "\n",
    "            #     if hasattr(module, \"lora_B\"):\n",
    "            #         for key in module.lora_B:\n",
    "            #             loc = pyro.param(f\"{name}.lora_B.{key}_loc\")\n",
    "            #             scale = pyro.param(f\"{name}.lora_B.{key}_scale\")\n",
    "            #             sampled_weight = pyro.sample(\n",
    "            #                 f\"{name}.lora_B.{key}\",\n",
    "            #                 dist.Normal(loc, scale).to_event(loc.dim())\n",
    "            #             )\n",
    "            #             sampled_weights_log.append(\n",
    "            #                 (name, key, sampled_weight.clone().cpu().numpy())\n",
    "            #             )\n",
    "            #             module.lora_B[key].weight.data.copy_(sampled_weight)\n",
    "\n",
    "            # Generate predictions using the tokenized inputs\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=inputs_tokenized[\"input_ids\"],\n",
    "                attention_mask=inputs_tokenized[\"attention_mask\"],\n",
    "                max_length=512,  # Adjust as needed\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True  # Optional: Sampling for diverse generations\n",
    "            )\n",
    "\n",
    "        # Decode generated IDs\n",
    "        final_batch_predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        final_answer.extend(final_batch_predictions)\n",
    "        # predictions.extend(batch_predictions)\n",
    "        # references.extend(batch_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c1fa3b8-441e-44e2-a8e7-9fce776da596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,   2014,     25,   7839,  10846,   5111,    323,   1732,    445,\n",
       "            551,    358,   5602,   2225,    315,   1521,  21562,   8079,   3814,\n",
       "           1174,    323,    814,   2225,  42423,    757,   3201,    662,  14243,\n",
       "            662,   7839,  10846,   5111,    374,  45166,    323,   3727,    757,\n",
       "          15648,    662,    358,   2216,    649,    539,   1520,    719,    387,\n",
       "           6380,    994,    358,   9020,    311,   1124,   2652,    358,   1781,\n",
       "            433,    364,     82,    279,   2144,    430,    814,   9508,    779,\n",
       "           6380,   5694,    994,    814,   6476,    662,  16225,     25,    763,\n",
       "            279,   3938,   1174,    690,    420,   1732,    733,    311,   1518,\n",
       "           1023,  21562,   1514,    949]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_tokenized[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa8ea215-a555-473b-bba8-8ac75cfa8567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Context: Then I drove all around to the used DVD stores to get season 2. ( which I found for 20 bucks! ) I have been watching a disk a night, and not going to bed until 3 am because I knew that the new season was starting soon and I didn't want to be behind. I just finished season 2 and was on the edge of my seat the whole last episode. Yesterday I taped what was on tv. Question: What does the narrator think about the price of the DVD set purchased?\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e32b06e-f87c-4dee-80a7-fbd0a3c67343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Context: Good Old War and person L : I saw both of these bands Wednesday night, and they both blew me away. seriously. Good Old War is acoustic and makes me smile. I really can not help but be happy when I listen to them ; I think it's the fact that they seemed so happy themselves when they played. Question: In the future, will this person go to see other bands play?. \\nQuestion: What type of person is this?The person is a fan of music. They go to see bands play. They like Good Old War and person L. They are a happy person. They enjoy music. They like to listen to bands play. They enjoy listening to music. They like to see bands perform. They are a happy person. They enjoy listening to music. They enjoy seeing bands perform. They are a fan of music. They like to see bands play. They like Good Old War and person L. They are a happy person. They like to see bands perform. They like to listen to music. They are a fan of music. They like to see bands play. They like Good Old War and person L. They are a happy person. They enjoy music. They like to see bands perform. They are a fan of music. They like to see bands play. They like Good Old War and person L. They are a happy person. They enjoy music. They like to see bands perform. They are a fan of music. They like to see bands play. They like Good Old War and person L. They are a happy person. They enjoy music. They like to see bands perform. They are a fan of music. They like to see bands play. They like Good Old War and person L. They are a happy person. They enjoy music. They like to see bands perform. They are a fan of music. They like to see bands play. They like Good Old War and person L. They are a happy person. They enjoy music. They like to see bands perform. They are a fan of music. They like to see bands play. They like Good Old War and person L. They are a happy person. They enjoy music. They like to see bands perform. They are a fan of music. They like to see bands play. They like Good Old War and person L. They are a happy person. They enjoy music. They like to see bands perform. They are a fan of music. They like to see bands play. They like Good Old War\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417f4c6-3d2c-44ea-b68b-5fe63ebdc7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c595385-1091-4c2a-b8a9-bf8d242083d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eef26b9-09ea-45d9-ad2a-93389a61ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to predictions.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create a dictionary to store the data\n",
    "data = {\n",
    "    \"batch_predictions\": batch_predictions,\n",
    "    \"predictions\": predictions,\n",
    "    \"references\": references\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"predictions_EVCL_Task2.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "print(\"Data saved to predictions.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "534f4391-9b1c-4031-8ee1-bead885f4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/pranav24/cs-546-project/SSR/Latest_Weights/QA_Weights/task024_cosmosqa_answer_generation.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract input-output pairs from JSON\n",
    "instances = data[\"Instances\"][2500:5000]\n",
    "inputs = [instance[\"input\"] for instance in instances]\n",
    "outputs = [instance[\"output\"][0] for instance in instances]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_inputs, test_inputs, train_outputs, test_outputs = train_test_split(\n",
    "    inputs, outputs, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5943f7bf-a228-4479-97c1-c8783e182e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: When Derek joined her , the door man unhooked the rope to let them through , still watching Lucy with undisguised lust as they walked in . A look of utter confusion shown on Derek 's features as they were granted entrance into the club . He draped an arm over Lucy 's shoulders and they made their way through the crowds of people . \" So how 'd you do that ?. \n",
      "Question: What may be the reason for Derek 's confusion ?\n"
     ]
    }
   ],
   "source": [
    "print(test_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01db09-2788-40e8-aa5a-c5f64bcab373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_546)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
